{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"transfer_from_mimic_plus_model_fusion_tuned.ipynb","provenance":[{"file_id":"1QsV0kSJG51OSJ-Qc6aGRp7dUxHIWC76S","timestamp":1605994614077},{"file_id":"10xNSbnm9sICcipsarPohRBFl-dm9J3Sy","timestamp":1590618496097},{"file_id":"https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/07_Keras_Flowers_TPU_squeezenet.ipynb","timestamp":1590349630848}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"cells":[{"cell_type":"markdown","metadata":{"id":"7TXW18uVoztb"},"source":["In this notebook GCP TPU(s) are loaded; Madrid’s previously cleaned train and test CXR jpg(s) and ehr data are loaded; then we put image, ehr data and the label in the same tf records; ehr data only model is defined; CXR only model is defined; pretrained MIMIC CXR model to identify CheXpert 14 labels is loaded; intermediated fusion model is defined; models are tuned; experiments are set up in order to find the best parameters; CXR model is retrained on full dataset using best parameters; finally results are visualized."]},{"cell_type":"markdown","metadata":{"id":"89B27-TGiDNB"},"source":["# Imports and Configuration"]},{"cell_type":"code","metadata":{"id":"hRUoBXwNdGNM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391603238,"user_tz":-60,"elapsed":7600,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"d8c0330e-b618-4dc7-f12c-a19614db7042"},"source":["# May not need them on paid tpu\n","!pip3 install sklearn\n","!pip3 install gcsfs\n","!pip3 install shap -q\n","!pip3 install seaborn\n","!pip3 install tableone -q\n","!pip3 install fsspec\n","!pip3 install talos\n","!pip3 install xlrd==1.2.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: sklearn in ./.local/lib/python3.7/site-packages (0.0)\n","Requirement already satisfied: scikit-learn in ./.local/lib/python3.7/site-packages (from sklearn) (0.24.1)\n","Requirement already satisfied: scipy>=0.19.1 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: gcsfs in ./.local/lib/python3.7/site-packages (0.7.2)\n","Requirement already satisfied: fsspec>=0.8.0 in ./.local/lib/python3.7/site-packages (from gcsfs) (0.8.5)\n","Requirement already satisfied: google-auth-oauthlib in ./.local/lib/python3.7/site-packages (from gcsfs) (0.4.2)\n","Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from gcsfs) (4.3.0)\n","Requirement already satisfied: aiohttp in ./.local/lib/python3.7/site-packages (from gcsfs) (3.7.3)\n","Requirement already satisfied: google-auth>=1.2 in ./.local/lib/python3.7/site-packages (from gcsfs) (1.27.0)\n","Requirement already satisfied: requests in ./.local/lib/python3.7/site-packages (from gcsfs) (2.21.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (4.7.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs) (0.2.1)\n","Requirement already satisfied: six>=1.9.0 in ./.local/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n","Requirement already satisfied: setuptools>=40.3.0 in ./.local/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (53.0.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs) (0.4.2)\n","Requirement already satisfied: typing-extensions>=3.6.5 in ./.local/lib/python3.7/site-packages (from aiohttp->gcsfs) (3.7.4.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.7/site-packages (from aiohttp->gcsfs) (1.6.3)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in ./.local/lib/python3.7/site-packages (from aiohttp->gcsfs) (3.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->gcsfs) (18.2.0)\n","Requirement already satisfied: chardet<4.0,>=2.0 in ./.local/lib/python3.7/site-packages (from aiohttp->gcsfs) (3.0.4)\n","Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.7/site-packages (from aiohttp->gcsfs) (5.1.0)\n","Requirement already satisfied: idna>=2.0 in ./.local/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp->gcsfs) (2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.7/site-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in ./.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in ./.local/lib/python3.7/site-packages (from requests->gcsfs) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.7/site-packages (from requests->gcsfs) (2020.12.5)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: seaborn in ./.local/lib/python3.7/site-packages (0.11.1)\n","Requirement already satisfied: pandas>=0.23 in ./.local/lib/python3.7/site-packages (from seaborn) (0.24.2)\n","Requirement already satisfied: scipy>=1.0 in ./.local/lib/python3.7/site-packages (from seaborn) (1.4.1)\n","Requirement already satisfied: numpy>=1.15 in ./.local/lib/python3.7/site-packages (from seaborn) (1.19.5)\n","Requirement already satisfied: matplotlib>=2.2 in ./.local/lib/python3.7/site-packages (from seaborn) (3.3.4)\n","Requirement already satisfied: python-dateutil>=2.1 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n","Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.1.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n","Requirement already satisfied: six in ./.local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n","Requirement already satisfied: pytz>=2011k in ./.local/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.1)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: fsspec in ./.local/lib/python3.7/site-packages (0.8.5)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: talos in ./.local/lib/python3.7/site-packages (1.0)\n","Requirement already satisfied: astetik in ./.local/lib/python3.7/site-packages (from talos) (1.11.1)\n","Requirement already satisfied: requests in ./.local/lib/python3.7/site-packages (from talos) (2.21.0)\n","Requirement already satisfied: tensorflow>=2.0.0 in ./.local/lib/python3.7/site-packages (from talos) (2.4.1)\n","Requirement already satisfied: chances in ./.local/lib/python3.7/site-packages (from talos) (0.1.9)\n","Requirement already satisfied: kerasplotlib in ./.local/lib/python3.7/site-packages (from talos) (0.1.6)\n","Requirement already satisfied: pandas in ./.local/lib/python3.7/site-packages (from talos) (0.24.2)\n","Requirement already satisfied: wrangle in ./.local/lib/python3.7/site-packages (from talos) (0.6.2)\n","Requirement already satisfied: sklearn in ./.local/lib/python3.7/site-packages (from talos) (0.0)\n","Requirement already satisfied: statsmodels>=0.11.0 in ./.local/lib/python3.7/site-packages (from talos) (0.12.2)\n","Requirement already satisfied: tqdm in ./.local/lib/python3.7/site-packages (from talos) (4.57.0)\n","Requirement already satisfied: numpy in ./.local/lib/python3.7/site-packages (from talos) (1.19.5)\n","Requirement already satisfied: patsy>=0.5 in ./.local/lib/python3.7/site-packages (from statsmodels>=0.11.0->talos) (0.5.1)\n","Requirement already satisfied: scipy>=1.1 in ./.local/lib/python3.7/site-packages (from statsmodels>=0.11.0->talos) (1.4.1)\n","Requirement already satisfied: pytz>=2011k in ./.local/lib/python3.7/site-packages (from pandas->talos) (2021.1)\n","Requirement already satisfied: python-dateutil>=2.5.0 in ./.local/lib/python3.7/site-packages (from pandas->talos) (2.8.1)\n","Requirement already satisfied: six in ./.local/lib/python3.7/site-packages (from patsy>=0.5->statsmodels>=0.11.0->talos) (1.15.0)\n","Requirement already satisfied: wheel~=0.35 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (0.36.2)\n","Requirement already satisfied: absl-py~=0.10 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (0.11.0)\n","Requirement already satisfied: grpcio~=1.32.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.32.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (3.7.4.3)\n","Requirement already satisfied: tensorboard~=2.4 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (2.4.1)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.1.2)\n","Requirement already satisfied: google-pasta~=0.2 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (0.2.0)\n","Requirement already satisfied: wrapt~=1.12.1 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.12.1)\n","Requirement already satisfied: h5py~=2.10.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (2.10.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.12)\n","Requirement already satisfied: protobuf>=3.9.2 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (3.15.2)\n","Requirement already satisfied: gast==0.3.3 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (0.3.3)\n","Requirement already satisfied: astunparse~=1.6.3 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.6.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (3.3.0)\n","Requirement already satisfied: termcolor~=1.1.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in ./.local/lib/python3.7/site-packages (from tensorflow>=2.0.0->talos) (2.4.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.27.0)\n","Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (53.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.4.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (4.7.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (4.2.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.3.0)\n","Requirement already satisfied: importlib-metadata in ./.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.7/site-packages (from requests->talos) (2020.12.5)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./.local/lib/python3.7/site-packages (from requests->talos) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in ./.local/lib/python3.7/site-packages (from requests->talos) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in ./.local/lib/python3.7/site-packages (from requests->talos) (2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in ./.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.4.2)\n","Requirement already satisfied: seaborn in ./.local/lib/python3.7/site-packages (from astetik->talos) (0.11.1)\n","Requirement already satisfied: geonamescache in ./.local/lib/python3.7/site-packages (from astetik->talos) (1.2.0)\n","Requirement already satisfied: IPython in ./.local/lib/python3.7/site-packages (from astetik->talos) (5.5.0)\n","Requirement already satisfied: zipp>=0.5 in ./.local/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.4.0)\n","Requirement already satisfied: decorator in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (4.3.0)\n","Requirement already satisfied: pexpect in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (4.6.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (1.0.15)\n","Requirement already satisfied: pygments in ./.local/lib/python3.7/site-packages (from IPython->astetik->talos) (2.8.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (4.3.2)\n","Requirement already satisfied: pickleshare in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/lib/python3/dist-packages (from IPython->astetik->talos) (0.8.1)\n","Requirement already satisfied: keras in ./.local/lib/python3.7/site-packages (from kerasplotlib->talos) (2.4.3)\n","Requirement already satisfied: pyyaml in ./.local/lib/python3.7/site-packages (from keras->kerasplotlib->talos) (5.4.1)\n","Requirement already satisfied: matplotlib>=2.2 in ./.local/lib/python3.7/site-packages (from seaborn->astetik->talos) (3.3.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn->astetik->talos) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn->astetik->talos) (1.3.1)\n","Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn->astetik->talos) (8.1.0)\n","Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn->astetik->talos) (0.10.0)\n","Requirement already satisfied: scikit-learn in ./.local/lib/python3.7/site-packages (from sklearn->talos) (0.24.1)\n","Requirement already satisfied: joblib>=0.11 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn->talos) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.7/site-packages (from scikit-learn->sklearn->talos) (2.1.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: xlrd==1.2.0 in ./.local/lib/python3.7/site-packages (1.2.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9u3d4Z7uQsmp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391605171,"user_tz":-60,"elapsed":9508,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"d3673275-9b06-43fa-cad1-f6e561462a6a"},"source":["import os, sys, math\n","import json\n","import numpy as np\n","from matplotlib import pyplot as plt\n","if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n","  %tensorflow_version 2.2.0\n","import tensorflow as tf\n","#import tensorflow_addons as tfa\n","from tensorflow.python.lib.io import file_io\n","import tensorflow.keras.backend as K\n","print(\"Tensorflow version \" + tf.__version__)\n","AUTO = tf.data.experimental.AUTOTUNE\n","%matplotlib inline\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import CustomObjectScope\n","import talos as ta\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import glob\n","import pandas as pd\n","import random\n","import gcsfs\n","\n","# import cv2\n","\n","import warnings\n","warnings.filterwarnings('ignore',category=FutureWarning)\n","\n","print(\"Tensorflow version \" + tf.__version__)\n","print(\"Numpy version \" + np.__version__)\n","print(\"gcsfs version \" + gcsfs.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensorflow version 2.4.1\n","Tensorflow version 2.4.1\n","Numpy version 1.19.5\n","gcsfs version 0.7.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s0aYb2-3q70v"},"source":["# Set seed"]},{"cell_type":"code","metadata":{"id":"eGMtHrg0aeCe"},"source":["# Set random seed for experiments\n","# works for cpu and gpu devices only but sufficient for single core tpu training\n","SEED = 42\n","os.environ['PYTHONHASHSEED']=str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","# This is just tuning how the data is prefetched for the dataloader\n","AUTO = tf.data.experimental.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d50hQ4HShbWy"},"source":["# TPU Detection"]},{"cell_type":"code","metadata":{"id":"kO7_MW6dfn-3"},"source":["# Change this to true if just want to play with colab tpu resource -- which is enough to train <70 search experiments\n","\n","HOSTED_RUNTIME = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQKx0jbjhYGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391605317,"user_tz":-60,"elapsed":9610,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"1f078010-d1c0-44f2-c933-0b1aefbf7eea"},"source":["# Detect hardware\n","try:\n","  if HOSTED_RUNTIME:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","  else:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='cxr-test',project='hm-covid-19') # TPU selection\n","except ValueError:\n","  tpu = None\n","  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n","    \n","# Select appropriate distribution strategy for hardware\n","if tpu:\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","  print('Running on TPU ', tpu.master())  \n","elif len(gpus) > 0:\n","  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n","  print('Running on ', len(gpus), ' GPU(s) ')\n","else:\n","  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n","  print('Running on CPU')\n","\n","# How many accelerators do we have ?\n","print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CPU\n","Number of accelerators:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iCrARmTxOs6G"},"source":["if 'google.colab' in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJUlzNBWwXzA"},"source":["if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BzqMlHOmMRG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391606509,"user_tz":-60,"elapsed":10762,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"e8aeb26b-fa80-432a-f86c-9da6d73fdea5"},"source":["if HOSTED_RUNTIME:\n","    # Run this if running on hosted runtime\n","    project_id = 'hm-covid-19'\n","    !gcloud config set project $project_id\n","    !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","    !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","    !apt -qq update\n","    !apt -qq install gcsfuse\n","    !mkdir data\n","    !gcsfuse new_cxr_30 data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Updated property [core/project].\n","\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [hm-covid-19] or it does not exist.\n","/usr/bin/sh: 1: cannot create /etc/apt/sources.list.d/gcsfuse.list: Permission denied\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  1974  100  1974    0     0   137k      0 --:--:-- --:--:-- --:--:--  137k\n","E: This command can only be used by root.\n","E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n","E: Unable to lock directory /var/lib/apt/lists/\n","W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n","W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n","E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n","E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n","mkdir: cannot create directory ‘data’: File exists\n","/usr/bin/sh: 1: gcsfuse: not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lppFcOCdiGBP"},"source":["project_id='hm-covid-19'\n","os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9aMfOvVrE3In"},"source":["# try:\n","#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","# except ValueError:\n","#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","# tf.config.experimental_connect_to_cluster(tpu)\n","# tf.tpu.experimental.initialize_tpu_system(tpu)\n","# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQNDWXDYPTBk"},"source":["# Define models\n","\n","Data preprocessing and cleaning code has been moved to another notebook here: https://colab.research.google.com/drive/1mi_OAwLNQGSCp-iJ84A3SNY63jaDPlGa?usp=sharing\n"]},{"cell_type":"markdown","metadata":{"id":"63UwpNN2veNo"},"source":["## Not tunable parameters"]},{"cell_type":"code","metadata":{"id":"ZVOmk3D7SN25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391608060,"user_tz":-60,"elapsed":12270,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"f47558a1-547d-4752-a789-d2b1289772d7"},"source":["# Not tunable input \n","CLASSES = ['ALIVE','EXPIRED']\n","\n","# Images\n","GCS_PATTERN_JPG_TRAIN = 'gs://new_cxr_30/classified/*/train_*.jpg'\n","GCS_PATTERN_JPG_TEST = 'gs://new_cxr_30/classified/*/test_*.jpg'\n","TARGET_SIZE = 320\n","\n","# splitting data files between training and validation\n","training_filenames = tf.io.gfile.glob(GCS_PATTERN_JPG_TRAIN)\n","validation_filenames = tf.io.gfile.glob(GCS_PATTERN_JPG_TEST)\n","print(\" {} training files and {} validation files\".format(len(training_filenames), len(validation_filenames)))\n","\n","# 2 fusion models: 1 with all features from Madrid, second with only features common across Madrid, Korean and Hoboken\n","# XFEATURES = ['age', 'MALE', 'vitals_temp_ed_first', 'vitals_sbp_ed_first', 'vitals_dbp_ed_first'\n","#             , 'vitals_hr_ed_first', 'vitals_spo2_ed_first', 'pmhx_diabetes', 'pmhx_hld', 'pmhx_htn'\n","#             , 'pmhx_ihd', 'pmhx_ckd', 'pmhx_copd', 'pmhx_asthma', 'pmhx_activecancer', 'pmhx_chronicliver'\n","#             , 'pmhx_stroke', 'pmhx_chf', 'pmhx_dementia', 'lab_glucose', 'lab_creatinine'\n","#             , 'lab_mean_platelet_volume', 'lab_neutrophil', 'lab_mch', 'lab_prothrombin_activity'\n","#             , 'lab_ldh', 'lab_rbc', 'lab_rdw', 'lab_inr', 'lab_potassium', 'lab_aptt'\n","#             , 'lab_lymphocyte_percentage', 'lab_platelet', 'lab_mcv', 'lab_sodium', 'lab_urea'\n","#             , 'lab_hct', 'lab_lymphocyte', 'lab_leukocyte', 'lab_alt', 'lab_ast', 'lab_ddimer'\n","#             , 'lab_neutrophil_percentage', 'lab_crp', 'lab_hemoglobin'\n","#             #, 'APview'\n","#             ]\n","# XFEATURES.sort()\n","# print(XFEATURES)\n","# need a mapping file that has path to image mapped to the corresponding structured data and the outcome (30 day mortality)\n","# hoboken_features = ['age','sex','ed_diagnosis','vitals_temp_ed_first','vitals_sbp_ed_first','vitals_dbp_ed_first','vitals_hr_ed_first','vitals_spo2_ed_first','hospital_outcome','pmhx_diabetes','pmhx_hld','pmhx_htn','pmhx_ihd','pmhx_ckd','pmhx_copd','pmhx_asthma','pmhx_activecancer','pmhx_chronicliver','pmhx_stroke','pmhx_chf','pmhx_dementia','lab_sodium','lab_leukocyte','lab_mean_platelet_volume','lab_neutrophil','lab_ddimer','lab_inr','lab_mch','lab_creatinine','lab_mcv','lab_aptt','lab_platelet','lab_lymphocyte_percentage','lab_glucose','lab_neutrophil_percentage','lab_ldh','lab_prothrombin_activity','lab_urea','lab_lymphocyte','lab_crp','lab_rdw','lab_hemoglobin','lab_rbc,','lab_hct,','lab_potassium,','lab_alt','lab_ast']\n","# hoboken_features.sort()\n","# print(hoboken_features)\n","# korean_features = ['age','sex','ed_diagnosis','vitals_temp_ed_first','vitals_sbp_ed_first','vitals_dbp_ed_first','vitals_hr_ed_first','vitals_spo2_ed_first','hospital_outcome','pmhx_diabetes','pmhx_hld','pmhx_htn','pmhx_ihd','pmhx_ckd','pmhx_copd','pmhx_asthma','pmhx_activecancer','pmhx_chronicliver','pmhx_stroke','pmhx_chf','pmhx_dementia','lab_sodium','lab_leukocyte','lab_mean_platelet_volume','lab_glucose','lab_hct','lab_hemoglobin','lab_creatinine','lab_lymphocyte_percentage','lab_urea','lab_inr','lab_lymphocyte','lab_ddimer','lab_crp','lab_ldh','lab_neutrophil_percentage','lab_rbc','lab_neutrophil','lab_alt','lab_potassium','lab_rdw','lab_mcv','lab_aptt','lab_mch','lab_prothrombin_activity','lab_ast','lab_platelet']\n","# korean_features.sort()\n","# print(korean_features)\n","# sorted\n","\n","XFEATURES = ['MALE', 'age', 'lab_alt', 'lab_aptt', 'lab_ast', 'lab_creatinine', 'lab_crp', 'lab_ddimer', 'lab_glucose'\n","                    , 'lab_hct', 'lab_hemoglobin', 'lab_inr', 'lab_ldh', 'lab_leukocyte', 'lab_lymphocyte'\n","                    , 'lab_lymphocyte_percentage', 'lab_mch', 'lab_mcv', 'lab_mean_platelet_volume', 'lab_neutrophil'\n","                    , 'lab_neutrophil_percentage', 'lab_platelet', 'lab_potassium', 'lab_prothrombin_activity'\n","                    , 'lab_rbc', 'lab_rdw', 'lab_sodium', 'lab_urea', 'pmhx_activecancer', 'pmhx_asthma', 'pmhx_chf'\n","                    , 'pmhx_chronicliver', 'pmhx_ckd', 'pmhx_copd', 'pmhx_dementia', 'pmhx_diabetes', 'pmhx_hld'\n","                    , 'pmhx_htn', 'pmhx_ihd', 'pmhx_stroke', 'vitals_dbp_ed_first', 'vitals_hr_ed_first'\n","                    , 'vitals_sbp_ed_first', 'vitals_spo2_ed_first', 'vitals_temp_ed_first']\n","\n","hoboken_features = ['sex', \n","                    #'ed_diagnosis', 'hospital_outcome',\n","                    'age', 'lab_alt', 'lab_aptt', 'lab_ast', 'lab_creatinine', 'lab_crp', 'lab_ddimer', 'lab_glucose'\n","                    , 'lab_hct,', 'lab_hemoglobin', 'lab_inr', 'lab_ldh', 'lab_leukocyte', 'lab_lymphocyte'\n","                    , 'lab_lymphocyte_percentage', 'lab_mch', 'lab_mcv', 'lab_mean_platelet_volume', 'lab_neutrophil'\n","                    , 'lab_neutrophil_percentage', 'lab_platelet', 'lab_potassium,', 'lab_prothrombin_activity'\n","                    , 'lab_rbc,', 'lab_rdw', 'lab_sodium', 'lab_urea', 'pmhx_activecancer', 'pmhx_asthma', 'pmhx_chf'\n","                    , 'pmhx_chronicliver', 'pmhx_ckd', 'pmhx_copd', 'pmhx_dementia', 'pmhx_diabetes', 'pmhx_hld'\n","                    , 'pmhx_htn', 'pmhx_ihd', 'pmhx_stroke', 'vitals_dbp_ed_first', 'vitals_hr_ed_first'\n","                    , 'vitals_sbp_ed_first', 'vitals_spo2_ed_first', 'vitals_temp_ed_first']\n","korean_features = ['sex', \n","                   #'ed_diagnosis', 'hospital_outcome',\n","                   'age', 'lab_alt', 'lab_aptt', 'lab_ast', 'lab_creatinine', 'lab_crp', 'lab_ddimer', 'lab_glucose'\n","                   , 'lab_hct', 'lab_hemoglobin', 'lab_inr', 'lab_ldh', 'lab_leukocyte', 'lab_lymphocyte'\n","                   , 'lab_lymphocyte_percentage', 'lab_mch', 'lab_mcv', 'lab_mean_platelet_volume', 'lab_neutrophil'\n","                   , 'lab_neutrophil_percentage', 'lab_platelet', 'lab_potassium', 'lab_prothrombin_activity'\n","                   , 'lab_rbc', 'lab_rdw', 'lab_sodium', 'lab_urea', 'pmhx_activecancer', 'pmhx_asthma', 'pmhx_chf'\n","                   , 'pmhx_chronicliver', 'pmhx_ckd', 'pmhx_copd', 'pmhx_dementia', 'pmhx_diabetes', 'pmhx_hld'\n","                   , 'pmhx_htn', 'pmhx_ihd', 'pmhx_stroke', 'vitals_dbp_ed_first', 'vitals_hr_ed_first'\n","                   , 'vitals_sbp_ed_first', 'vitals_spo2_ed_first', 'vitals_temp_ed_first']\n","\n","# number of features seem the same but it seems there are more missing values in hoboken and korean datasets\n","print(len(XFEATURES))\n","print(len(hoboken_features))\n","print(len(korean_features))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 1393 training files and 457 validation files\n","45\n","45\n","45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tygs_niCGPhw","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"ok","timestamp":1615391608772,"user_tz":-60,"elapsed":12958,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"621ec075-c50c-46f8-ece5-4f96a2d31d67"},"source":["# these data have previously been cleaned and normalized\n","madrid = pd.read_csv('gs://new_cxr_30/split/valtest_structured.csv')\n","print(madrid.shape)\n","print(madrid[madrid.expired_30_days==1].shape)\n","madrid.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(457, 52)\n","(43, 52)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                     SOPInstanceUID  \\\n","0           0  1.2.124.113532.1498221512208150662116715066119...   \n","1           1  1.2.124.113532.1611534457135871191862002058421...   \n","2           2  1.2.840.113619.2.202.4.2147483647.1585562476.4...   \n","3           3  1.2.840.113619.2.202.4.2147483647.1585896668.8...   \n","4           4  1.2.840.113619.2.202.4.2147483647.1586241488.7...   \n","\n","                                                path  expired_30_days  \\\n","0  gs://new_cxr_30/classified/ALIVE/test_1.2.124....                0   \n","1  gs://new_cxr_30/classified/ALIVE/test_1.2.124....                0   \n","2  gs://new_cxr_30/classified/ALIVE/test_1.2.840....                0   \n","3  gs://new_cxr_30/classified/ALIVE/test_1.2.840....                0   \n","4  gs://new_cxr_30/classified/ALIVE/test_1.2.840....                0   \n","\n","   patient_id       age  MALE  vitals_temp_ed_first  vitals_sbp_ed_first  \\\n","0       661.0 -0.250000   0.0              0.000000            -2.133333   \n","1      1434.0 -0.125000   1.0              2.500000             1.666667   \n","2      1407.0  0.333333   1.0              0.000000             0.000000   \n","3      1609.0  0.291667   0.0             -0.333333             0.533333   \n","4       216.0 -0.541667   0.0             -0.333333            -0.200000   \n","\n","   vitals_dbp_ed_first  ...  lab_lymphocyte  lab_leukocyte   lab_alt  \\\n","0               -3.875  ...       -0.735849       1.462661  0.000000   \n","1                1.250  ...       -1.018868       2.039485 -0.052117   \n","2                0.000  ...       -1.075472      -0.916738  0.247557   \n","3                0.250  ...        0.528302       0.243777 -0.579805   \n","4               -0.625  ...       -0.283019      -0.545923 -0.827362   \n","\n","    lab_ast  lab_ddimer  lab_neutrophil_percentage   lab_crp  lab_hemoglobin  \\\n","0  0.000000    0.000000                   1.293233  0.195206       -0.941176   \n","1 -0.388610   -0.654905                   1.503759  3.098790        0.529412   \n","2  0.616415   11.133380                  -0.067669  0.721019       -0.941176   \n","3 -0.871022    0.985180                   0.015038 -0.501428       -1.176471   \n","4 -0.321608   -0.564573                  -0.751880 -0.720121        0.352941   \n","\n","   APview                       bbox_coordinates  \n","0       1  [135, 29, 167, 123, 24, 31, 264, 231]  \n","1       1    [130, 0, 198, 138, 4, 17, 318, 241]  \n","2       1   [141, 0, 178, 111, 32, 17, 307, 211]  \n","3       1   [138, 0, 175, 149, 38, 61, 302, 259]  \n","4       1   [129, 0, 187, 144, 31, 25, 288, 249]  \n","\n","[5 rows x 52 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>SOPInstanceUID</th>\n","      <th>path</th>\n","      <th>expired_30_days</th>\n","      <th>patient_id</th>\n","      <th>age</th>\n","      <th>MALE</th>\n","      <th>vitals_temp_ed_first</th>\n","      <th>vitals_sbp_ed_first</th>\n","      <th>vitals_dbp_ed_first</th>\n","      <th>...</th>\n","      <th>lab_lymphocyte</th>\n","      <th>lab_leukocyte</th>\n","      <th>lab_alt</th>\n","      <th>lab_ast</th>\n","      <th>lab_ddimer</th>\n","      <th>lab_neutrophil_percentage</th>\n","      <th>lab_crp</th>\n","      <th>lab_hemoglobin</th>\n","      <th>APview</th>\n","      <th>bbox_coordinates</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1.2.124.113532.1498221512208150662116715066119...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.2.124....</td>\n","      <td>0</td>\n","      <td>661.0</td>\n","      <td>-0.250000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>-2.133333</td>\n","      <td>-3.875</td>\n","      <td>...</td>\n","      <td>-0.735849</td>\n","      <td>1.462661</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.293233</td>\n","      <td>0.195206</td>\n","      <td>-0.941176</td>\n","      <td>1</td>\n","      <td>[135, 29, 167, 123, 24, 31, 264, 231]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1.2.124.113532.1611534457135871191862002058421...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.2.124....</td>\n","      <td>0</td>\n","      <td>1434.0</td>\n","      <td>-0.125000</td>\n","      <td>1.0</td>\n","      <td>2.500000</td>\n","      <td>1.666667</td>\n","      <td>1.250</td>\n","      <td>...</td>\n","      <td>-1.018868</td>\n","      <td>2.039485</td>\n","      <td>-0.052117</td>\n","      <td>-0.388610</td>\n","      <td>-0.654905</td>\n","      <td>1.503759</td>\n","      <td>3.098790</td>\n","      <td>0.529412</td>\n","      <td>1</td>\n","      <td>[130, 0, 198, 138, 4, 17, 318, 241]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1.2.840.113619.2.202.4.2147483647.1585562476.4...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.2.840....</td>\n","      <td>0</td>\n","      <td>1407.0</td>\n","      <td>0.333333</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000</td>\n","      <td>...</td>\n","      <td>-1.075472</td>\n","      <td>-0.916738</td>\n","      <td>0.247557</td>\n","      <td>0.616415</td>\n","      <td>11.133380</td>\n","      <td>-0.067669</td>\n","      <td>0.721019</td>\n","      <td>-0.941176</td>\n","      <td>1</td>\n","      <td>[141, 0, 178, 111, 32, 17, 307, 211]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1.2.840.113619.2.202.4.2147483647.1585896668.8...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.2.840....</td>\n","      <td>0</td>\n","      <td>1609.0</td>\n","      <td>0.291667</td>\n","      <td>0.0</td>\n","      <td>-0.333333</td>\n","      <td>0.533333</td>\n","      <td>0.250</td>\n","      <td>...</td>\n","      <td>0.528302</td>\n","      <td>0.243777</td>\n","      <td>-0.579805</td>\n","      <td>-0.871022</td>\n","      <td>0.985180</td>\n","      <td>0.015038</td>\n","      <td>-0.501428</td>\n","      <td>-1.176471</td>\n","      <td>1</td>\n","      <td>[138, 0, 175, 149, 38, 61, 302, 259]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1.2.840.113619.2.202.4.2147483647.1586241488.7...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.2.840....</td>\n","      <td>0</td>\n","      <td>216.0</td>\n","      <td>-0.541667</td>\n","      <td>0.0</td>\n","      <td>-0.333333</td>\n","      <td>-0.200000</td>\n","      <td>-0.625</td>\n","      <td>...</td>\n","      <td>-0.283019</td>\n","      <td>-0.545923</td>\n","      <td>-0.827362</td>\n","      <td>-0.321608</td>\n","      <td>-0.564573</td>\n","      <td>-0.751880</td>\n","      <td>-0.720121</td>\n","      <td>0.352941</td>\n","      <td>1</td>\n","      <td>[129, 0, 187, 144, 31, 25, 288, 249]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 52 columns</p>\n","</div>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XDGod_BWG1xc"},"source":["# still would need same preprocessing steps as the Madrid data (from Wesley's notebook) - NaN values, no MALE feature encoding\n","# use scaler from madrid train data to fit/normalize hoboken and korean test data\n","# need to add image \"path\" info to same file\n","# need to add \"expired_30_days\" outcome column to same file\n","\n","# hoboken structured data\n","#hobo = pd.read_excel('gs://hoboken_structured_data/hoboken_structured_data.xlsx')\n","#hobo.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgXrOFc7BpSv"},"source":["## Data loaders"]},{"cell_type":"code","metadata":{"id":"F9lUt3jBTCLb","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1615391608944,"user_tz":-60,"elapsed":13089,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"982d62d1-610d-4b38-83c9-e650995a8ad6"},"source":["structured_path = 'gs://new_cxr_30/split/valtest_structured.csv'\n","dfstructure = pd.read_csv(structured_path)\n","# dfstructure.head()\n","print(dfstructure.shape)\n","is_NaN = dfstructure.isnull()\n","row_has_NaN = is_NaN.any(axis=1)\n","# dfstructure = dfstructure[~row_has_NaN].copy()\n","# print(dfstructure.shape)\n","dfstructure[row_has_NaN].head()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(457, 52)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["    Unnamed: 0                                   SOPInstanceUID  \\\n","66          66  1.3.12.2.1107.5.3.56.3575.11.202003231216470983   \n","67          67  1.3.12.2.1107.5.3.56.3575.11.202003231219100126   \n","68          68  1.3.12.2.1107.5.3.56.3575.11.202003231827560130   \n","69          69  1.3.12.2.1107.5.3.56.3575.11.202003241049480745   \n","70          70  1.3.12.2.1107.5.3.56.3575.11.202003241703070834   \n","\n","                                                 path  expired_30_days  \\\n","66  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","67  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","68  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","69  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","70  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","\n","    patient_id  age  MALE  vitals_temp_ed_first  vitals_sbp_ed_first  \\\n","66         NaN  NaN   NaN                   NaN                  NaN   \n","67         NaN  NaN   NaN                   NaN                  NaN   \n","68         NaN  NaN   NaN                   NaN                  NaN   \n","69         NaN  NaN   NaN                   NaN                  NaN   \n","70         NaN  NaN   NaN                   NaN                  NaN   \n","\n","    vitals_dbp_ed_first  ...  lab_lymphocyte  lab_leukocyte  lab_alt  lab_ast  \\\n","66                  NaN  ...             NaN            NaN      NaN      NaN   \n","67                  NaN  ...             NaN            NaN      NaN      NaN   \n","68                  NaN  ...             NaN            NaN      NaN      NaN   \n","69                  NaN  ...             NaN            NaN      NaN      NaN   \n","70                  NaN  ...             NaN            NaN      NaN      NaN   \n","\n","    lab_ddimer  lab_neutrophil_percentage  lab_crp  lab_hemoglobin  APview  \\\n","66         NaN                        NaN      NaN             NaN       0   \n","67         NaN                        NaN      NaN             NaN       0   \n","68         NaN                        NaN      NaN             NaN       0   \n","69         NaN                        NaN      NaN             NaN       0   \n","70         NaN                        NaN      NaN             NaN       0   \n","\n","                         bbox_coordinates  \n","66  [139, 29, 194, 184, 55, 70, 292, 286]  \n","67  [137, 29, 158, 144, 41, 73, 287, 224]  \n","68  [125, 29, 174, 166, 28, 44, 284, 256]  \n","69  [138, 18, 174, 139, 25, 47, 291, 230]  \n","70  [142, 29, 178, 148, 51, 57, 284, 233]  \n","\n","[5 rows x 52 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>SOPInstanceUID</th>\n","      <th>path</th>\n","      <th>expired_30_days</th>\n","      <th>patient_id</th>\n","      <th>age</th>\n","      <th>MALE</th>\n","      <th>vitals_temp_ed_first</th>\n","      <th>vitals_sbp_ed_first</th>\n","      <th>vitals_dbp_ed_first</th>\n","      <th>...</th>\n","      <th>lab_lymphocyte</th>\n","      <th>lab_leukocyte</th>\n","      <th>lab_alt</th>\n","      <th>lab_ast</th>\n","      <th>lab_ddimer</th>\n","      <th>lab_neutrophil_percentage</th>\n","      <th>lab_crp</th>\n","      <th>lab_hemoglobin</th>\n","      <th>APview</th>\n","      <th>bbox_coordinates</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>66</th>\n","      <td>66</td>\n","      <td>1.3.12.2.1107.5.3.56.3575.11.202003231216470983</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>[139, 29, 194, 184, 55, 70, 292, 286]</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>67</td>\n","      <td>1.3.12.2.1107.5.3.56.3575.11.202003231219100126</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>[137, 29, 158, 144, 41, 73, 287, 224]</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>68</td>\n","      <td>1.3.12.2.1107.5.3.56.3575.11.202003231827560130</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>[125, 29, 174, 166, 28, 44, 284, 256]</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>69</td>\n","      <td>1.3.12.2.1107.5.3.56.3575.11.202003241049480745</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>[138, 18, 174, 139, 25, 47, 291, 230]</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>70</td>\n","      <td>1.3.12.2.1107.5.3.56.3575.11.202003241703070834</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>[142, 29, 178, 148, 51, 57, 284, 233]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 52 columns</p>\n","</div>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Kguz1n29ttGE"},"source":["# now just have to put image, structured data and the label in the same tf records\n","# Adapted from: https://androidkt.com/feed-tfrecord-to-keras/\n","def get_augmented_paths(df,subdirname):\n","    df = df.copy()\n","    df['path'] = [x.replace('classified',subdirname) for x in df['path']]\n","    return df\n","\n","def prepare_structured_data(dfstructure, model_type, xfeatures, rseed, augment_bbox=False, train = True):\n","    if model_type in ['tab_model','fused_model']:\n","        # these are images with no structured data\n","        is_NaN = dfstructure.isnull() \n","        row_has_NaN = is_NaN.any(axis=1)\n","        dfstructure = dfstructure[~row_has_NaN].copy()\n","    # Shuffle the dataset so every batch likely has an expired case\n","    if train: \n","        dfstructure = dfstructure.sample(frac=1,random_state=rseed).reset_index(drop=True).copy()\n","        # hope 5x the images is still readable into ram..\n","        # different ways of augmenting the cxr images with the bboxes - preprocessed\n","        df1 = get_augmented_paths(dfstructure,'classified_bbox1') # trachea clear\n","        df2 = get_augmented_paths(dfstructure,'classified_bbox2') # trachea noise\n","        df3 = get_augmented_paths(dfstructure,'classified_bbox3') # trachea and background clear\n","        df4 = get_augmented_paths(dfstructure,'classified_bbox4') # trachea and background noise\n","        if augment_bbox == 'A': # only augmented images\n","            dfstructure = pd.concat([df1,df2,df3.df4],ignore_index=True).copy()\n","        elif augment_bbox == 'B': # original and augmented images\n","            dfstructure = pd.concat([dfstructure, df1,df2,df3,df4],ignore_index=True).copy() # plus original images\n","        dfstructure = dfstructure.sample(frac=1,random_state=rseed).reset_index(drop=True).copy()\n","    # must input for the files\n","    dfstructure.set_index('path',inplace=True)\n","    y_encoded = dfstructure.pop('expired_30_days') # derived from the filepaths for images in new_cxr_30 folder\n","    X = dfstructure[xfeatures].copy() # same header name\n","    # split to individual columns\n","    if ('bbox_coordinates' in dfstructure.columns.tolist())&(train==True):\n","        bbox_coord = dfstructure['bbox_coordinates'].apply(lambda x: pd.Series(x.replace('[','').replace(']','').split(',')))\n","        bbox_coord = bbox_coord.astype(float)\n","    else:\n","        bbox_coord = pd.DataFrame({'bbox_coordinates': [0]*len(X)})\n","    return X, y_encoded, bbox_coord\n","\n","def read_image_label_and_path(img_path):\n","    bits = tf.io.read_file(img_path)\n","    image = tf.image.decode_jpeg(bits, channels=1)\n","    image = tf.image.resize(image, [TARGET_SIZE, TARGET_SIZE])\n","    image = tf.cast(image, tf.float32) / 255.0\n","    label = tf.strings.split(img_path, sep='/')[4]\n","    return image, label, img_path\n","\n","def rearrange_structure_image_label_path(elements1, elements2):\n","    structured = tf.keras.backend.cast(elements1[0], dtype='float32') \n","    label_encoded = tf.keras.backend.cast(elements1[1], dtype='float32')  \n","    bbox_coord = tf.keras.backend.cast(elements1[2], dtype='int32')\n","    image = tf.keras.backend.cast(elements2[0], dtype='float32')\n","    label = elements2[1]\n","    img_path = elements2[2]\n","    return structured, image, label, label_encoded, img_path, bbox_coord\n","\n","\n","def data_loader_(dfstructure, model_type, xfeatures, rseed, augment_bbox=False, train = True):\n","    # read structure data with image path info. dfstructure's index is the path\n","    dfstructure, label_encoded, bbox_coord = prepare_structured_data(dfstructure, model_type\n","                                            , xfeatures, rseed, augment_bbox=augment_bbox, train=train)\n","    #print(dfstructure.values[0][0])\n","    # get structured data into tf dataset object\n","    dataset1 = tf.data.Dataset.from_tensor_slices((dfstructure.values, label_encoded.values, bbox_coord.values))\n","    # get image paths in the structured data index into tf dataset object\n","    paths = tf.data.Dataset.from_tensor_slices(dfstructure.index.tolist())\n","    # get image pixels and labels into tf dataset object\n","    dataset2 = paths.map(read_image_label_and_path, num_parallel_calls=AUTO)\n","    # Zip the structured, imagd, and label df dataset objects\n","    dataset = tf.data.Dataset.zip((dataset1, dataset2))\n","    # Rearrange the elements so it is easier to iterate downstream\n","    dataset = dataset.map(rearrange_structure_image_label_path, num_parallel_calls=AUTO)\n","    return dataset\n","\n","# bbox operations for numpy image array\n","def clear_bbox_(image,x1,y1,x2,y2):\n","    if len(image.shape)==3:\n","        image = image.squeeze()\n","        #image = tf.reshape(image, image.shape[:2])\n","    image[y1:y2, x1:x2] = 0\n","    return image\n","def keep_bbox_only_(image,x1,y1,x2,y2):\n","    if len(image.shape)==3:\n","        image = image.squeeze()\n","        #image = tf.reshape(image, image.shape[:2])\n","    image[:y1, :] = 0\n","    image[y2:, :] = 0\n","    image[:, :x1] = 0\n","    image[:, x2:] = 0\n","    return image\n","def replace_zero_Gaussian_(image, plot = False):\n","    if len(image.shape)==3:\n","        image = image.squeeze()\n","        #image = tf.reshape(image, image.shape[:2])\n","    image_shape = image.shape\n","    image_flattened = image.flatten()\n","    mean = np.mean(image_flattened)\n","    sigma = np.mean(image_flattened)\n","    noise = np.random.normal(mean,sigma,image_flattened.shape)\n","    noisy_image_flat = np.asarray([n if p == 0 else p for n,p in zip(noise, image_flattened)])\n","    noisy_image = np.reshape(noisy_image_flat, image_shape)\n","    return noisy_image\n","def bbox_augment_(image, bbox_coord):\n","    # image = img_to_array(image)\n","    #image = image.numpy()\n","    image_shape = image.shape\n","    if len(image.shape)==3:\n","        image = image.squeeze()\n","    #bbox_coord = bbox_coord.numpy().tolist()\n","    bbox_coord2 = bbox_coord.tolist()\n","    x1,y1,x2,y2,x12,y12,x22,y22 = bbox_coord2\n","    # randomly pick different bbox augmentation\n","    toss = random.uniform(0, 1)\n","    if toss > 0.5:\n","        image = clear_bbox_(image,x1, 0, x2, y2)\n","    toss = random.uniform(0, 1)\n","    if toss > 0.5:\n","        image = keep_bbox_only_(image, x12, y12, x22, y22)\n","    toss = random.uniform(0, 1)\n","    if toss > 0.5:\n","        image = replace_zero_Gaussian_(image)\n","    #image = array_to_img(image)\n","    # image = tf.convert_to_tensor(image, dtype=tf.float32)\n","    if len(image.shape)==2:\n","        image = np.reshape(image, image_shape)\n","    #     image = tf.reshape(image, image_shape)\n","    return image.astype('float32'), bbox_coord\n","# Wrap the bbox augment python function to make it compatible with `tf.data.Dataset.map`.\n","# https://stackoverflow.com/questions/60375717/how-to-convert-tensor-to-numpy-array-inside-a-map-function-using-tf-py-function\n","def eagarly_bbox_augment_(structured, image, label, label_encoded, img_path, bbox_coord):\n","    # print('Before')\n","    # print(type(image))\n","    # print(image.shape)\n","    # print(image)\n","    image_shape = image.get_shape()\n","    image, _ = tf.numpy_function(bbox_augment_, [image, bbox_coord], [tf.float32,tf.int32])\n","    image.set_shape(image_shape)\n","    # print('after')\n","    # print(type(image))\n","    # print(image.shape)\n","    # print(image)\n","    # print()\n","    return structured, image, label, label_encoded, img_path, bbox_coord\n","\n","# Augmentation \n","def data_augment_(structured, image, label, label_encoded, img_path, bbox_coord):\n","    image = tf.keras.preprocessing.image.random_rotation(image, 0) # only small degrees\n","    image = tf.image.random_flip_left_right(image) # images flipped vertically\n","    image = tf.image.random_brightness(image, 0, 0.05) # brightness changed in %\n","    return structured, image, label, label_encoded, img_path, bbox_coord\n","\n","# Different data loading wrapper for different model types\n","def load_data_structured(structured, image, label, label_encoded, img_path, bbox_coord):\n","    return structured, label_encoded\n","def load_data_image(structured, image, label, label_encoded, img_path, bbox_coord):\n","    return image, label_encoded\n","def load_data_multimodal(structured, image, label, label_encoded, img_path, bbox_coord):\n","    return (structured, image), label_encoded\n","\n","# # Data loader/iterator to call in train/tuning function -- on the fly bbox augment (requires eagarly execution on tpu which doesn't seem to work with colab)\n","# def get_augmented_batched_dataset_eagarly(dfstructure, xfeatures, model_type, batch_size, augment_bbox, rseed, train=True):\n","#     dataset = data_loader_(dfstructure, model_type, xfeatures, rseed, train = train)\n","#     dataset = dataset.cache() # This dataset fits in RAM\n","\n","#     # Augmentation for image and cxr model\n","#     if train:\n","#         # Best practices for Keras:\n","#         # Training dataset: repeat then batch\n","#         # Evaluation dataset: do not repeat\n","#         # shufflesize = len(dataset)\n","#         # print(shufflesize)\n","#         dataset = dataset.repeat()\n","#         # need to do the bbox augmentation before rotation/flipping image\n","#         print(type(dataset))\n","#         if augment_bbox:\n","#             dataset = dataset.map(eagarly_bbox_augment_, num_parallel_calls=AUTO)\n","#         else:\n","#             dataset = dataset.map(data_augment_ , num_parallel_calls=AUTO)\n","#         print(type(dataset))\n","#         dataset2 = dataset.map(data_augment_ , num_parallel_calls=AUTO)\n","#         dataset = dataset.concatenate(dataset2)\n","#         dataset = dataset.shuffle(256, seed=rseed, reshuffle_each_iteration=True)\n","#     if model_type == 'tab_model':\n","#         dataset = dataset.map(load_data_structured, num_parallel_calls=AUTO)\n","#     elif model_type =='cxr_model':\n","#         dataset = dataset.map(load_data_image, num_parallel_calls=AUTO)\n","#     elif model_type == 'fused_model':\n","#         print(model_type)\n","#         dataset = dataset.map(load_data_multimodal, num_parallel_calls=AUTO)\n","#     else:\n","#         print('Model type does not exist.')\n","#         return\n","\n","#     # batching\n","#     dataset = dataset.batch(batch_size)\n","#     dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","#     # should shuffle too but this dataset was well shuffled on disk already\n","#     return dataset\n","#     # source: Dataset performance guide: https://www.tensorflow.org/guide/performance/datasets\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_j6NM8XXzLyI"},"source":["# Data loader/iterator to call in train/tuning function -- with preprocessed augmented images, no eagarly/numpy execuations\n","def get_augmented_batched_dataset_(dfstructure, xfeatures, model_type, batch_size, augment_bbox, rseed, train=True):\n","    # Read in already augmented dataset\n","    dataset = data_loader_(dfstructure, model_type, xfeatures, rseed, augment_bbox=augment_bbox, train = train)\n","    dataset = dataset.cache() # This dataset fits in RAM\n","\n","    if train:\n","        # Best practices for Keras:\n","        # Training dataset: repeat then batch\n","        # Evaluation dataset: do not repeat\n","        # shufflesize = len(dataset)\n","        # print(shufflesize)\n","        dataset = dataset.repeat()\n","        # standard random flip and rotations augmentation\n","        dataset = dataset.map(data_augment_ , num_parallel_calls=AUTO)\n","        dataset2 = dataset.map(data_augment_ , num_parallel_calls=AUTO)\n","        dataset = dataset.concatenate(dataset2)\n","        dataset = dataset.shuffle(256, seed=rseed, reshuffle_each_iteration=True)\n","    if model_type == 'tab_model':\n","        dataset = dataset.map(load_data_structured, num_parallel_calls=AUTO)\n","    elif model_type =='cxr_model':\n","        dataset = dataset.map(load_data_image, num_parallel_calls=AUTO)\n","    elif model_type == 'fused_model':\n","        print(model_type)\n","        dataset = dataset.map(load_data_multimodal, num_parallel_calls=AUTO)\n","    # else:\n","    #     print('Model type does not exist.')\n","    #     return\n","\n","    # batching\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","    # should shuffle too but this dataset was well shuffled on disk already\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALgk3oI0ucL8"},"source":["# # Exporting tf records\n","# def recompress_image(structured, image, label, img_path):\n","#     image = tf.cast(image, tf.uint8)\n","#     image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n","#     return structured, image, label, img_path\n","\n","# def _bytestring_feature(list_of_bytestrings):\n","#     return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n","\n","# def _int_feature(list_of_ints): # int64\n","#     return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n","\n","# def _float_feature(list_of_floats): # float32\n","#     return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n","\n","# def to_tfrecord(structured, image, label, label_encoded, img_path):  \n","#     #class_num = np.argmax(np.array(CLASSES)==label) \n","#     feature = {\n","#         \"structured\": _float_feature([structured]),\n","#         \"image\": _bytestring_feature([img_bytes]), # one image in the list\n","#         \"class_encoded\": _int_feature([label_encoded]),        # one class in the list  \n","#         \"class_string\": _bytestring_feature([label]),\n","#         \"image_path\": _bytestring_feature([img_path]),\n","#     }\n","#     return tf.train.Example(features=tf.train.Features(feature=feature))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRb_4bxVSrqk"},"source":["### Testing dataloader"]},{"cell_type":"code","metadata":{"id":"PdHFmwQl1qt4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391610808,"user_tz":-60,"elapsed":14897,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"48f089bc-2a40-420a-c78b-46745555be08"},"source":["# import tensorflow as tf\n","# import numpy as np\n","# Checking\n","AUGMENT_BBOX = 'B' \n","structured_path = 'gs://new_cxr_30/split/train_structured.csv'\n","dfstructure = pd.read_csv(structured_path)\n","dataset_batched = get_augmented_batched_dataset_(dfstructure, XFEATURES, 'fused_model', 32, AUGMENT_BBOX, 42)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fused_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a4frCkaNg__p"},"source":["# https://github.com/tensorflow/tensorflow/issues/43037\n","# There may be problem if initialize the TPU first, and then dataset later.\n","# Same code but sometimes for no reason have google sdk related access issues i think\n","# Just restart runtime and try again.\n","# If this line works, then training later should and vice versa\n","structure_image_batch, label_batch = next(iter(dataset_batched))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSM4eiRa8aQZ"},"source":["def show_batch(image_batch, label_batch):\n","    plt.figure(figsize=(10, 10))\n","    for n in range(25):\n","        ax = plt.subplot(7, 5, n + 1)\n","        plt.imshow(tf.reshape(image_batch[n],[TARGET_SIZE,TARGET_SIZE]), cmap='gray')\n","        if label_batch[n] == 1:\n","            plt.title(\"EXPIRED\")\n","        else:\n","            plt.title(\"ALIVE\")\n","        plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"49KXlRgcBRWz","colab":{"base_uri":"https://localhost:8080/","height":431},"executionInfo":{"status":"ok","timestamp":1615391616264,"user_tz":-60,"elapsed":20312,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"ff2ae65a-e747-407e-8cab-1f6a970d7d17"},"source":["structure_batch, image_batch = structure_image_batch\n","show_batch(image_batch, label_batch)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 25 Axes>"],"image/png":"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\n"},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"sX_SBAdQBhId"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"8w3bkT_XqI-f"},"source":["def calculate_f1(precision,recall):\n","    if precision+recall != 0:\n","        return 2*(precision*recall)/(precision+recall)\n","    else:\n","        return 0 #close to 0\n","\n","#adapted from https://keras.io/examples/vision/xray_classification_with_tpus/\n","def visualize(history, outpath=None):\n","    metrics = [\"loss\",\"precision\", \"recall\", \"accuracy\", \"auc\",\"f1\"]\n","    fig, ax = plt.subplots(1, len(metrics), figsize=(25, 5))\n","    ax = ax.ravel()\n","\n","    if outpath:\n","        fig.suptitle(outpath.split('/')[-1])\n","\n","    for i, met in enumerate(metrics):\n","        ax[i].plot(history[met])\n","        ax[i].plot(history[\"val_\" + met])\n","        ax[i].set_title(\"Model {}\".format(met))\n","        ax[i].set_xlabel(\"epochs\")\n","        ax[i].set_ylabel(met)\n","        ax[i].legend([\"train\", \"val\"])\n","    \n","    if outpath:\n","        plt.savefig(outpath)\n","\n","\n","# #https://keras.io/examples/vision/xray_classification_with_tpus/\n","# def visualize(history):\n","#     fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n","#     ax = ax.ravel()\n","\n","#     for i, met in enumerate([\"precision\", \"recall\", \"binary_accuracy\", \"loss\"]):\n","#         ax[i].plot(history.history[met])\n","#         ax[i].plot(history.history[\"val_\" + met])\n","#         ax[i].set_title(\"Model {}\".format(met))\n","#         ax[i].set_xlabel(\"epochs\")\n","#         ax[i].set_ylabel(met)\n","#         ax[i].legend([\"train\", \"val\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y42o-2EfcSup"},"source":["def plot_history(results, history,params,extension='.pdf'):\n","    # results = ta_object.data\n","    # history = ta_object.round_history\n","    # params = ['augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', \n","    #    'output_bias', 'pretrained_feature_layer','class_weight']\n","    for i in results.index:\n","        fname = []\n","        for p in params:\n","            v = results.loc[i,p]\n","            if type(v)==float: v=round(v,4)\n","            fname.append(p+str(v))\n","        fname = '_'.join(fname)+extension\n","        fname = fname.replace(':','|').replace('{','|').replace('}','|')\n","        fpath= os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/figures',fname)\n","        visualize(history[i], outpath=fpath)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuSWE1kd-xvn"},"source":["# transfer learning from MIMIC -- loading to this notebook\n","def download_from_gcs(gcs_path, local_path):\n","  with tf.io.gfile.GFile(gcs_path, 'rb') as gcs_file:\n","    with tf.io.gfile.GFile(local_path, 'wb') as local_file:\n","      local_file.write(gcs_file.read())\n","\n","# def load_base_model(PRETRAINED_KERAS_MODEL, compile = False, return_model=False):\n","#     #PRETRAINED_KERAS_MODEL = 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5' # trained on MIMIC CXR to identify CheXpert 14 labels\n","#     download_from_gcs(PRETRAINED_KERAS_MODEL, 'pretrained_model.h5')\n","#     if return_model:\n","#         if 'weights' in PRETRAINED_KERAS_MODEL:\n","#             orig_model = tf.keras.applications.DenseNet121(include_top=False)\n","#             orig_model.load_weights('pretrained_model.h5')\n","#             dim1, dim2, channel = orig_model.input.shape\n","#             dense_input = tf.keras.layers.Input(shape=(dim1,dim2, 1))\n","#             dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_input)\n","#             output = orig_model(dense_filter)\n","#             model = tf.keras.Model(dense_input, output)\n","#         else:\n","#             model = tf.keras.models.load_model('pretrained_model.h5', compile=compile)\n","#         return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQRCif_igLJF"},"source":["# Saving files to gcs\n","def copy_file_to_gcs(job_dir, file_path):\n","    with file_io.FileIO(file_path, mode='rb') as input_f:\n","        with file_io.FileIO(os.path.join(job_dir, file_path), mode='wb+') as output_f:\n","            output_f.write(input_f.read())\n","\n","def save_jpg_image(image, fname):\n","    with tf.compat.v1.Session() as sess:\n","        if len(image.shape)==2:\n","            image = np.expand_dims(image, axis=-1)\n","        enc = tf.image.encode_jpeg(image)\n","        fwrite = tf.io.write_file(tf.constant(fname), enc)\n","        result = sess.run(fwrite)\n","\n","def export_to_gcs(f, filename, exportdir):\n","    if not os.path.isdir(exportdir):\n","        os.makedirs(exportdir)\n","    copy = True\n","    if filename[-4:] == '.csv':\n","        f.to_csv(filename, index=False)\n","    elif filename[-4:] == '.txt':\n","        f.to_csv(filename, sep='\\t', index=False)\n","    elif filename[-3:] == '.h5':\n","        f.save(filename)\n","    elif filename[-4:] == '.jpg':\n","        save_jpg_image(f, filename)\n","        copy = False\n","    else:\n","        copy = False\n","    if copy:\n","        copy_file_to_gcs(exportdir, filename)\n","\n","def get_best_model(scan_results, metric):\n","    tf.keras.backend.clear_session()\n","    model_id = scan_results.data[metric].astype('float').argmax() - 1\n","    model = model_from_json(scan_results.saved_models[model_id])\n","    model.set_weights(scan_results.saved_weights[model_id])\n","    return model\n","\n","# # e.g.\n","# bbox_clean224.to_csv('bboxes_cleaned_224x224_plus_original.csv', index=False)\n","# copy_file_to_gcs('gs://new_cxr_30/bboxes/','bboxes_cleaned_224x224_plus_original.csv')\n","# bbox_clean320.to_csv('bboxes_cleaned_320x320_plus_original.csv', index=False)\n","# copy_file_to_gcs('gs://new_cxr_30/bboxes/','bboxes_cleaned_320x320_plus_original.csv')\n","# bboxes320_for_augment.to_csv('bboxes_cleaned_320x320_for_augment.csv', index=False)\n","# copy_file_to_gcs('gs://new_cxr_30/bboxes/','bboxes_cleaned_320x320_for_augment.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ivebk9A5vhd_"},"source":["## Define structure/tabular model"]},{"cell_type":"code","metadata":{"id":"9DfwomJfrkwa"},"source":["# Model that uses structured data only for prediction\n","class TabularModel(tf.keras.Model):\n","\n","  def __init__(self, input_dim, drop_out, out_dim=128, combine = False, train=True):\n","    super(TabularModel, self).__init__()\n","    self.train = train\n","    self.combine = combine\n","    self.norm1 =  tf.keras.layers.BatchNormalization(axis=1)\n","    self.dense0 = tf.keras.layers.Dense(input_dim, activation='relu')\n","    self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n","    # drop out earlier might deal with potential missing values\n","    self.drop1 = tf.keras.layers.Dropout(drop_out)\n","    self.dense2 = tf.keras.layers.Dense(out_dim, activation='relu', name = 'dense128')\n","    if not combine:\n","        # binary prediction from structured data alone\n","        self.pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_tab\")\n","\n","  def call(self, inputs):\n","    x = self.norm1(inputs)\n","    x = self.dense0(x)\n","    x = self.dense1(x)\n","    x = self.drop1(x, training=self.train)\n","    x = self.dense2(x)\n","    if self.combine:\n","        return x\n","    else:\n","        return self.pred(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0665I8FOY_Wm"},"source":["def TabularModel_functional(input_dim, drop_out, out_dim=128, output_bias = None, combine = False):\n","    inputs = tf.keras.Input(shape=(input_dim,), name = 'tab_input')\n","    x = tf.keras.layers.BatchNormalization()(inputs) # see if helps or not\n","    x = tf.keras.layers.Dense(input_dim, activation='relu')(x)\n","    x = tf.keras.layers.Dense(64, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(drop_out)(x)\n","    out = tf.keras.layers.Dense(out_dim, activation='relu', name = 'dense128')(x)\n","    if not combine:\n","        output_bias = tf.keras.initializers.Constant(output_bias)\n","        pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_tab\", bias_initializer=output_bias)(out)\n","        model = tf.keras.Model(inputs=inputs, outputs=pred)\n","    # for fusion\n","    else:\n","        model = tf.keras.Model(inputs=inputs, outputs=out)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hoGSSX9gvpGb"},"source":["## Define CXR image only model"]},{"cell_type":"code","metadata":{"id":"PF1eF9FxYsiM"},"source":["# Model that uses only CXR image for prediction -- shoud be same as what Po-Chi did before if combine =False\n","class CXRModel(tf.keras.Model):\n","\n","  def __init__(self, drop_out, layers_not_trainable, out_dim=128, combine = False, train=True):\n","    super(CXRModel, self).__init__()\n","    self.train = train\n","    self.combine = combine\n","    base = tf.keras.models.load_model('pretrained_model.h5', compile=False)\n","    # Setting earlier layers not trainable\n","    for layer in base.layers[:layers_not_trainable]: # this can possibly be tuned\n","        layer.trainable=False  \n","    self.base_model = tf.keras.Model(inputs=base.input, outputs=base.layers[-2].output)\n","    # binary prediction from cxr alone\n","    if not combine:\n","        self.pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_cxr\")\n","    else:\n","        # Additional layers before concatenation with structured so more similar feature sizes\n","        # self.dense512 = tf.keras.layers.Dense(512, activation = 'relu', name=\"dense512\")\n","        # self.drop1 = tf.keras.layers.Dropout(drop_out) \n","        self.dense = tf.keras.layers.Dense(out_dim, activation = 'relu', name=\"dense\"+str(out_dim))\n","\n","  def call(self, inputs):\n","    x = self.base_model(inputs)\n","    if not self.combine:\n","        return self.pred(x)\n","    else:\n","        # x = self.dense512(x)\n","        # x = self.drop1(x, training=self.train)\n","        x = self.dense(x)\n","        return x\n","\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dccp3yG8lRc7"},"source":["#adapted from\n","import importlib\n","# from keras.layers import Input\n","# from keras.layers.core import Dense\n","# from keras.models import Model\n","\n","class ModelFactory:\n","    \"\"\"\n","    Model facotry for Keras default models\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.models_ = dict(\n","            VGG16=dict(\n","                input_shape=(224, 224, 3),\n","                module_name=\"vgg16\",\n","                last_conv_layer=\"block5_conv3\",\n","            ),\n","            VGG19=dict(\n","                input_shape=(224, 224, 3),\n","                module_name=\"vgg19\",\n","                last_conv_layer=\"block5_conv4\",\n","            ),\n","            DenseNet121=dict(\n","                input_shape=(224, 224, 3),\n","                module_name=\"densenet\",\n","                last_conv_layer=\"bn\",\n","            ),\n","            ResNet50=dict(\n","                input_shape=(224, 224, 3),\n","                module_name=\"resnet50\",\n","                last_conv_layer=\"activation_49\",\n","            ),\n","            InceptionV3=dict(\n","                input_shape=(299, 299, 3),\n","                module_name=\"inception_v3\",\n","                last_conv_layer=\"mixed10\",\n","            ),\n","            InceptionResNetV2=dict(\n","                input_shape=(299, 299, 3),\n","                module_name=\"inception_resnet_v2\",\n","                last_conv_layer=\"conv_7b_ac\",\n","            ),\n","            NASNetMobile=dict(\n","                input_shape=(224, 224, 3),\n","                module_name=\"nasnet\",\n","                last_conv_layer=\"activation_188\",\n","            ),\n","            NASNetLarge=dict(\n","                input_shape=(331, 331, 3),\n","                module_name=\"nasnet\",\n","                last_conv_layer=\"activation_260\",\n","            ),\n","        )\n","\n","    def get_last_conv_layer(self, model_name):\n","        return self.models_[model_name][\"last_conv_layer\"]\n","\n","    def get_input_size(self, model_name):\n","        return self.models_[model_name][\"input_shape\"][:2]\n","\n","    def get_model(self, class_num, model_name=\"DenseNet121\", use_base_weights=True,\n","                  weights_path=None, input_shape=None):\n","\n","        if use_base_weights is True:\n","            base_weights = \"imagenet\"\n","        else:\n","            base_weights = None\n","\n","        base_model_class = getattr(\n","            importlib.import_module(\n","                f\"keras.applications.{self.models_[model_name]['module_name']}\"\n","            ),\n","            model_name)\n","\n","        if input_shape is None:\n","            input_shape = self.models_[model_name][\"input_shape\"]\n","\n","        img_input = tf.keras.layers.Input(shape=input_shape)\n","\n","        base_model = base_model_class(\n","            include_top=False,\n","            input_tensor=img_input,\n","            input_shape=input_shape,\n","            weights=base_weights,\n","            pooling=\"avg\")\n","        x = base_model.output\n","        predictions = tf.keras.layers.Dense(class_num, activation=\"sigmoid\", name=\"predictions\")(x)\n","        model = tf.keras.models.Model(inputs=img_input, outputs=predictions)\n","\n","        if weights_path == \"\":\n","            weights_path = None\n","\n","        if weights_path is not None:\n","            print(f\"load model weights_path: {weights_path}\")\n","            model.load_weights(weights_path)\n","        return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ou7EdiWELLsw"},"source":["def load_base_model(PRETRAINED_KERAS_MODEL, compile = False, return_model=True):\n","    #PRETRAINED_KERAS_MODEL = 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5' # trained on MIMIC CXR to identify CheXpert 14 labels\n","    local_fname = PRETRAINED_KERAS_MODEL.split('/')[-1]\n","    if not tf.io.gfile.exists(local_fname):\n","        print('download file from GCS')\n","        download_from_gcs(PRETRAINED_KERAS_MODEL, local_fname)\n","    if return_model:\n","        if 'weights' in PRETRAINED_KERAS_MODEL:\n","            factory = ModelFactory()\n","            model = factory.get_model(class_num = 14\n","                                    , weights_path = local_fname)\n","        else:\n","            model = tf.keras.models.load_model(local_fname, compile=compile)\n","        return model\n","\n","def change_model_input_layer(orig_model, channel_num=1):\n","    #print(orig_model.input.shape)\n","    orig_shape = orig_model.input.shape\n","    dense_input = tf.keras.layers.Input(shape=(orig_shape[1],orig_shape[2], channel_num))\n","    dense_filter = tf.keras.layers.Conv2D(3, 3, padding='same')(dense_input)\n","    output = orig_model(dense_filter)\n","    model = tf.keras.Model(dense_input, output)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fHHvqTL9i_4"},"source":["def CXRModel_functional(base_model, drop_out, layers_not_trainable, pretrained_feature_layer = -2\n","                        , hidden_dims = None, output_bias = None, combine = False):\n","    #base = tf.keras.models.load_model('pretrained_model.h5', compile=False)\n","    for layer in base_model.layers[:layers_not_trainable]: # this can possibly be tuned\n","        layer.trainable=False  \n","    # feature layer\n","    x = base_model.layers[pretrained_feature_layer].output # batchnorm layer after convolutions and before relu activation\n","    # Global pooling after conv feature layers if required\n","    if pretrained_feature_layer < -2:\n","        # so many 0s with base model's ReLU layer\n","        x = tf.keras.layers.LeakyReLU()(x)\n","        # Max pooling more discriminative than average pooling\n","        x = tf.keras.layers.GlobalMaxPooling2D()(x)\n","    # Hidden dense layer(s)\n","    if hidden_dims != None:\n","        for i, dim in enumerate(hidden_dims):\n","            a = tf.keras.layers.LeakyReLU()(x)\n","            x = tf.keras.layers.Dense(dim, name=\"dense\"+str(i)+\"_\"+str(dim))(a)\n","    # x = tf.keras.layers.LeakyReLU()(x)\n","    # out = tf.keras.layers.Dense(out_dim, name=\"dense_out\"+str(out_dim))(x)\n","    # not sure if this dropout layer is helpful or not\n","    out = tf.keras.layers.Dropout(drop_out)(x)\n","    if not combine: \n","        if output_bias != None:\n","            output_bias = tf.keras.initializers.Constant(output_bias)\n","            pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_cxr\", bias_initializer=output_bias)(out)\n","        else:\n","            pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_cxr\")(out)\n","        model = tf.keras.Model(inputs=base_model.input, outputs=pred)\n","    # for fusion\n","    else:\n","        model = tf.keras.Model(inputs=base_model.input, outputs=out)\n","    if model.input.shape[-1] == 3:\n","        model = change_model_input_layer(model)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ja2LgiQnSm3F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391618215,"user_tz":-60,"elapsed":22144,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"b21e7348-ba89-4ace-8fc5-f7f17da53b41"},"source":["model_teacher = 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5'\n","base_model = load_base_model(model_teacher, return_model=True)\n","# base_model.summary()\n","\n","CXRmodel = CXRModel_functional(base_model, 0.1, 355,hidden_dims=[128,64])\n","CXRmodel.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 320, 320, 1) 0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 326, 326, 1)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1/conv (Conv2D)             (None, 160, 160, 64) 3136        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","conv1/bn (BatchNormalization)   (None, 160, 160, 64) 256         conv1/conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1/relu (Activation)         (None, 160, 160, 64) 0           conv1/bn[0][0]                   \n","__________________________________________________________________________________________________\n","zero_padding2d_1 (ZeroPadding2D (None, 162, 162, 64) 0           conv1/relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1 (MaxPooling2D)            (None, 80, 80, 64)   0           zero_padding2d_1[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 80, 80, 64)   256         pool1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2_block1_0_relu (Activation (None, 80, 80, 64)   0           conv2_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 80, 80, 128)  8192        conv2_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 80, 80, 128)  0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_concat (Concatenat (None, 80, 80, 96)   0           pool1[0][0]                      \n","                                                                 conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_bn (BatchNormali (None, 80, 80, 96)   384         conv2_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_0_relu (Activation (None, 80, 80, 96)   0           conv2_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 80, 80, 128)  12288       conv2_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 80, 80, 128)  0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_concat (Concatenat (None, 80, 80, 128)  0           conv2_block1_concat[0][0]        \n","                                                                 conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_0_relu (Activation (None, 80, 80, 128)  0           conv2_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 80, 80, 128)  16384       conv2_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 80, 80, 128)  0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_concat (Concatenat (None, 80, 80, 160)  0           conv2_block2_concat[0][0]        \n","                                                                 conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_bn (BatchNormali (None, 80, 80, 160)  640         conv2_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_0_relu (Activation (None, 80, 80, 160)  0           conv2_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_1_conv (Conv2D)    (None, 80, 80, 128)  20480       conv2_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_1_relu (Activation (None, 80, 80, 128)  0           conv2_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block4_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block4_concat (Concatenat (None, 80, 80, 192)  0           conv2_block3_concat[0][0]        \n","                                                                 conv2_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_bn (BatchNormali (None, 80, 80, 192)  768         conv2_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_0_relu (Activation (None, 80, 80, 192)  0           conv2_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_1_conv (Conv2D)    (None, 80, 80, 128)  24576       conv2_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_1_relu (Activation (None, 80, 80, 128)  0           conv2_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block5_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block5_concat (Concatenat (None, 80, 80, 224)  0           conv2_block4_concat[0][0]        \n","                                                                 conv2_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_bn (BatchNormali (None, 80, 80, 224)  896         conv2_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_0_relu (Activation (None, 80, 80, 224)  0           conv2_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_1_conv (Conv2D)    (None, 80, 80, 128)  28672       conv2_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_bn (BatchNormali (None, 80, 80, 128)  512         conv2_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_1_relu (Activation (None, 80, 80, 128)  0           conv2_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block6_2_conv (Conv2D)    (None, 80, 80, 32)   36864       conv2_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block6_concat (Concatenat (None, 80, 80, 256)  0           conv2_block5_concat[0][0]        \n","                                                                 conv2_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","pool2_bn (BatchNormalization)   (None, 80, 80, 256)  1024        conv2_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","pool2_relu (Activation)         (None, 80, 80, 256)  0           pool2_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool2_conv (Conv2D)             (None, 80, 80, 128)  32768       pool2_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool2_pool (AveragePooling2D)   (None, 40, 40, 128)  0           pool2_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 40, 40, 128)  512         pool2_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv3_block1_0_relu (Activation (None, 40, 40, 128)  0           conv3_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 40, 40, 128)  16384       conv3_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 40, 40, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_concat (Concatenat (None, 40, 40, 160)  0           pool2_pool[0][0]                 \n","                                                                 conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_bn (BatchNormali (None, 40, 40, 160)  640         conv3_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_0_relu (Activation (None, 40, 40, 160)  0           conv3_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 40, 40, 128)  20480       conv3_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 40, 40, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_concat (Concatenat (None, 40, 40, 192)  0           conv3_block1_concat[0][0]        \n","                                                                 conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_bn (BatchNormali (None, 40, 40, 192)  768         conv3_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_0_relu (Activation (None, 40, 40, 192)  0           conv3_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 40, 40, 128)  24576       conv3_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 40, 40, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_concat (Concatenat (None, 40, 40, 224)  0           conv3_block2_concat[0][0]        \n","                                                                 conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_bn (BatchNormali (None, 40, 40, 224)  896         conv3_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_0_relu (Activation (None, 40, 40, 224)  0           conv3_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 40, 40, 128)  28672       conv3_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 40, 40, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_concat (Concatenat (None, 40, 40, 256)  0           conv3_block3_concat[0][0]        \n","                                                                 conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_bn (BatchNormali (None, 40, 40, 256)  1024        conv3_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_0_relu (Activation (None, 40, 40, 256)  0           conv3_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_1_conv (Conv2D)    (None, 40, 40, 128)  32768       conv3_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_1_relu (Activation (None, 40, 40, 128)  0           conv3_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block5_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block5_concat (Concatenat (None, 40, 40, 288)  0           conv3_block4_concat[0][0]        \n","                                                                 conv3_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_bn (BatchNormali (None, 40, 40, 288)  1152        conv3_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_0_relu (Activation (None, 40, 40, 288)  0           conv3_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_1_conv (Conv2D)    (None, 40, 40, 128)  36864       conv3_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_1_relu (Activation (None, 40, 40, 128)  0           conv3_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block6_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block6_concat (Concatenat (None, 40, 40, 320)  0           conv3_block5_concat[0][0]        \n","                                                                 conv3_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_bn (BatchNormali (None, 40, 40, 320)  1280        conv3_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_0_relu (Activation (None, 40, 40, 320)  0           conv3_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_1_conv (Conv2D)    (None, 40, 40, 128)  40960       conv3_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_1_relu (Activation (None, 40, 40, 128)  0           conv3_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block7_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block7_concat (Concatenat (None, 40, 40, 352)  0           conv3_block6_concat[0][0]        \n","                                                                 conv3_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_bn (BatchNormali (None, 40, 40, 352)  1408        conv3_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_0_relu (Activation (None, 40, 40, 352)  0           conv3_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_1_conv (Conv2D)    (None, 40, 40, 128)  45056       conv3_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_1_relu (Activation (None, 40, 40, 128)  0           conv3_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block8_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block8_concat (Concatenat (None, 40, 40, 384)  0           conv3_block7_concat[0][0]        \n","                                                                 conv3_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_bn (BatchNormali (None, 40, 40, 384)  1536        conv3_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_0_relu (Activation (None, 40, 40, 384)  0           conv3_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_1_conv (Conv2D)    (None, 40, 40, 128)  49152       conv3_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_bn (BatchNormali (None, 40, 40, 128)  512         conv3_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_1_relu (Activation (None, 40, 40, 128)  0           conv3_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block9_2_conv (Conv2D)    (None, 40, 40, 32)   36864       conv3_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block9_concat (Concatenat (None, 40, 40, 416)  0           conv3_block8_concat[0][0]        \n","                                                                 conv3_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_bn (BatchNormal (None, 40, 40, 416)  1664        conv3_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block10_0_relu (Activatio (None, 40, 40, 416)  0           conv3_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_1_conv (Conv2D)   (None, 40, 40, 128)  53248       conv3_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_bn (BatchNormal (None, 40, 40, 128)  512         conv3_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_1_relu (Activatio (None, 40, 40, 128)  0           conv3_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block10_2_conv (Conv2D)   (None, 40, 40, 32)   36864       conv3_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block10_concat (Concatena (None, 40, 40, 448)  0           conv3_block9_concat[0][0]        \n","                                                                 conv3_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_bn (BatchNormal (None, 40, 40, 448)  1792        conv3_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_0_relu (Activatio (None, 40, 40, 448)  0           conv3_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_1_conv (Conv2D)   (None, 40, 40, 128)  57344       conv3_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_bn (BatchNormal (None, 40, 40, 128)  512         conv3_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_1_relu (Activatio (None, 40, 40, 128)  0           conv3_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block11_2_conv (Conv2D)   (None, 40, 40, 32)   36864       conv3_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block11_concat (Concatena (None, 40, 40, 480)  0           conv3_block10_concat[0][0]       \n","                                                                 conv3_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_bn (BatchNormal (None, 40, 40, 480)  1920        conv3_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_0_relu (Activatio (None, 40, 40, 480)  0           conv3_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_1_conv (Conv2D)   (None, 40, 40, 128)  61440       conv3_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_bn (BatchNormal (None, 40, 40, 128)  512         conv3_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_1_relu (Activatio (None, 40, 40, 128)  0           conv3_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv3_block12_2_conv (Conv2D)   (None, 40, 40, 32)   36864       conv3_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv3_block12_concat (Concatena (None, 40, 40, 512)  0           conv3_block11_concat[0][0]       \n","                                                                 conv3_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool3_bn (BatchNormalization)   (None, 40, 40, 512)  2048        conv3_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool3_relu (Activation)         (None, 40, 40, 512)  0           pool3_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool3_conv (Conv2D)             (None, 40, 40, 256)  131072      pool3_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool3_pool (AveragePooling2D)   (None, 20, 20, 256)  0           pool3_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 20, 20, 256)  1024        pool3_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv4_block1_0_relu (Activation (None, 20, 20, 256)  0           conv4_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 20, 20, 128)  32768       conv4_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 20, 20, 128)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_concat (Concatenat (None, 20, 20, 288)  0           pool3_pool[0][0]                 \n","                                                                 conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_bn (BatchNormali (None, 20, 20, 288)  1152        conv4_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_0_relu (Activation (None, 20, 20, 288)  0           conv4_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 20, 20, 128)  36864       conv4_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 20, 20, 128)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_concat (Concatenat (None, 20, 20, 320)  0           conv4_block1_concat[0][0]        \n","                                                                 conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_bn (BatchNormali (None, 20, 20, 320)  1280        conv4_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_0_relu (Activation (None, 20, 20, 320)  0           conv4_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 20, 20, 128)  40960       conv4_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 20, 20, 128)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_concat (Concatenat (None, 20, 20, 352)  0           conv4_block2_concat[0][0]        \n","                                                                 conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_bn (BatchNormali (None, 20, 20, 352)  1408        conv4_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_0_relu (Activation (None, 20, 20, 352)  0           conv4_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 20, 20, 128)  45056       conv4_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 20, 20, 128)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_concat (Concatenat (None, 20, 20, 384)  0           conv4_block3_concat[0][0]        \n","                                                                 conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_bn (BatchNormali (None, 20, 20, 384)  1536        conv4_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_0_relu (Activation (None, 20, 20, 384)  0           conv4_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 20, 20, 128)  49152       conv4_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 20, 20, 128)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_concat (Concatenat (None, 20, 20, 416)  0           conv4_block4_concat[0][0]        \n","                                                                 conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_bn (BatchNormali (None, 20, 20, 416)  1664        conv4_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_0_relu (Activation (None, 20, 20, 416)  0           conv4_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 20, 20, 128)  53248       conv4_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 20, 20, 128)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_concat (Concatenat (None, 20, 20, 448)  0           conv4_block5_concat[0][0]        \n","                                                                 conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_bn (BatchNormali (None, 20, 20, 448)  1792        conv4_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_0_relu (Activation (None, 20, 20, 448)  0           conv4_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_1_conv (Conv2D)    (None, 20, 20, 128)  57344       conv4_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_1_relu (Activation (None, 20, 20, 128)  0           conv4_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block7_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block7_concat (Concatenat (None, 20, 20, 480)  0           conv4_block6_concat[0][0]        \n","                                                                 conv4_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_bn (BatchNormali (None, 20, 20, 480)  1920        conv4_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_0_relu (Activation (None, 20, 20, 480)  0           conv4_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_1_conv (Conv2D)    (None, 20, 20, 128)  61440       conv4_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_1_relu (Activation (None, 20, 20, 128)  0           conv4_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block8_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block8_concat (Concatenat (None, 20, 20, 512)  0           conv4_block7_concat[0][0]        \n","                                                                 conv4_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_bn (BatchNormali (None, 20, 20, 512)  2048        conv4_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_0_relu (Activation (None, 20, 20, 512)  0           conv4_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_1_conv (Conv2D)    (None, 20, 20, 128)  65536       conv4_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_bn (BatchNormali (None, 20, 20, 128)  512         conv4_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_1_relu (Activation (None, 20, 20, 128)  0           conv4_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block9_2_conv (Conv2D)    (None, 20, 20, 32)   36864       conv4_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block9_concat (Concatenat (None, 20, 20, 544)  0           conv4_block8_concat[0][0]        \n","                                                                 conv4_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_bn (BatchNormal (None, 20, 20, 544)  2176        conv4_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block10_0_relu (Activatio (None, 20, 20, 544)  0           conv4_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_1_conv (Conv2D)   (None, 20, 20, 128)  69632       conv4_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block10_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block10_concat (Concatena (None, 20, 20, 576)  0           conv4_block9_concat[0][0]        \n","                                                                 conv4_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_bn (BatchNormal (None, 20, 20, 576)  2304        conv4_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_0_relu (Activatio (None, 20, 20, 576)  0           conv4_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_1_conv (Conv2D)   (None, 20, 20, 128)  73728       conv4_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block11_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block11_concat (Concatena (None, 20, 20, 608)  0           conv4_block10_concat[0][0]       \n","                                                                 conv4_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_bn (BatchNormal (None, 20, 20, 608)  2432        conv4_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_0_relu (Activatio (None, 20, 20, 608)  0           conv4_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_1_conv (Conv2D)   (None, 20, 20, 128)  77824       conv4_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block12_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block12_concat (Concatena (None, 20, 20, 640)  0           conv4_block11_concat[0][0]       \n","                                                                 conv4_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_bn (BatchNormal (None, 20, 20, 640)  2560        conv4_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_0_relu (Activatio (None, 20, 20, 640)  0           conv4_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_1_conv (Conv2D)   (None, 20, 20, 128)  81920       conv4_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block13_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block13_concat (Concatena (None, 20, 20, 672)  0           conv4_block12_concat[0][0]       \n","                                                                 conv4_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_bn (BatchNormal (None, 20, 20, 672)  2688        conv4_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_0_relu (Activatio (None, 20, 20, 672)  0           conv4_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_1_conv (Conv2D)   (None, 20, 20, 128)  86016       conv4_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block14_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block14_concat (Concatena (None, 20, 20, 704)  0           conv4_block13_concat[0][0]       \n","                                                                 conv4_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_bn (BatchNormal (None, 20, 20, 704)  2816        conv4_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_0_relu (Activatio (None, 20, 20, 704)  0           conv4_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_1_conv (Conv2D)   (None, 20, 20, 128)  90112       conv4_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block15_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block15_concat (Concatena (None, 20, 20, 736)  0           conv4_block14_concat[0][0]       \n","                                                                 conv4_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_bn (BatchNormal (None, 20, 20, 736)  2944        conv4_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_0_relu (Activatio (None, 20, 20, 736)  0           conv4_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_1_conv (Conv2D)   (None, 20, 20, 128)  94208       conv4_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block16_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block16_concat (Concatena (None, 20, 20, 768)  0           conv4_block15_concat[0][0]       \n","                                                                 conv4_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_bn (BatchNormal (None, 20, 20, 768)  3072        conv4_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_0_relu (Activatio (None, 20, 20, 768)  0           conv4_block17_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_1_conv (Conv2D)   (None, 20, 20, 128)  98304       conv4_block17_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block17_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block17_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block17_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block17_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block17_concat (Concatena (None, 20, 20, 800)  0           conv4_block16_concat[0][0]       \n","                                                                 conv4_block17_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_bn (BatchNormal (None, 20, 20, 800)  3200        conv4_block17_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_0_relu (Activatio (None, 20, 20, 800)  0           conv4_block18_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_1_conv (Conv2D)   (None, 20, 20, 128)  102400      conv4_block18_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block18_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block18_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block18_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block18_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block18_concat (Concatena (None, 20, 20, 832)  0           conv4_block17_concat[0][0]       \n","                                                                 conv4_block18_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_bn (BatchNormal (None, 20, 20, 832)  3328        conv4_block18_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_0_relu (Activatio (None, 20, 20, 832)  0           conv4_block19_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_1_conv (Conv2D)   (None, 20, 20, 128)  106496      conv4_block19_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block19_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block19_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block19_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block19_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block19_concat (Concatena (None, 20, 20, 864)  0           conv4_block18_concat[0][0]       \n","                                                                 conv4_block19_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_bn (BatchNormal (None, 20, 20, 864)  3456        conv4_block19_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_0_relu (Activatio (None, 20, 20, 864)  0           conv4_block20_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_1_conv (Conv2D)   (None, 20, 20, 128)  110592      conv4_block20_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block20_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block20_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block20_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block20_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block20_concat (Concatena (None, 20, 20, 896)  0           conv4_block19_concat[0][0]       \n","                                                                 conv4_block20_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_bn (BatchNormal (None, 20, 20, 896)  3584        conv4_block20_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_0_relu (Activatio (None, 20, 20, 896)  0           conv4_block21_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_1_conv (Conv2D)   (None, 20, 20, 128)  114688      conv4_block21_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block21_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block21_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block21_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block21_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block21_concat (Concatena (None, 20, 20, 928)  0           conv4_block20_concat[0][0]       \n","                                                                 conv4_block21_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_bn (BatchNormal (None, 20, 20, 928)  3712        conv4_block21_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_0_relu (Activatio (None, 20, 20, 928)  0           conv4_block22_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_1_conv (Conv2D)   (None, 20, 20, 128)  118784      conv4_block22_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block22_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block22_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block22_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block22_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block22_concat (Concatena (None, 20, 20, 960)  0           conv4_block21_concat[0][0]       \n","                                                                 conv4_block22_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_bn (BatchNormal (None, 20, 20, 960)  3840        conv4_block22_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_0_relu (Activatio (None, 20, 20, 960)  0           conv4_block23_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_1_conv (Conv2D)   (None, 20, 20, 128)  122880      conv4_block23_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block23_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block23_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block23_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block23_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block23_concat (Concatena (None, 20, 20, 992)  0           conv4_block22_concat[0][0]       \n","                                                                 conv4_block23_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_bn (BatchNormal (None, 20, 20, 992)  3968        conv4_block23_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_0_relu (Activatio (None, 20, 20, 992)  0           conv4_block24_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_1_conv (Conv2D)   (None, 20, 20, 128)  126976      conv4_block24_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_bn (BatchNormal (None, 20, 20, 128)  512         conv4_block24_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_1_relu (Activatio (None, 20, 20, 128)  0           conv4_block24_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv4_block24_2_conv (Conv2D)   (None, 20, 20, 32)   36864       conv4_block24_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv4_block24_concat (Concatena (None, 20, 20, 1024) 0           conv4_block23_concat[0][0]       \n","                                                                 conv4_block24_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","pool4_bn (BatchNormalization)   (None, 20, 20, 1024) 4096        conv4_block24_concat[0][0]       \n","__________________________________________________________________________________________________\n","pool4_relu (Activation)         (None, 20, 20, 1024) 0           pool4_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool4_conv (Conv2D)             (None, 20, 20, 512)  524288      pool4_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool4_pool (AveragePooling2D)   (None, 10, 10, 512)  0           pool4_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 10, 10, 512)  2048        pool4_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv5_block1_0_relu (Activation (None, 10, 10, 512)  0           conv5_block1_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 10, 10, 128)  65536       conv5_block1_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 10, 10, 128)  0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_concat (Concatenat (None, 10, 10, 544)  0           pool4_pool[0][0]                 \n","                                                                 conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_bn (BatchNormali (None, 10, 10, 544)  2176        conv5_block1_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_0_relu (Activation (None, 10, 10, 544)  0           conv5_block2_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 10, 10, 128)  69632       conv5_block2_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 10, 10, 128)  0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_concat (Concatenat (None, 10, 10, 576)  0           conv5_block1_concat[0][0]        \n","                                                                 conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_bn (BatchNormali (None, 10, 10, 576)  2304        conv5_block2_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_0_relu (Activation (None, 10, 10, 576)  0           conv5_block3_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 10, 10, 128)  73728       conv5_block3_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 10, 10, 128)  0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_concat (Concatenat (None, 10, 10, 608)  0           conv5_block2_concat[0][0]        \n","                                                                 conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_bn (BatchNormali (None, 10, 10, 608)  2432        conv5_block3_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_0_relu (Activation (None, 10, 10, 608)  0           conv5_block4_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_1_conv (Conv2D)    (None, 10, 10, 128)  77824       conv5_block4_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_1_relu (Activation (None, 10, 10, 128)  0           conv5_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block4_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block4_concat (Concatenat (None, 10, 10, 640)  0           conv5_block3_concat[0][0]        \n","                                                                 conv5_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_bn (BatchNormali (None, 10, 10, 640)  2560        conv5_block4_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_0_relu (Activation (None, 10, 10, 640)  0           conv5_block5_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_1_conv (Conv2D)    (None, 10, 10, 128)  81920       conv5_block5_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_1_relu (Activation (None, 10, 10, 128)  0           conv5_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block5_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block5_concat (Concatenat (None, 10, 10, 672)  0           conv5_block4_concat[0][0]        \n","                                                                 conv5_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_bn (BatchNormali (None, 10, 10, 672)  2688        conv5_block5_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_0_relu (Activation (None, 10, 10, 672)  0           conv5_block6_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_1_conv (Conv2D)    (None, 10, 10, 128)  86016       conv5_block6_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_1_relu (Activation (None, 10, 10, 128)  0           conv5_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block6_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block6_concat (Concatenat (None, 10, 10, 704)  0           conv5_block5_concat[0][0]        \n","                                                                 conv5_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_bn (BatchNormali (None, 10, 10, 704)  2816        conv5_block6_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_0_relu (Activation (None, 10, 10, 704)  0           conv5_block7_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_1_conv (Conv2D)    (None, 10, 10, 128)  90112       conv5_block7_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block7_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_1_relu (Activation (None, 10, 10, 128)  0           conv5_block7_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block7_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block7_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block7_concat (Concatenat (None, 10, 10, 736)  0           conv5_block6_concat[0][0]        \n","                                                                 conv5_block7_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_bn (BatchNormali (None, 10, 10, 736)  2944        conv5_block7_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_0_relu (Activation (None, 10, 10, 736)  0           conv5_block8_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_1_conv (Conv2D)    (None, 10, 10, 128)  94208       conv5_block8_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block8_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_1_relu (Activation (None, 10, 10, 128)  0           conv5_block8_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block8_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block8_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block8_concat (Concatenat (None, 10, 10, 768)  0           conv5_block7_concat[0][0]        \n","                                                                 conv5_block8_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_bn (BatchNormali (None, 10, 10, 768)  3072        conv5_block8_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_0_relu (Activation (None, 10, 10, 768)  0           conv5_block9_0_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_1_conv (Conv2D)    (None, 10, 10, 128)  98304       conv5_block9_0_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_bn (BatchNormali (None, 10, 10, 128)  512         conv5_block9_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_1_relu (Activation (None, 10, 10, 128)  0           conv5_block9_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block9_2_conv (Conv2D)    (None, 10, 10, 32)   36864       conv5_block9_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block9_concat (Concatenat (None, 10, 10, 800)  0           conv5_block8_concat[0][0]        \n","                                                                 conv5_block9_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_bn (BatchNormal (None, 10, 10, 800)  3200        conv5_block9_concat[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block10_0_relu (Activatio (None, 10, 10, 800)  0           conv5_block10_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_1_conv (Conv2D)   (None, 10, 10, 128)  102400      conv5_block10_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block10_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block10_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block10_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block10_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block10_concat (Concatena (None, 10, 10, 832)  0           conv5_block9_concat[0][0]        \n","                                                                 conv5_block10_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_bn (BatchNormal (None, 10, 10, 832)  3328        conv5_block10_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_0_relu (Activatio (None, 10, 10, 832)  0           conv5_block11_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_1_conv (Conv2D)   (None, 10, 10, 128)  106496      conv5_block11_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block11_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block11_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block11_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block11_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block11_concat (Concatena (None, 10, 10, 864)  0           conv5_block10_concat[0][0]       \n","                                                                 conv5_block11_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_bn (BatchNormal (None, 10, 10, 864)  3456        conv5_block11_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_0_relu (Activatio (None, 10, 10, 864)  0           conv5_block12_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_1_conv (Conv2D)   (None, 10, 10, 128)  110592      conv5_block12_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block12_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block12_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block12_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block12_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block12_concat (Concatena (None, 10, 10, 896)  0           conv5_block11_concat[0][0]       \n","                                                                 conv5_block12_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_bn (BatchNormal (None, 10, 10, 896)  3584        conv5_block12_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_0_relu (Activatio (None, 10, 10, 896)  0           conv5_block13_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_1_conv (Conv2D)   (None, 10, 10, 128)  114688      conv5_block13_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block13_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block13_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block13_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block13_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block13_concat (Concatena (None, 10, 10, 928)  0           conv5_block12_concat[0][0]       \n","                                                                 conv5_block13_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_bn (BatchNormal (None, 10, 10, 928)  3712        conv5_block13_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_0_relu (Activatio (None, 10, 10, 928)  0           conv5_block14_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_1_conv (Conv2D)   (None, 10, 10, 128)  118784      conv5_block14_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block14_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block14_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block14_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block14_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block14_concat (Concatena (None, 10, 10, 960)  0           conv5_block13_concat[0][0]       \n","                                                                 conv5_block14_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_bn (BatchNormal (None, 10, 10, 960)  3840        conv5_block14_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_0_relu (Activatio (None, 10, 10, 960)  0           conv5_block15_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_1_conv (Conv2D)   (None, 10, 10, 128)  122880      conv5_block15_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block15_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block15_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block15_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block15_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block15_concat (Concatena (None, 10, 10, 992)  0           conv5_block14_concat[0][0]       \n","                                                                 conv5_block15_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_bn (BatchNormal (None, 10, 10, 992)  3968        conv5_block15_concat[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_0_relu (Activatio (None, 10, 10, 992)  0           conv5_block16_0_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_1_conv (Conv2D)   (None, 10, 10, 128)  126976      conv5_block16_0_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_bn (BatchNormal (None, 10, 10, 128)  512         conv5_block16_1_conv[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_1_relu (Activatio (None, 10, 10, 128)  0           conv5_block16_1_bn[0][0]         \n","__________________________________________________________________________________________________\n","conv5_block16_2_conv (Conv2D)   (None, 10, 10, 32)   36864       conv5_block16_1_relu[0][0]       \n","__________________________________________________________________________________________________\n","conv5_block16_concat (Concatena (None, 10, 10, 1024) 0           conv5_block15_concat[0][0]       \n","                                                                 conv5_block16_2_conv[0][0]       \n","__________________________________________________________________________________________________\n","bn (BatchNormalization)         (None, 10, 10, 1024) 4096        conv5_block16_concat[0][0]       \n","__________________________________________________________________________________________________\n","relu (Activation)               (None, 10, 10, 1024) 0           bn[0][0]                         \n","__________________________________________________________________________________________________\n","max_pool (GlobalMaxPooling2D)   (None, 1024)         0           relu[0][0]                       \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 1024)         0           max_pool[0][0]                   \n","__________________________________________________________________________________________________\n","dense0_128 (Dense)              (None, 128)          131200      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 128)          0           dense0_128[0][0]                 \n","__________________________________________________________________________________________________\n","dense1_64 (Dense)               (None, 64)           8256        leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 64)           0           dense1_64[0][0]                  \n","__________________________________________________________________________________________________\n","pred_cxr (Dense)                (None, 1)            65          dropout[0][0]                    \n","==================================================================================================\n","Total params: 7,170,753\n","Trainable params: 1,615,169\n","Non-trainable params: 5,555,584\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4dlQXPNHONtK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391620797,"user_tz":-60,"elapsed":24704,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"32f9b052-b86b-4955-d73a-aabc395b5f51"},"source":["model_teacher = 'gs://first_cxr/model/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'\n","base_model = load_base_model(model_teacher, return_model=True)\n","CXRmodel = CXRModel_functional(base_model, 0.1, 355, pretrained_feature_layer =-4)\n","CXRmodel.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["load model weights_path: brucechou1983_CheXNet_Keras_0.3.0_weights.h5\n","Model: \"model_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 224, 224, 1)]     0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 224, 224, 3)       30        \n","_________________________________________________________________\n","model_2 (Functional)         (None, 1)                 7038529   \n","=================================================================\n","Total params: 7,038,559\n","Trainable params: 1,476,703\n","Non-trainable params: 5,561,856\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9SveEFJkF58"},"source":["# maybe we're not getting the best feature layers\n","# https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/filter_visualizer.ipynb\n","# https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNRXxpY6vtrq"},"source":["## Define Intermediate Fusion model"]},{"cell_type":"code","metadata":{"id":"WZVIuQy10fkr"},"source":["# Intermediate/Late Fusion model\n","class Combined_Model(tf.keras.Model):\n","\n","  def __init__(self, tab_input_dim, drop_out, layers_not_trainable, tab_out_dim, cxr_out_dim, train=True):\n","    super(Combined_Model, self).__init__()\n","    self.train = train\n","    self.cxr_out = CXRModel(drop_out, layers_not_trainable, out_dim=cxr_out_dim, combine=True, train = train)\n","    self.tab_out = TabularModel(tab_input_dim, drop_out, out_dim = tab_out_dim, combine=True,train = train)\n","    self.norm = tf.keras.layers.BatchNormalization(axis=1)\n","    self.dense = tf.keras.layers.Dense(tab_out_dim+cxr_out_dim, activation='relu')\n","    self.dropout = tf.keras.layers.Dropout(drop_out)\n","    # final binary classification from both structured and cxr model\n","    self.pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_combined\")\n","\n","  def call(self, inputs):\n","    # Takes in (input1,input2) or [input1,input2]\n","    tab_inputs, cxr_inputs = inputs\n","    x1 = self.tab_out(tab_inputs)\n","    x2 = self.cxr_out(cxr_inputs)\n","    concat = tf.keras.layers.concatenate([x1, x2], axis=1)\n","    # might help with different feature scales from imaging and tab data\n","    x = self.norm(concat)\n","    x = self.dense(x)\n","    x = self.dropout(x, training=self.train)\n","    return self.pred(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GjIWTYOjdMTq"},"source":["# this one works with tuning\n","def Combined_Model_functional(cxr_base_model, tab_input_dim, drop_out, layers_not_trainable\n","                              , pretrained_feature_layer, cxr_hidden_dims, tab_out_dim \n","                              #, cxr_out_dim\n","                              , output_bias = None):\n","    tabmodel = TabularModel_functional(tab_input_dim, drop_out, out_dim=tab_out_dim, combine = True)\n","    cxrmodel = CXRModel_functional(cxr_base_model, drop_out, layers_not_trainable\n","                                   , pretrained_feature_layer=pretrained_feature_layer\n","                                   , hidden_dims = cxr_hidden_dims\n","                                   #, out_dim=cxr_out_dim\n","                                   , combine = True\n","                                   )\n","    output_bias = tf.keras.initializers.Constant(output_bias)\n","    x1 = tabmodel.layers[-1].output\n","    x2 = cxrmodel.layers[-1].output\n","    concat = tf.keras.layers.concatenate([x1, x2], axis=1) # for functional API\n","    #concat = tf.keras.layers.Concatenate(axis=1)([x1, x2]) # for sequential API\n","    x = tf.keras.layers.BatchNormalization(axis=1)(concat)\n","    x = tf.keras.layers.Dense(tab_out_dim + cxr_out_dim, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(drop_out)(x)\n","    pred = tf.keras.layers.Dense(1, activation='sigmoid', name=\"pred_combined\", bias_initializer=output_bias)(x)\n","    model = tf.keras.Model(inputs = [tabmodel.input, cxrmodel.input], outputs = pred)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NqXgTH4WR42W"},"source":["# Tune models"]},{"cell_type":"markdown","metadata":{"id":"7vtLqGH0S4Ek"},"source":["In general there are several models/strategies to try:\n","1. RF/XGB etc for structured data that Wesley has done in another notebook\n","2. Late fusion from Po-Chih's transfer-learned CXR model mortality likelihood output + structured RF/XGB model\n","3. Intermediate offline fusion - extract CXR features with the transfer-learned CXR model then concatenate with the raw structured feature\n","4. Intermediate offline fusion - extract CXR features with the transfer-learned CXR model then concatenate with deep learner encoded structured features. This may be better because the weights in deep learning models and other logistic/RF models mean different things mathematically.\n","5. Intermediate online fusion - both weights for the CXR and the structured features are learned during training\n","6. Intermediate online fusion + transfer learn -- trained the CXR and structured deep learning models separately, pick the best models then fuse and learn a bit more. 5 likely works better as larger set of hyperparameters can be explored/tuned but likely less interpretable.\n","7. For any CXR related training, can tune for with and without Bbox augmentation for trache and lung/heart regions to help network ignore less relevant CXR features for prediction."]},{"cell_type":"markdown","metadata":{"id":"CVBefQBr_rsx"},"source":["Po-Chih seems to be working on 3\n","\n","This notebook is trying to do 5 with 7\n","\n","It would be reasonable to try to do 2 as well\n","\n","For testing on external data (Korean & Hoboken), CXR features have already been extracted for 3. To test the models from this notebook, one would need to package the final models and get help from Seth/Joseph to run on the Hoboken dataset \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dR2o-9XqI7im"},"source":["### Training/Tuning code"]},{"cell_type":"code","metadata":{"id":"dGW1kK_NR7__"},"source":["# # Tuning function adapted from\n","# # https://github.com/cxr-eye-gaze/eye-gaze-dataset/blob/master/Experiments/tune_static.py\n","# # https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/tune_mnist_keras.py\n","# # https://keras.io/examples/vision/xray_classification_with_tpus/ \n","# # https://colab.research.google.com/drive/1kpCDInclZHLOvb-9MOgQHUfJfsg8748Z#scrollTo=ZbJDZ6chSWOb\n","\n","# def tune_covid19_models(x_train, y_train, x_val, y_val, config):\n","#     tf.keras.backend.clear_session()\n","    \n","#     print(config)\n","#     # args\n","#     args = type('', (), {})()\n","#     # Hyperparameters that can be tuned\n","#     args.model_type = config['model_type'] #'tab_model','cxr_model','model_fused'\n","#     args.tab_out_dim = config['tab_out_dim']\n","#     args.cxr_out_dim = config['cxr_out_dim']\n","#     args.augment_bbox = config['augment_bbox']\n","#     args.model_teacher = config['model_teacher']\n","#     args.lr_init = config['lr_init']\n","#     args.epochs = config[\"epochs\"]\n","#     args.dropout = config['dropout']\n","#     args.batch_size = config['batch_size']\n","#     args.class_weight = config['class_weight']\n","#     args.layers_not_trainable = config['layers_not_trainable']\n","#     args.pretrained_feature_layer = config['pretrained_feature_layer']\n","#     args.cxr_hidden_dims = config['cxr_hidden_dims']\n","\n","#     args.steps_per_epoch = int(len(training_filenames)) // args.batch_size\n","#     args.val_steps = int(len(validation_filenames)) // args.batch_size\n","#     print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(args.batch_size, args.steps_per_epoch, args.val_steps))\n","\n","#     # input and output parameters\n","#     args.train_table_path = 'gs://new_cxr_30/split/train_structured.csv'\n","#     args.valid_table_path = 'gs://new_cxr_30/split/valtest_structured.csv'\n","#     args.test_table_path = 'gs://new_cxr_30/split/test_structured.csv'\n","#     args.xfeatures = XFEATURES\n","#     args.image_path_train = 'gs://new_cxr_30/classified/*/train_*.jpg'\n","#     args.image_path_test = 'gs://new_cxr_30/classified/*/test_*.jpg' \n","#     args.resize = TARGET_SIZE\n","#     args.num_workers = 16 # can reduce to optimize memory\n","#     args.rseed = SEED\n","#     args.output_dir = 'gs://new_cxr_30/models/'\n","\n","#     # Create saving dir, all useful variables\n","#     output_model_path = os.path.join(args.output_dir, args.model_type)\n","#     if not os.path.exists(output_model_path): \n","#         os.makedirs(output_model_path)\n","    \n","#     # Load data to iterator\n","#     # argumetns: get_augmented_batched_dataset_(structured_path, xfeatures, model_type, batch_size, rseed, train=True)\n","#     train_dl = get_augmented_batched_dataset_(args.train_table_path, args.xfeatures\n","#                             , args.model_type, args.batch_size, args.augment_bbox, args.rseed, train=True)\n","#     valid_dl = get_augmented_batched_dataset_(args.valid_table_path, args.xfeatures\n","#                             , args.model_type, args.batch_size, False, args.rseed, train=False)\n","#     #test_dl = get_augmented_batched_dataset_(args.test_table_path, args.xfeatures\n","#                             #, args.model_type, args.batch_size, args.augment_bbox, args.rseed, train=False)\n","    \n","#     # Logs in keras -- no idea where things are being saved\n","#     checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(output_model_path,'model-{epoch:03d}.h5')\n","#                                                     , verbose=1, monitor='val_loss'\n","#                                                     ,save_best_only=True, mode='min')  \n","#     early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2, verbose = 1, restore_best_weights=True)\n","\n","#     # Tune learning rate\n","#     initial_learning_rate = config['lr_init']\n","#     lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate\n","#                     , decay_steps=100000, decay_rate=0.96, staircase=True)\n","    \n","#     # Need to load datasets before initializing tpu or will have address error\n","#     # problem:https://github.com/tensorflow/tensorflow/issues/43037\n","#     # solution: https://colab.research.google.com/drive/1kpCDInclZHLOvb-9MOgQHUfJfsg8748Z#scrollTo=ZbJDZ6chSWOb\n","\n","#     # set tpu model strategy\n","#     if USE_TPU:\n","#         if HOSTED_RUNTIME: # but this is still giving me address error when run with eagarly executions required for bbox augmentation\n","#             #resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","#             try:\n","#                 tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","#             except ValueError:\n","#                 raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","#             # https://stackoverflow.com/questions/55541881/how-to-convert-tf-keras-model-to-tpu-using-tensorflow-2-0-in-google-colab\n","#         else:\n","#             try:\n","#                 tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='cxr-test',project='hm-covid-19') \n","#             except ValueError:\n","#                 raise BaseException('ERROR: Not connected to a TPU runtime')\n","#         print('Hosted runtime:', HOSTED_RUNTIME)\n","#         print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","#         tf.config.experimental_connect_to_cluster(tpu)\n","#         tf.tpu.experimental.initialize_tpu_system(tpu)\n","#         strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","#     else:\n","#         strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n","\n","#     # Compile model\n","#     with strategy.scope():\n","#         # Getting error with serializing subclassed models...which cannot be done! so changed models to functional\n","#         # https://stackoverflow.com/questions/51806852/cant-save-custom-subclassed-model\n","#         # Pick the model to fit\n","#         if args.model_type == 'tab_model':\n","#             #input: input_dim, drop+out\n","#             model = TabularModel_functional(len(args.xfeatures), args.dropout)\n","#         elif args.model_type == 'cxr_model':\n","#             base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","#             #input: drop_out, layers_not_trainable\n","#             model = CXRModel_functional(base, args.dropout, args.layers_not_trainable\n","#                                         , pretrained_feature_layer=args.pretrained_feature_layer\n","#                                         , hidden_dims = args.cxr_hidden_dims)\n","#         elif args.model_type == 'fused_model':\n","#             base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","#             #input: tab_input_dim, drop_out, layers_not_trainable, tab_out_dim, cxr_out_dim\n","#             model = Combined_Model_functional(base, len(args.xfeatures), args.dropout, args.layers_not_trainable\n","#                                         ,args.pretrained_feature_layer, args.cxr_hidden_dims\n","#                                         , args.tab_out_dim, args.cxr_out_dim)\n","#         else:\n","#             print('Model type does not exist')\n","#         METRICS = [\n","#                 tf.keras.metrics.BinaryAccuracy(),\n","#                 tf.keras.metrics.Precision(name=\"precision\"),\n","#                 tf.keras.metrics.Recall(name=\"recall\"),\n","#                 tf.keras.metrics.AUC(name='auc'),\n","#                 ]\n","#         model.compile(\n","#             #optimizer='adam',\n","#             optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n","#             loss='binary_crossentropy',\n","#             metrics=METRICS,\n","#         )\n","\n","#     # Fit the model in tf.keras...\n","#     history = model.fit(train_dl,\n","#                         steps_per_epoch = args.steps_per_epoch,\n","#                         epochs = args.epochs, \n","#                         validation_data = valid_dl,\n","#                         shuffle = True,\n","#                         class_weight = args.class_weight, \n","#                         callbacks=[checkpoint, early_stopping_cb])\n","    \n","#     # might not need this in tensorflow 2.x\n","#     # if USE_TPU:\n","#     #     return history, model #.sync_to_cpu() \n","#     # else:\n","#     return history, model\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-YwCT_sTZ2H"},"source":["# https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n","def f1(y_true, y_pred):\n","    y_pred = K.round(y_pred)\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return K.mean(f1)\n","\n","def f1_loss(y_true, y_pred):\n","    \n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return 1 - K.mean(f1)\n","\n","# from: https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d\n","def macro_double_soft_f1(y, y_hat):\n","    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n","    Use probability values instead of binary predictions.\n","    This version uses the computation of soft-F1 for both positive and negative class for each label.\n","    \n","    Args:\n","        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n","        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n","        \n","    Returns:\n","        cost (scalar Tensor): value of the cost function for the batch\n","    \"\"\"\n","    y = tf.cast(y, tf.float32)\n","    y_hat = tf.cast(y_hat, tf.float32)\n","    tp = tf.reduce_sum(y_hat * y, axis=0)\n","    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n","    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n","    tn = tf.reduce_sum((1 - y_hat) * (1 - y), axis=0)\n","    soft_f1_class1 = 2*tp / (2*tp + fn + fp + 1e-16)\n","    soft_f1_class0 = 2*tn / (2*tn + fn + fp + 1e-16)\n","    cost_class1 = 1 - soft_f1_class1 # reduce 1 - soft-f1_class1 in order to increase soft-f1 on class 1\n","    cost_class0 = 1 - soft_f1_class0 # reduce 1 - soft-f1_class0 in order to increase soft-f1 on class 0\n","    cost = 0.5 * (cost_class1 + cost_class0) # take into account both class 1 and class 0\n","    macro_cost = tf.reduce_mean(cost) # average on all labels\n","    return macro_cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nRD4FfPR62oj"},"source":["def tune_covid19_models(x_train, y_train, x_val, y_val, config):\n","    tf.keras.backend.clear_session()\n","    \n","    print(config)\n","    # args\n","    args = type('', (), {})()\n","    # Hyperparameters that can be tuned\n","    args.model_type = config['model_type'] #'tab_model','cxr_model','model_fused'\n","    args.tab_out_dim = config['tab_out_dim']\n","    #args.cxr_out_dim = config['cxr_out_dim'] # last hidden dim would be the cxr_out_dim so fewer search params\n","    args.augment_bbox = config['augment_bbox']\n","    args.model_teacher = config['model_teacher']\n","    args.lr_init = config['lr_init']\n","    args.epochs = config[\"epochs\"]\n","    args.dropout = config['dropout']\n","    args.batch_size = config['batch_size']\n","    args.loss_function = config['loss_function']\n","    args.class_weight = config['class_weight']\n","    args.layers_not_trainable = config['layers_not_trainable']\n","    args.pretrained_feature_layer = config['pretrained_feature_layer']\n","    args.cxr_hidden_dims = config['cxr_hidden_dims']\n","    args.output_bias = config['output_bias']\n","    args.steps_per_epoch = int(len(training_filenames)) // args.batch_size\n","    args.val_steps = int(len(validation_filenames)) // args.batch_size\n","    print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(args.batch_size, args.steps_per_epoch, args.val_steps))\n","    args.fold = config['k-fold']\n","\n","    # input and output parameters\n","    args.train_table_path = 'gs://new_cxr_30/split/train_structured.csv'\n","    args.valid_table_path = 'gs://new_cxr_30/split/valtest_structured.csv'\n","    args.test_table_path = 'gs://new_cxr_30/split/test_structured.csv'\n","    args.combined_table_path = 'gs://new_cxr_30/split/combined_structured.csv'\n","    args.xfeatures = XFEATURES\n","    args.image_path_train = 'gs://new_cxr_30/classified/*/train_*.jpg'\n","    args.image_path_test = 'gs://new_cxr_30/classified/*/test_*.jpg' \n","    #args.resize = TARGET_SIZE\n","    args.num_workers = 16 # can reduce to optimize memory\n","    args.rseed = SEED\n","    args.output_dir = 'gs://new_cxr_30/models/'\n","\n","    # Create saving dir, all useful variables\n","    output_model_path = os.path.join(args.output_dir, args.model_type)\n","    if not os.path.exists(output_model_path): \n","        os.makedirs(output_model_path)\n","    \n","    # Option for k-fold splits for train/val, k=4\n","    if args.fold > 0:\n","        dfall = pd.read_csv(args.combined_table_path)\n","        dfvalid = dfall[dfall.fold==args.fold].copy()\n","        dftrain = dfall[~dfall.index.isin(dfvalid.index.tolist())].copy()\n","    else:\n","        dftrain = pd.read_csv(args.train_table_path)\n","        dfvalid = pd.read_csv(args.valid_table_path)\n","\n","    # Need to load datasets before initializing tpu or will have address error\n","    # problem:https://github.com/tensorflow/tensorflow/issues/43037\n","    # solution: https://colab.research.google.com/drive/1kpCDInclZHLOvb-9MOgQHUfJfsg8748Z#scrollTo=ZbJDZ6chSWOb\n","\n","    # Compile model\n","    with strategy.scope():\n","        # Load data to iterator\n","        # argumetns: get_augmented_batched_dataset_(structured_path, xfeatures, model_type, batch_size, rseed, train=True)\n","        train_dl = get_augmented_batched_dataset_(dftrain, args.xfeatures\n","                                , args.model_type, args.batch_size, args.augment_bbox, args.rseed, train=True)\n","        valid_dl = get_augmented_batched_dataset_(dfvalid, args.xfeatures\n","                                , args.model_type, args.batch_size, False, args.rseed, train=False)\n","        #test_dl = get_augmented_batched_dataset_(args.test_table_path, args.xfeatures\n","                                #, args.model_type, args.batch_size, False, args.rseed, train=False)\n","        \n","        # Logs in keras -- no idea where things are being saved\n","        checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(output_model_path,'model-{epoch:03d}.h5')\n","                                                        , verbose=1, monitor='val_auc'\n","                                                        ,save_best_only=True, mode='max')  \n","        early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode = 'max'\n","                                                        , verbose = 1, restore_best_weights=True)\n","        \n","        # Tune learning rate\n","        initial_learning_rate = config['lr_init']\n","        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate\n","                        , decay_steps=100000, decay_rate=0.96, staircase=True)  \n","        \n","        # Getting error with serializing subclassed models...which cannot be done! so changed models to functional\n","        # https://stackoverflow.com/questions/51806852/cant-save-custom-subclassed-model\n","        # Pick the model to fit\n","        if args.model_type == 'tab_model':\n","            #input: input_dim, drop+out\n","            model = TabularModel_functional(len(args.xfeatures), args.dropout)\n","        elif args.model_type == 'cxr_model':\n","            base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","            #input: drop_out, layers_not_trainable\n","            model = CXRModel_functional(base, args.dropout, args.layers_not_trainable\n","                                        , pretrained_feature_layer=args.pretrained_feature_layer\n","                                        , hidden_dims = args.cxr_hidden_dims\n","                                        , output_bias = args.output_bias\n","                                        )\n","        elif args.model_type == 'fused_model':\n","            base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","            #input: tab_input_dim, drop_out, layers_not_trainable, tab_out_dim, cxr_out_dim\n","            model = Combined_Model_functional(base, len(args.xfeatures), args.dropout, args.layers_not_trainable\n","                                        ,args.pretrained_feature_layer, args.cxr_hidden_dims\n","                                        , args.tab_out_dim \n","                                        #, args.cxr_out_dim\n","                                        , output_bias = args.output_bias\n","                                        )\n","        else:\n","            print('Model type does not exist')\n","        METRICS = [\n","                tf.keras.metrics.TruePositives(name='tp'),\n","                tf.keras.metrics.FalsePositives(name='fp'),\n","                tf.keras.metrics.TrueNegatives(name='tn'),\n","                tf.keras.metrics.FalseNegatives(name='fn'), \n","                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","                tf.keras.metrics.Precision(name=\"precision\"),\n","                tf.keras.metrics.Recall(name=\"recall\"),\n","                tf.keras.metrics.AUC(name='auc'),\n","                f1,\n","                #tfa.metrics.F1Score(2, name='f1_score') # gives an error\n","                ]\n","        \n","        # likely do better for imbalanced data: https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy\n","        if args.loss_function == 'sigmoid_focal_crossentropy':\n","            loss = tfa.losses.SigmoidFocalCrossEntropy()\n","        elif args.loss_function == 'f1_loss':  \n","            loss = f1_loss\n","        elif args.loss_function == 'macro_double_soft_f1':\n","            loss = macro_double_soft_f1\n","        else:\n","            loss = args.loss_function\n","        \n","        model.compile(\n","            #optimizer='adam',\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n","            loss=loss,\n","            metrics=METRICS,\n","        )\n","\n","    # Fit the model in tf.keras...\n","    history = model.fit(train_dl,\n","                        steps_per_epoch = args.steps_per_epoch // 10,\n","                        epochs = args.epochs * 10, \n","                        validation_data = valid_dl,\n","                        shuffle = True,\n","                        class_weight = args.class_weight, \n","                        callbacks=[checkpoint, early_stopping_cb]\n","                        )\n","    \n","    # Visualize\n","    \n","    # might not need this in tensorflow 2.x\n","    # if USE_TPU:\n","    #     return history, model #.sync_to_cpu() \n","    # else:\n","    return history, model\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AV-MBGsGgljS"},"source":["## Tunable parameters"]},{"cell_type":"code","metadata":{"id":"vgeli6PyaPWy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391621154,"user_tz":-60,"elapsed":24982,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"312aaee9-b4a6-4b5b-f30d-4033c5907cd8"},"source":["# Po-Chih noted that on Colab/GPU, a higher batch size does not help and sometimes does not fit on the GPU (OOM)\n","BATCH_SIZE = [16] # most models performed better on 16 and there are usually 1-2 examples in each batch of 16\n","\n","# Even though bias inialization usually doesn't matter for large CNN networks\n","# We're actually mostly tuning only the last few layers of the pretrained CNN\n","# And our data is very imbalanced\n","# so maybe more careful initialization bias in the last neural layer is useful particularly for precision\n","# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n","GCS_PATTERN_JPG = 'gs://new_cxr_30/classified/*/*.jpg'\n","imagefilenames = tf.io.gfile.glob(GCS_PATTERN_JPG)\n","pos = len([x for x in imagefilenames if 'EXPIRED' in x])\n","neg = len([x for x in imagefilenames if 'ALIVE' in x])\n","total = neg + pos\n","print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n","    total, pos, 100 * pos / total))\n","initial_bias = np.log([pos/neg])\n","BIAS = [initial_bias]\n","\n","# Very unbalanced training data so will use class weights. 1 is expired, added weight to boost the expired cases\n","weight_for_0 = (1 / neg)*(total)/2.0 \n","weight_for_1 = (1 / pos)*(total)/2.0\n","print('Calculated weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Calculated weight for class 1: {:.2f}'.format(weight_for_1))\n","cw_calculated = {0: weight_for_0, 1: weight_for_1}\n","# For best recall/AUC, cw_calculated is likely most helpful, but would be worst for precision (best if no class weight)\n","CLASS_WEIGHT = [cw_calculated, {0:10 , 1:10}]\n","\n","# Other tunable parameters\n","DROPOUT = [0.1, 0.3, 0.5]\n","EPOCHS = [30] # up to this number of epochs -- have early stopping\n","LR_INIT = [0.001, 0.003, 0.009]\n","AUGMENT_BBOX = [False, 'B']\n","\n","# Not Tunable layers for pretrained model\n","LAYERS_NOT_TRAINABLE = [355, 400]\n","\n","# feature layer from the pretrained cxr model\n","PRETRAINED_FEATURE_LAYER = [-2, -4]\n","\n","# Can try hidden dims\n","CXR_HIDDEN_DIMS = [[128],[128,64],[128,128]]\n","\n","# Dimension of concat layer for fusion model: \n","structured_feature_size = int(len(XFEATURES))\n","print(structured_feature_size)\n","TAB_OUT_DIM = [structured_feature_size, 64]\n","#CXR_OUT_DIM = [structured_feature_size, 64]\n","\n","# May want a different loss function than binary cross entropy loss\n","LOSS = ['binary_crossentropy','sigmoid_focal_crossentropy']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Examples:\n","    Total: 1850\n","    Positive: 207 (11.19% of total)\n","\n","Calculated weight for class 0: 0.56\n","Calculated weight for class 1: 4.47\n","45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"II1e8lHQ9FZ2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615391621165,"user_tz":-60,"elapsed":24970,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"2b8cb88c-8364-49c3-d16b-1eeb1b2e193d"},"source":["search_num_tab = len(BATCH_SIZE)*len(CLASS_WEIGHT)*len(DROPOUT)*len(EPOCHS)*len(LR_INIT)\n","print(search_num_tab)\n","\n","search_num_cxr = len(BATCH_SIZE)*len(CLASS_WEIGHT)*len(DROPOUT)*len(EPOCHS)*len(LR_INIT)*len(AUGMENT_BBOX)*len(LAYERS_NOT_TRAINABLE)*len(PRETRAINED_FEATURE_LAYER)*len(BIAS)*len(CXR_HIDDEN_DIMS)*len(LOSS)\n","print(search_num_cxr)\n","\n","search_num_fused = len(BATCH_SIZE)*len(CLASS_WEIGHT)*len(DROPOUT)*len(EPOCHS)*len(LR_INIT)*len(AUGMENT_BBOX)*len(LAYERS_NOT_TRAINABLE)*len(TAB_OUT_DIM)*len(PRETRAINED_FEATURE_LAYER)*len(BIAS)*len(CXR_HIDDEN_DIMS)\n","print(search_num_fused)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["18\n","864\n","864\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-49q4J4zTwvV","colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"status":"ok","timestamp":1615391621339,"user_tz":-60,"elapsed":25120,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"ed4e3fff-4a4d-402c-ba5a-15f575cd1582"},"source":["# Get consistent folds in case random state seed didn't work\n","\n","# train_table_path = 'gs://new_cxr_30/split/train_structured.csv'\n","# valid_table_path = 'gs://new_cxr_30/split/valtest_structured.csv'\n","# dftrain = pd.read_csv(train_table_path)\n","# dfvalid = pd.read_csv(valid_table_path)\n","# print(len(dfvalid))\n","# dftrain = dftrain.sample(frac=1,random_state=42).reset_index(drop=True).copy()\n","# dfvalid = dfvalid.sample(frac=1,random_state=42).reset_index(drop=True).copy()\n","# dfall = pd.concat([dfvalid,dftrain],ignore_index=True).copy()\n","# # for 4 folds of 75% / 25% train / val split with n val examples\n","# n = len(dfall) // k +1\n","# print(n)\n","# folds = [indices[i * n:(i + 1) * n] for i in range((len(indices) + n - 1) // n)]\n","# print(len(folds))\n","# def getfold(idx,folds):\n","#     for i, fold in enumerate(folds):\n","#         if idx in fold:\n","#             return i\n","# dfall['fold'] = [getfold(idx,folds) for idx in dfall.index.tolist()]\n","# # export_to_gcs(dfall, 'combined_structured.csv', 'gs://new_cxr_30/split')\n","\n","dfall = pd.read_csv('gs://new_cxr_30/split/combined_structured.csv')\n","for i in range(4):\n","    print(dfall[dfall.fold==i].shape)\n","    print(dfall[(dfall.fold==i)&(dfall.expired_30_days==1)].shape)\n","dfall.head()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(463, 53)\n","(43, 53)\n","(463, 53)\n","(58, 53)\n","(463, 53)\n","(49, 53)\n","(461, 53)\n","(57, 53)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                     SOPInstanceUID  \\\n","0         304  1.3.51.0.7.181565542.25952.64328.34017.44892.5...   \n","1          39    1.3.12.2.1107.5.3.56.2693.11.202003271231300687   \n","2         341  1.3.51.0.7.3412060171.33033.63557.36001.21862....   \n","3         218  1.3.51.0.7.12213814209.18309.19527.45079.23149...   \n","4         155  1.3.46.670589.30.36.0.1.18774111139.1586155491...   \n","\n","                                                path  expired_30_days  \\\n","0  gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...                0   \n","1  gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...                0   \n","2  gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...                0   \n","3  gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...                0   \n","4  gs://new_cxr_30/classified/ALIVE/test_1.3.46.6...                0   \n","\n","   patient_id       age  MALE  vitals_temp_ed_first  vitals_sbp_ed_first  \\\n","0       738.0 -1.500000   1.0              0.666667             0.000000   \n","1      1026.0 -0.916667   1.0              0.833333            -0.266667   \n","2      2433.0  0.458333   1.0              0.000000            -2.733333   \n","3      2469.0 -0.375000   1.0              0.000000             0.000000   \n","4      1117.0  0.291667   0.0             -1.500000             1.333333   \n","\n","   vitals_dbp_ed_first  ...  lab_leukocyte   lab_alt   lab_ast  lab_ddimer  \\\n","0                  0.0  ...      -0.793133  4.534202  4.938023    0.000000   \n","1                  0.0  ...      -0.315880  0.084691  0.804020   -0.293578   \n","2                 -1.0  ...       0.563090  0.000000  0.000000   -0.988003   \n","3                  0.0  ...       0.082403 -0.182410 -0.951424   -1.013409   \n","4                  1.5  ...       0.230043 -0.312704 -0.067002   -0.115737   \n","\n","   lab_neutrophil_percentage   lab_crp  lab_hemoglobin  APview  \\\n","0                  -0.563910 -0.454840        0.470588       1   \n","1                   0.578947  1.434851        0.058824       1   \n","2                   0.812030 -0.587801       -0.411765       1   \n","3                  -0.992481 -0.830622        0.117647       1   \n","4                  -0.729323 -0.520294       -2.823529       1   \n","\n","                        bbox_coordinates  fold  \n","0  [135, 29, 178, 164, 11, 50, 298, 303]     0  \n","1   [120, 34, 162, 148, 9, 46, 288, 238]     0  \n","2  [135, 29, 178, 166, 39, 58, 294, 283]     0  \n","3  [152, 29, 187, 163, 42, 71, 312, 266]     0  \n","4  [169, 29, 204, 157, 49, 66, 272, 241]     0  \n","\n","[5 rows x 53 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>SOPInstanceUID</th>\n","      <th>path</th>\n","      <th>expired_30_days</th>\n","      <th>patient_id</th>\n","      <th>age</th>\n","      <th>MALE</th>\n","      <th>vitals_temp_ed_first</th>\n","      <th>vitals_sbp_ed_first</th>\n","      <th>vitals_dbp_ed_first</th>\n","      <th>...</th>\n","      <th>lab_leukocyte</th>\n","      <th>lab_alt</th>\n","      <th>lab_ast</th>\n","      <th>lab_ddimer</th>\n","      <th>lab_neutrophil_percentage</th>\n","      <th>lab_crp</th>\n","      <th>lab_hemoglobin</th>\n","      <th>APview</th>\n","      <th>bbox_coordinates</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>304</td>\n","      <td>1.3.51.0.7.181565542.25952.64328.34017.44892.5...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...</td>\n","      <td>0</td>\n","      <td>738.0</td>\n","      <td>-1.500000</td>\n","      <td>1.0</td>\n","      <td>0.666667</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>-0.793133</td>\n","      <td>4.534202</td>\n","      <td>4.938023</td>\n","      <td>0.000000</td>\n","      <td>-0.563910</td>\n","      <td>-0.454840</td>\n","      <td>0.470588</td>\n","      <td>1</td>\n","      <td>[135, 29, 178, 164, 11, 50, 298, 303]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39</td>\n","      <td>1.3.12.2.1107.5.3.56.2693.11.202003271231300687</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.12.2...</td>\n","      <td>0</td>\n","      <td>1026.0</td>\n","      <td>-0.916667</td>\n","      <td>1.0</td>\n","      <td>0.833333</td>\n","      <td>-0.266667</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>-0.315880</td>\n","      <td>0.084691</td>\n","      <td>0.804020</td>\n","      <td>-0.293578</td>\n","      <td>0.578947</td>\n","      <td>1.434851</td>\n","      <td>0.058824</td>\n","      <td>1</td>\n","      <td>[120, 34, 162, 148, 9, 46, 288, 238]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>341</td>\n","      <td>1.3.51.0.7.3412060171.33033.63557.36001.21862....</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...</td>\n","      <td>0</td>\n","      <td>2433.0</td>\n","      <td>0.458333</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>-2.733333</td>\n","      <td>-1.0</td>\n","      <td>...</td>\n","      <td>0.563090</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>-0.988003</td>\n","      <td>0.812030</td>\n","      <td>-0.587801</td>\n","      <td>-0.411765</td>\n","      <td>1</td>\n","      <td>[135, 29, 178, 166, 39, 58, 294, 283]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>218</td>\n","      <td>1.3.51.0.7.12213814209.18309.19527.45079.23149...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.51.0...</td>\n","      <td>0</td>\n","      <td>2469.0</td>\n","      <td>-0.375000</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.082403</td>\n","      <td>-0.182410</td>\n","      <td>-0.951424</td>\n","      <td>-1.013409</td>\n","      <td>-0.992481</td>\n","      <td>-0.830622</td>\n","      <td>0.117647</td>\n","      <td>1</td>\n","      <td>[152, 29, 187, 163, 42, 71, 312, 266]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>155</td>\n","      <td>1.3.46.670589.30.36.0.1.18774111139.1586155491...</td>\n","      <td>gs://new_cxr_30/classified/ALIVE/test_1.3.46.6...</td>\n","      <td>0</td>\n","      <td>1117.0</td>\n","      <td>0.291667</td>\n","      <td>0.0</td>\n","      <td>-1.500000</td>\n","      <td>1.333333</td>\n","      <td>1.5</td>\n","      <td>...</td>\n","      <td>0.230043</td>\n","      <td>-0.312704</td>\n","      <td>-0.067002</td>\n","      <td>-0.115737</td>\n","      <td>-0.729323</td>\n","      <td>-0.520294</td>\n","      <td>-2.823529</td>\n","      <td>1</td>\n","      <td>[169, 29, 204, 157, 49, 66, 272, 241]</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 53 columns</p>\n","</div>"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"ChRngdKxum4v"},"source":["# Different experiment set ups"]},{"cell_type":"markdown","metadata":{"id":"zZ2ifQNPqcAO"},"source":["## Tuning CXR model experiments with 320 pretrained model"]},{"cell_type":"code","metadata":{"id":"2dIxqDVpFjiu"},"source":["# documentations\n","\n","# report1 -- 71 experiments but the CXR network didn't actually have a drop out layer so actually fewer combinations\n","# report2 -- reran the 71 experiments with drop out but very bad results for almost all likely to due to vanishing features/gradients after relu/maxpool layer\n","# report3 -- runing with 0 dropout but testing different baseline input feature layers and changed relu to leaky relu\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U43cyyo1BPw4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615407960873,"user_tz":-60,"elapsed":16364616,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"a6866998-ba27-4e57-9611-47c18474b449"},"source":["# pretrained CXR model input image width/height\n","TARGET_SIZE = 320\n","MODEL_TEACHER = ['gs://first_cxr/model/mimic_gen_aug_epoch5.h5'] # 320x320 input\n","\n","# Rough Manual Hyperparameter search space\n","# Slower learning rate and bias seem to help with smoother learning curves. Need more drop out to reduce overfitting.\n","# Increasing batch size didn't help like Po-Chih found out\n","# Class weighting helps recall and AUC but not precision as expected\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": CLASS_WEIGHT,\n","    \"dropout\": [0.1,0.3,0.5],\n","    \"epochs\": EPOCHS,\n","    \"lr_init\": [0.001, 0.003, 0.009],\n","    \"loss_function\": ['sigmoid_focal_crossentropy'],\n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": [None],\n","    \"output_bias\": BIAS, #[None, initial_bias],\n","    \"layers_not_trainable\": [355,400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-4,-2],\n","    \"augment_bbox\": ['B'], #[False]\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0],\n","}\n","\n","# # Narrowed down on these Hyperparameter search spaces -288 experiments\n","# cxr_search_space = {\n","#     \"batch_size\": BATCH_SIZE,\n","#     \"class_weight\": CLASS_WEIGHT,\n","#     \"dropout\": DROPOUT,\n","#     \"epochs\": EPOCHS,\n","#     \"lr_init\": LR_INIT,\n","#     \"model_type\": ['cxr_model'],\n","#     \"tab_out_dim\": [1],\n","#     \"cxr_hidden_dims\": CXR_HIDDEN_DIMS,\n","#     \"output_bias\": BIAS,\n","#     \"layers_not_trainable\": LAYERS_NOT_TRAINABLE, # max layers 428 for Po-Chi's base cxr model\n","#     'pretrained_feature_layer': PRETRAINED_FEATURE_LAYER,\n","#     \"augment_bbox\": AUGMENT_BBOX,\n","#     \"model_teacher\": MODEL_TEACHER,\n","#     \"k-fold\":[0],\n","# }\n","\n","\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": CLASS_WEIGHT,\n","    \"dropout\": [0.5],\n","    \"epochs\": [40],\n","    \"lr_init\": [0.001, 0.003, 0.009],\n","    \"loss_function\": ['binary_crossentropy'], # both pretty bad -- not learning at all\n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": CXR_HIDDEN_DIMS,\n","    \"output_bias\": BIAS, #[None, initial_bias],\n","    \"layers_not_trainable\": [355,400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2,-4],\n","    \"augment_bbox\": ['B'], #[False]\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0],\n","}\n","\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": [{0:10 , 1:10}],\n","    \"dropout\": [0.5],\n","    \"epochs\": [50],\n","    \"lr_init\": [0.001,0.002,0.003],\n","    \"loss_function\": ['binary_crossentropy'], \n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": [[128,64]],\n","    \"output_bias\": [initial_bias], #[None, initial_bias],\n","    \"layers_not_trainable\": [400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2, -4],\n","    \"augment_bbox\": ['B'],\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0,1,2,3],\n","}\n","\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    cxr320 = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=cxr_search_space,\n","                        experiment_name='tune_covid19_models')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/24 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 33s 3s/step - loss: 11.0066 - tp: 0.4444 - fp: 3.4444 - tn: 63.7778 - fn: 10.5556 - accuracy: 0.8281 - precision: 0.0444 - recall: 0.0222 - auc: 0.3724 - f1: 0.0111 - val_loss: 0.3146 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4808 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.48079, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 19s 3s/step - loss: 11.3595 - tp: 0.0000e+00 - fp: 17.8889 - tn: 54.8889 - fn: 5.4444 - accuracy: 0.6352 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3133 - f1: 0.0000e+00 - val_loss: 0.3062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7132 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.48079 to 0.71321, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 20s 3s/step - loss: 9.4695 - tp: 0.8889 - fp: 1.3333 - tn: 66.0000 - fn: 10.0000 - accuracy: 0.8599 - precision: 0.1574 - recall: 0.0482 - auc: 0.5370 - f1: 0.0370 - val_loss: 0.3023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7164 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.71321 to 0.71644, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 20s 3s/step - loss: 8.0511 - tp: 1.7778 - fp: 13.8889 - tn: 56.1111 - fn: 6.4444 - accuracy: 0.7225 - precision: 0.1364 - recall: 0.2365 - auc: 0.4117 - f1: 0.1329 - val_loss: 0.2995 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7449 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.71644 to 0.74489, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.2104 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.6667 - fn: 6.5556 - accuracy: 0.9163 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6536 - f1: 0.0000e+00 - val_loss: 0.2973 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7698 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.74489 to 0.76977, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 19s 3s/step - loss: 7.3066 - tp: 0.0000e+00 - fp: 5.5556 - tn: 60.3333 - fn: 12.3333 - accuracy: 0.7776 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4906 - f1: 0.0000e+00 - val_loss: 0.2958 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7624 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.76977\n","Epoch 7/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.2432 - tp: 1.6667 - fp: 7.6667 - tn: 59.8889 - fn: 9.0000 - accuracy: 0.7850 - precision: 0.2129 - recall: 0.1928 - auc: 0.5616 - f1: 0.2140 - val_loss: 0.2938 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7739 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.76977 to 0.77393, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.8485 - tp: 0.2222 - fp: 0.4444 - tn: 70.5556 - fn: 7.0000 - accuracy: 0.9141 - precision: 0.1111 - recall: 0.0159 - auc: 0.3782 - f1: 0.0139 - val_loss: 0.2932 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7699 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.77393\n","Epoch 9/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.8696 - tp: 0.0000e+00 - fp: 2.5556 - tn: 68.2222 - fn: 7.4444 - accuracy: 0.8557 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6109 - f1: 0.0000e+00 - val_loss: 0.2921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7756 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.77393 to 0.77556, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0350 - tp: 0.0000e+00 - fp: 0.4444 - tn: 71.3333 - fn: 6.4444 - accuracy: 0.9011 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6863 - f1: 0.0000e+00 - val_loss: 0.2911 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7771 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.77556 to 0.77708, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9892 - tp: 1.6667 - fp: 2.5556 - tn: 65.3333 - fn: 8.6667 - accuracy: 0.8385 - precision: 0.3407 - recall: 0.1440 - auc: 0.7379 - f1: 0.1742 - val_loss: 0.2889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7806 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.77708 to 0.78056, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.7608 - tp: 0.8889 - fp: 5.4444 - tn: 60.8889 - fn: 11.0000 - accuracy: 0.7977 - precision: 0.1446 - recall: 0.0921 - auc: 0.6291 - f1: 0.1024 - val_loss: 0.2876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7833 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.78056 to 0.78328, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6019 - tp: 0.7778 - fp: 5.0000 - tn: 63.2222 - fn: 9.2222 - accuracy: 0.8145 - precision: 0.1151 - recall: 0.0723 - auc: 0.5221 - f1: 0.0497 - val_loss: 0.2868 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7823 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.78328\n","Epoch 14/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9814 - tp: 0.2222 - fp: 0.3333 - tn: 69.2222 - fn: 8.4444 - accuracy: 0.8872 - precision: 0.1111 - recall: 0.0159 - auc: 0.5581 - f1: 0.0278 - val_loss: 0.2864 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7822 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.78328\n","Epoch 15/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.1773 - tp: 0.0000e+00 - fp: 2.1111 - tn: 65.6667 - fn: 10.4444 - accuracy: 0.8474 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6242 - f1: 0.0000e+00 - val_loss: 0.2857 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7827 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.78328\n","Epoch 16/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.8889 - fn: 8.3333 - accuracy: 0.8961 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7359 - f1: 0.0000e+00 - val_loss: 0.2859 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7856 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.78328 to 0.78561, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3675 - tp: 0.0000e+00 - fp: 1.1111 - tn: 69.7778 - fn: 7.3333 - accuracy: 0.8744 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7423 - f1: 0.0000e+00 - val_loss: 0.2856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7857 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.78561 to 0.78567, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3619 - tp: 0.5556 - fp: 0.7778 - tn: 69.7778 - fn: 7.1111 - accuracy: 0.9017 - precision: 0.2778 - recall: 0.0508 - auc: 0.6453 - f1: 0.0338 - val_loss: 0.2835 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7863 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.78567 to 0.78634, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4148 - tp: 0.2222 - fp: 1.4444 - tn: 69.3333 - fn: 7.2222 - accuracy: 0.8787 - precision: 0.0741 - recall: 0.0185 - auc: 0.6398 - f1: 0.0185 - val_loss: 0.2844 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7883 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.78634 to 0.78831, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.8855 - tp: 0.0000e+00 - fp: 0.5556 - tn: 70.4444 - fn: 7.2222 - accuracy: 0.9067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7146 - f1: 0.0000e+00 - val_loss: 0.2831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7922 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.78831 to 0.79216, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4437 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.2222 - fn: 7.0000 - accuracy: 0.8708 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6752 - f1: 0.0000e+00 - val_loss: 0.2896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7925 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc improved from 0.79216 to 0.79252, saving model to gs://new_cxr_30/models/cxr_model/model-021.h5\n","Epoch 22/500\n","8/8 [==============================] - 29s 4s/step - loss: 2.3737 - tp: 0.0000e+00 - fp: 0.5556 - tn: 68.5556 - fn: 9.1111 - accuracy: 0.9044 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7952 - f1: 0.0000e+00 - val_loss: 0.2773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7985 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.79252 to 0.79853, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.8632 - tp: 1.5556 - fp: 11.7778 - tn: 56.8889 - fn: 8.0000 - accuracy: 0.7416 - precision: 0.1068 - recall: 0.1761 - auc: 0.5782 - f1: 0.0959 - val_loss: 0.2841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7897 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.79853\n","Epoch 24/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.6443 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.5556 - fn: 8.6667 - accuracy: 0.8930 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7029 - f1: 0.0000e+00 - val_loss: 0.2813 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7943 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.79853\n","Epoch 25/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.3326 - tp: 0.0000e+00 - fp: 3.1111 - tn: 68.3333 - fn: 6.7778 - accuracy: 0.8719 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5706 - f1: 0.0000e+00 - val_loss: 0.2793 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8002 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc improved from 0.79853 to 0.80022, saving model to gs://new_cxr_30/models/cxr_model/model-025.h5\n","Epoch 26/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.0681 - tp: 2.0000 - fp: 2.0000 - tn: 66.5556 - fn: 7.6667 - accuracy: 0.8782 - precision: 0.5370 - recall: 0.2243 - auc: 0.8360 - f1: 0.2312 - val_loss: 0.2786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7992 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.80022\n","Epoch 27/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.7660 - tp: 1.0000 - fp: 0.0000e+00 - tn: 69.0000 - fn: 8.2222 - accuracy: 0.8894 - precision: 1.0000 - recall: 0.1384 - auc: 0.8599 - f1: 0.1263 - val_loss: 0.2776 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7958 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.80022\n","Epoch 28/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.8750 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.2222 - fn: 7.1111 - accuracy: 0.9062 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6469 - f1: 0.0000e+00 - val_loss: 0.2749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7968 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.80022\n","Epoch 29/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.5457 - tp: 1.3333 - fp: 2.7778 - tn: 66.6667 - fn: 7.4444 - accuracy: 0.8844 - precision: 0.2500 - recall: 0.1424 - auc: 0.6599 - f1: 0.1084 - val_loss: 0.2756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7964 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.80022\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.4436 - tp: 0.0000e+00 - fp: 2.2222 - tn: 67.1111 - fn: 8.8889 - accuracy: 0.8635 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4831 - f1: 0.0000e+00 - val_loss: 0.2772 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7971 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.80022\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.9141 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.4444 - fn: 6.7778 - accuracy: 0.8989 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6628 - f1: 0.0000e+00 - val_loss: 0.2771 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7972 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.80022\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.9944 - tp: 0.2222 - fp: 0.0000e+00 - tn: 69.1111 - fn: 8.8889 - accuracy: 0.9060 - precision: 0.2222 - recall: 0.0117 - auc: 0.7465 - f1: 0.0111 - val_loss: 0.2761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7927 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.80022\n","Epoch 33/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.3798 - tp: 1.6667 - fp: 8.8889 - tn: 61.6667 - fn: 6.0000 - accuracy: 0.7974 - precision: 0.1480 - recall: 0.2003 - auc: 0.6607 - f1: 0.1182 - val_loss: 0.2816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7964 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.80022\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6552 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.1111 - fn: 10.1111 - accuracy: 0.8628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7390 - f1: 0.0000e+00 - val_loss: 0.2786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7934 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.80022\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.1299 - tp: 0.2222 - fp: 5.5556 - tn: 63.8889 - fn: 8.5556 - accuracy: 0.8141 - precision: 0.0185 - recall: 0.0185 - auc: 0.6736 - f1: 0.0139 - val_loss: 0.2770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7942 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.80022\n","Restoring model weights from the end of the best epoch.\n","Epoch 00035: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r  4%|▍         | 1/24 [12:21<4:44:12, 741.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 8.2475 - tp: 1.4444 - fp: 4.6667 - tn: 62.5556 - fn: 9.5556 - accuracy: 0.8467 - precision: 0.1071 - recall: 0.0811 - auc: 0.3796 - f1: 0.0462 - val_loss: 0.3093 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6866 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.68658, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6452 - tp: 0.0000e+00 - fp: 1.0000 - tn: 71.7778 - fn: 5.4444 - accuracy: 0.9246 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4351 - f1: 0.0000e+00 - val_loss: 0.3018 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7613 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.68658 to 0.76132, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.0748 - tp: 1.8889 - fp: 10.1111 - tn: 57.2222 - fn: 9.0000 - accuracy: 0.7709 - precision: 0.1536 - recall: 0.1770 - auc: 0.5300 - f1: 0.1367 - val_loss: 0.2966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7808 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.76132 to 0.78084, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.1576 - tp: 0.5556 - fp: 3.5556 - tn: 66.4444 - fn: 7.6667 - accuracy: 0.8456 - precision: 0.0884 - recall: 0.0534 - auc: 0.3516 - f1: 0.0422 - val_loss: 0.2952 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7828 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.78084 to 0.78278, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5688 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.7778 - fn: 6.5556 - accuracy: 0.9035 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5500 - f1: 0.0000e+00 - val_loss: 0.2935 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7852 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.78278 to 0.78525, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 6.9882 - tp: 0.0000e+00 - fp: 1.1111 - tn: 64.7778 - fn: 12.3333 - accuracy: 0.8221 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4943 - f1: 0.0000e+00 - val_loss: 0.2956 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7784 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.78525\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.2108 - tp: 2.6667 - fp: 6.4444 - tn: 61.1111 - fn: 8.0000 - accuracy: 0.8139 - precision: 0.3237 - recall: 0.3318 - auc: 0.6353 - f1: 0.3275 - val_loss: 0.2895 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7847 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.78525\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7422 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.1111 - fn: 7.2222 - accuracy: 0.9089 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5116 - f1: 0.0000e+00 - val_loss: 0.2902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7804 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.78525\n","Epoch 9/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7765 - tp: 1.0000 - fp: 2.4444 - tn: 68.3333 - fn: 6.4444 - accuracy: 0.8741 - precision: 0.3148 - recall: 0.1620 - auc: 0.6137 - f1: 0.1263 - val_loss: 0.2869 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7890 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.78525 to 0.78901, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1756 - tp: 0.0000e+00 - fp: 0.6667 - tn: 71.1111 - fn: 6.4444 - accuracy: 0.8994 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6390 - f1: 0.0000e+00 - val_loss: 0.2858 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7946 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.78901 to 0.79460, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3313 - tp: 2.2222 - fp: 1.6667 - tn: 66.2222 - fn: 8.1111 - accuracy: 0.8766 - precision: 0.6074 - recall: 0.2553 - auc: 0.7745 - f1: 0.2894 - val_loss: 0.2841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7951 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.79460 to 0.79508, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.9030 - tp: 1.3333 - fp: 4.8889 - tn: 61.4444 - fn: 10.5556 - accuracy: 0.7995 - precision: 0.1963 - recall: 0.1164 - auc: 0.6096 - f1: 0.1201 - val_loss: 0.2826 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7943 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.79508\n","Epoch 13/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0984 - tp: 0.0000e+00 - fp: 3.2222 - tn: 65.0000 - fn: 10.0000 - accuracy: 0.8138 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6280 - f1: 0.0000e+00 - val_loss: 0.2795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7956 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.79508 to 0.79556, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2144 - tp: 0.0000e+00 - fp: 2.2222 - tn: 67.3333 - fn: 8.6667 - accuracy: 0.8469 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5694 - f1: 0.0000e+00 - val_loss: 0.2795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7899 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.79556\n","Epoch 15/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6224 - tp: 0.0000e+00 - fp: 2.5556 - tn: 65.2222 - fn: 10.4444 - accuracy: 0.8336 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5844 - f1: 0.0000e+00 - val_loss: 0.2790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7885 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.79556\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.8889 - fn: 8.3333 - accuracy: 0.8961 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7844 - f1: 0.0000e+00 - val_loss: 0.2773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7869 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.79556\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2878 - tp: 1.8889 - fp: 3.5556 - tn: 67.3333 - fn: 5.4444 - accuracy: 0.8708 - precision: 0.3804 - recall: 0.2826 - auc: 0.7481 - f1: 0.3101 - val_loss: 0.2786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7890 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.79556\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0756 - tp: 0.5556 - fp: 0.8889 - tn: 69.6667 - fn: 7.1111 - accuracy: 0.9038 - precision: 0.3148 - recall: 0.0508 - auc: 0.5360 - f1: 0.0338 - val_loss: 0.2738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7949 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.79556\n","Epoch 19/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7016 - tp: 0.0000e+00 - fp: 2.3333 - tn: 68.4444 - fn: 7.4444 - accuracy: 0.8659 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6521 - f1: 0.0000e+00 - val_loss: 0.2773 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7974 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.79556 to 0.79741, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0914 - tp: 0.5556 - fp: 1.5556 - tn: 69.4444 - fn: 6.6667 - accuracy: 0.9037 - precision: 0.2315 - recall: 0.0538 - auc: 0.6868 - f1: 0.0422 - val_loss: 0.2762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7963 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.79741\n","Epoch 21/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7481 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.2222 - fn: 7.0000 - accuracy: 0.8905 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6289 - f1: 0.0000e+00 - val_loss: 0.2803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7987 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc improved from 0.79741 to 0.79867, saving model to gs://new_cxr_30/models/cxr_model/model-021.h5\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.5557 - tp: 0.3333 - fp: 0.2222 - tn: 68.8889 - fn: 8.7778 - accuracy: 0.9098 - precision: 0.2222 - recall: 0.0185 - auc: 0.7492 - f1: 0.0175 - val_loss: 0.2759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8039 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.79867 to 0.80390, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5041 - tp: 3.1111 - fp: 8.1111 - tn: 60.5556 - fn: 6.4444 - accuracy: 0.8168 - precision: 0.2614 - recall: 0.3817 - auc: 0.6486 - f1: 0.2004 - val_loss: 0.2777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8009 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.80390\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.5556 - fn: 8.6667 - accuracy: 0.8930 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7805 - f1: 0.0000e+00 - val_loss: 0.2746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7999 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.80390\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8859 - tp: 1.5556 - fp: 2.0000 - tn: 69.4444 - fn: 5.2222 - accuracy: 0.9119 - precision: 0.4074 - recall: 0.2271 - auc: 0.6928 - f1: 0.1585 - val_loss: 0.2747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8025 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.80390\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3588 - tp: 0.6667 - fp: 0.5556 - tn: 68.0000 - fn: 9.0000 - accuracy: 0.8756 - precision: 0.4630 - recall: 0.0553 - auc: 0.6125 - f1: 0.0561 - val_loss: 0.2716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8042 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc improved from 0.80390 to 0.80421, saving model to gs://new_cxr_30/models/cxr_model/model-026.h5\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9356 - tp: 3.0000 - fp: 1.8889 - tn: 67.1111 - fn: 6.2222 - accuracy: 0.8963 - precision: 0.6167 - recall: 0.4153 - auc: 0.8453 - f1: 0.2369 - val_loss: 0.2731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7999 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.80421\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2030 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.1111 - fn: 7.1111 - accuracy: 0.9190 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5236 - f1: 0.0000e+00 - val_loss: 0.2693 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8047 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc improved from 0.80421 to 0.80466, saving model to gs://new_cxr_30/models/cxr_model/model-028.h5\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4446 - tp: 0.3333 - fp: 3.3333 - tn: 66.1111 - fn: 8.4444 - accuracy: 0.8651 - precision: 0.0556 - recall: 0.0218 - auc: 0.7058 - f1: 0.0291 - val_loss: 0.2702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8061 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc improved from 0.80466 to 0.80615, saving model to gs://new_cxr_30/models/cxr_model/model-029.h5\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6704 - tp: 0.0000e+00 - fp: 0.8889 - tn: 68.4444 - fn: 8.8889 - accuracy: 0.8762 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4462 - f1: 0.0000e+00 - val_loss: 0.2707 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8043 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.80615\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.8836 - tp: 1.0000 - fp: 1.6667 - tn: 69.7778 - fn: 5.7778 - accuracy: 0.9116 - precision: 0.3889 - recall: 0.2809 - auc: 0.7242 - f1: 0.2106 - val_loss: 0.2731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8032 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.80615\n","Epoch 32/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0212 - tp: 0.8889 - fp: 0.0000e+00 - tn: 69.1111 - fn: 8.2222 - accuracy: 0.9116 - precision: 0.4444 - recall: 0.0504 - auc: 0.7395 - f1: 0.0341 - val_loss: 0.2724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8014 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.80615\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.1884 - tp: 3.3333 - fp: 8.6667 - tn: 61.8889 - fn: 4.3333 - accuracy: 0.8267 - precision: 0.2873 - recall: 0.4958 - auc: 0.7051 - f1: 0.3062 - val_loss: 0.2809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8047 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.80615\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.8460 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.1111 - fn: 10.1111 - accuracy: 0.8628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7453 - f1: 0.0000e+00 - val_loss: 0.2736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8013 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.80615\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.1965 - tp: 0.2222 - fp: 3.3333 - tn: 66.1111 - fn: 8.5556 - accuracy: 0.8477 - precision: 0.0247 - recall: 0.0185 - auc: 0.3885 - f1: 0.0185 - val_loss: 0.2739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8026 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.80615\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7615 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.1111 - fn: 11.1111 - accuracy: 0.8625 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7943 - f1: 0.0000e+00 - val_loss: 0.2731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7997 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.80615\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.8913 - tp: 0.4444 - fp: 3.1111 - tn: 61.8889 - fn: 12.7778 - accuracy: 0.8026 - precision: 0.0494 - recall: 0.0185 - auc: 0.8003 - f1: 0.0111 - val_loss: 0.2703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7973 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.80615\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.1434 - tp: 0.0000e+00 - fp: 5.3333 - tn: 66.4444 - fn: 6.4444 - accuracy: 0.8280 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5153 - f1: 0.0000e+00 - val_loss: 0.2805 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8027 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.80615\n","Epoch 39/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.5511 - tp: 0.0000e+00 - fp: 0.8889 - tn: 66.1111 - fn: 11.2222 - accuracy: 0.8372 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6605 - f1: 0.0000e+00 - val_loss: 0.2679 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8032 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.80615\n","Restoring model weights from the end of the best epoch.\n","Epoch 00039: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r  8%|▊         | 2/24 [25:10<4:37:42, 757.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 12.4670 - tp: 1.5556 - fp: 6.4444 - tn: 60.7778 - fn: 9.4444 - accuracy: 0.8288 - precision: 0.1090 - recall: 0.1008 - auc: 0.3414 - f1: 0.0508 - val_loss: 0.3168 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5619 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.56188, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9406 - tp: 0.0000e+00 - fp: 3.2222 - tn: 69.5556 - fn: 5.4444 - accuracy: 0.9040 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4071 - f1: 0.0000e+00 - val_loss: 0.3069 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7170 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.56188 to 0.71703, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 17s 2s/step - loss: 5.5788 - tp: 0.6667 - fp: 5.4444 - tn: 61.8889 - fn: 10.2222 - accuracy: 0.7993 - precision: 0.0722 - recall: 0.0385 - auc: 0.6157 - f1: 0.0388 - val_loss: 0.3017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7546 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.71703 to 0.75455, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 17s 2s/step - loss: 6.9459 - tp: 0.5556 - fp: 6.7778 - tn: 63.2222 - fn: 7.6667 - accuracy: 0.7980 - precision: 0.0556 - recall: 0.0534 - auc: 0.3964 - f1: 0.0563 - val_loss: 0.2963 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7687 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.75455 to 0.76871, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 17s 2s/step - loss: 4.7963 - tp: 0.0000e+00 - fp: 3.8889 - tn: 67.7778 - fn: 6.5556 - accuracy: 0.8819 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5453 - f1: 0.0000e+00 - val_loss: 0.2950 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7698 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.76871 to 0.76980, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.5066 - tp: 0.3333 - fp: 0.4444 - tn: 65.4444 - fn: 12.0000 - accuracy: 0.8311 - precision: 0.1852 - recall: 0.0173 - auc: 0.5780 - f1: 0.0146 - val_loss: 0.2957 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7824 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.76980 to 0.78238, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.7546 - tp: 3.6667 - fp: 12.5556 - tn: 55.0000 - fn: 7.0000 - accuracy: 0.7169 - precision: 0.2298 - recall: 0.4292 - auc: 0.6502 - f1: 0.2491 - val_loss: 0.2914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7854 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.78238 to 0.78545, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9113 - tp: 0.0000e+00 - fp: 1.8889 - tn: 69.1111 - fn: 7.2222 - accuracy: 0.8984 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5230 - f1: 0.0000e+00 - val_loss: 0.2921 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7902 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.78545 to 0.79019, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 17s 2s/step - loss: 4.1321 - tp: 0.3333 - fp: 3.4444 - tn: 67.3333 - fn: 7.1111 - accuracy: 0.8589 - precision: 0.0476 - recall: 0.0286 - auc: 0.6133 - f1: 0.0146 - val_loss: 0.2906 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7889 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.79019\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0588 - tp: 0.0000e+00 - fp: 2.1111 - tn: 69.6667 - fn: 6.4444 - accuracy: 0.8790 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5677 - f1: 0.0000e+00 - val_loss: 0.2891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7886 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.79019\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9065 - tp: 1.5556 - fp: 6.6667 - tn: 61.2222 - fn: 8.7778 - accuracy: 0.8025 - precision: 0.1162 - recall: 0.1028 - auc: 0.6184 - f1: 0.0966 - val_loss: 0.2870 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7949 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.79019 to 0.79491, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 17s 2s/step - loss: 4.9586 - tp: 0.0000e+00 - fp: 2.5556 - tn: 63.7778 - fn: 11.8889 - accuracy: 0.8256 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5683 - f1: 0.0000e+00 - val_loss: 0.2836 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7947 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.79491\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0012 - tp: 2.7778 - fp: 5.0000 - tn: 63.2222 - fn: 7.2222 - accuracy: 0.8471 - precision: 0.3626 - recall: 0.2983 - auc: 0.7263 - f1: 0.2890 - val_loss: 0.2835 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7933 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.79491\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.0093 - tp: 0.0000e+00 - fp: 2.4444 - tn: 67.1111 - fn: 8.6667 - accuracy: 0.8559 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5757 - f1: 0.0000e+00 - val_loss: 0.2798 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7916 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.79491\n","Epoch 15/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.1182 - tp: 0.6667 - fp: 4.3333 - tn: 63.4444 - fn: 9.7778 - accuracy: 0.8166 - precision: 0.1131 - recall: 0.0497 - auc: 0.5800 - f1: 0.0374 - val_loss: 0.2795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7954 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc improved from 0.79491 to 0.79544, saving model to gs://new_cxr_30/models/cxr_model/model-015.h5\n","Epoch 16/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.3014 - tp: 0.0000e+00 - fp: 0.4444 - tn: 69.4444 - fn: 8.3333 - accuracy: 0.8923 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7262 - f1: 0.0000e+00 - val_loss: 0.2780 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7927 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.79544\n","Epoch 17/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.1620 - tp: 1.5556 - fp: 5.5556 - tn: 65.3333 - fn: 5.7778 - accuracy: 0.8452 - precision: 0.3023 - recall: 0.2160 - auc: 0.8181 - f1: 0.1685 - val_loss: 0.2846 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7918 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.79544\n","Epoch 18/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.6921 - tp: 1.1111 - fp: 1.2222 - tn: 69.3333 - fn: 6.5556 - accuracy: 0.9104 - precision: 0.6574 - recall: 0.1527 - auc: 0.6394 - f1: 0.1550 - val_loss: 0.2775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7959 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.79544 to 0.79595, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.3318 - tp: 2.0000 - fp: 4.2222 - tn: 66.5556 - fn: 5.4444 - accuracy: 0.8729 - precision: 0.3460 - recall: 0.3414 - auc: 0.5821 - f1: 0.2106 - val_loss: 0.2831 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7989 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.79595 to 0.79890, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5305 - tp: 0.3333 - fp: 2.8889 - tn: 68.1111 - fn: 6.8889 - accuracy: 0.8900 - precision: 0.0381 - recall: 0.0303 - auc: 0.6704 - f1: 0.0146 - val_loss: 0.2775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8031 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.79890 to 0.80314, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7415 - tp: 0.0000e+00 - fp: 1.5556 - tn: 69.6667 - fn: 7.0000 - accuracy: 0.8719 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6573 - f1: 0.0000e+00 - val_loss: 0.2871 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7969 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.80314\n","Epoch 22/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.0972 - tp: 0.3333 - fp: 2.0000 - tn: 67.1111 - fn: 8.7778 - accuracy: 0.8935 - precision: 0.0593 - recall: 0.0185 - auc: 0.7147 - f1: 0.0125 - val_loss: 0.2720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8090 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.80314 to 0.80898, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.5320 - tp: 3.1111 - fp: 11.4444 - tn: 57.2222 - fn: 6.4444 - accuracy: 0.7536 - precision: 0.1978 - recall: 0.3817 - auc: 0.5686 - f1: 0.1477 - val_loss: 0.2789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8077 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.80898\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7643 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.5556 - fn: 8.6667 - accuracy: 0.8930 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6743 - f1: 0.0000e+00 - val_loss: 0.2746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8087 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.80898\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1642 - tp: 0.8889 - fp: 1.4444 - tn: 70.0000 - fn: 5.8889 - accuracy: 0.9045 - precision: 0.3704 - recall: 0.1459 - auc: 0.6622 - f1: 0.1365 - val_loss: 0.2747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8040 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.80898\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8829 - tp: 1.0000 - fp: 4.6667 - tn: 63.8889 - fn: 8.6667 - accuracy: 0.8365 - precision: 0.1075 - recall: 0.0727 - auc: 0.7123 - f1: 0.0545 - val_loss: 0.2767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8029 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.80898\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8697 - tp: 0.0000e+00 - fp: 0.5556 - tn: 68.4444 - fn: 9.2222 - accuracy: 0.8652 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7834 - f1: 0.0000e+00 - val_loss: 0.2697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8074 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.80898\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3512 - tp: 0.8889 - fp: 3.4444 - tn: 67.6667 - fn: 6.2222 - accuracy: 0.8841 - precision: 0.1833 - recall: 0.1929 - auc: 0.7145 - f1: 0.0819 - val_loss: 0.2724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8096 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc improved from 0.80898 to 0.80957, saving model to gs://new_cxr_30/models/cxr_model/model-028.h5\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5244 - tp: 1.1111 - fp: 4.8889 - tn: 64.5556 - fn: 7.6667 - accuracy: 0.8587 - precision: 0.1231 - recall: 0.0869 - auc: 0.6851 - f1: 0.0675 - val_loss: 0.2708 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8103 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc improved from 0.80957 to 0.81030, saving model to gs://new_cxr_30/models/cxr_model/model-029.h5\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.6488 - tp: 0.0000e+00 - fp: 3.8889 - tn: 65.4444 - fn: 8.8889 - accuracy: 0.8319 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4267 - f1: 0.0000e+00 - val_loss: 0.2728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8082 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.81030\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6110 - tp: 1.0000 - fp: 0.4444 - tn: 71.0000 - fn: 5.7778 - accuracy: 0.9345 - precision: 0.7778 - recall: 0.2809 - auc: 0.7551 - f1: 0.3159 - val_loss: 0.2747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8078 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.81030\n","Epoch 32/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8744 - tp: 0.6667 - fp: 0.8889 - tn: 68.2222 - fn: 8.4444 - accuracy: 0.8966 - precision: 0.1667 - recall: 0.0351 - auc: 0.6374 - f1: 0.0238 - val_loss: 0.2736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8047 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.81030\n","Epoch 33/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6437 - tp: 0.7778 - fp: 10.4444 - tn: 60.1111 - fn: 6.8889 - accuracy: 0.7628 - precision: 0.0597 - recall: 0.0862 - auc: 0.6311 - f1: 0.0373 - val_loss: 0.2876 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8047 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.81030\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.6280 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.1111 - fn: 10.1111 - accuracy: 0.8628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6448 - f1: 0.0000e+00 - val_loss: 0.2744 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8053 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.81030\n","Epoch 35/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5464 - tp: 0.2222 - fp: 5.3333 - tn: 64.1111 - fn: 8.5556 - accuracy: 0.8206 - precision: 0.0222 - recall: 0.0185 - auc: 0.5604 - f1: 0.0185 - val_loss: 0.2799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8111 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc improved from 0.81030 to 0.81109, saving model to gs://new_cxr_30/models/cxr_model/model-035.h5\n","Epoch 36/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.9793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.1111 - fn: 11.1111 - accuracy: 0.8625 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7060 - f1: 0.0000e+00 - val_loss: 0.2731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8115 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc improved from 0.81109 to 0.81154, saving model to gs://new_cxr_30/models/cxr_model/model-036.h5\n","Epoch 37/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2654 - tp: 1.8889 - fp: 5.4444 - tn: 59.5556 - fn: 11.3333 - accuracy: 0.7912 - precision: 0.2984 - recall: 0.1879 - auc: 0.7044 - f1: 0.2083 - val_loss: 0.2686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8092 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.81154\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.5157 - tp: 0.0000e+00 - fp: 5.5556 - tn: 66.2222 - fn: 6.4444 - accuracy: 0.8460 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6541 - f1: 0.0000e+00 - val_loss: 0.2810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8082 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.81154\n","Epoch 39/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.1090 - tp: 0.0000e+00 - fp: 1.4444 - tn: 65.5556 - fn: 11.2222 - accuracy: 0.8318 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7295 - f1: 0.0000e+00 - val_loss: 0.2659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8096 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.81154\n","Epoch 40/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.4904 - tp: 0.8889 - fp: 6.0000 - tn: 64.2222 - fn: 7.1111 - accuracy: 0.7824 - precision: 0.1270 - recall: 0.1116 - auc: 0.7467 - f1: 0.0819 - val_loss: 0.2829 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8091 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc did not improve from 0.81154\n","Epoch 41/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.8681 - tp: 1.5556 - fp: 2.8889 - tn: 62.0000 - fn: 11.7778 - accuracy: 0.8326 - precision: 0.2656 - recall: 0.0780 - auc: 0.6199 - f1: 0.0977 - val_loss: 0.2707 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8079 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc did not improve from 0.81154\n","Epoch 42/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.8987 - tp: 1.8889 - fp: 4.0000 - tn: 65.5556 - fn: 6.7778 - accuracy: 0.8388 - precision: 0.3185 - recall: 0.2781 - auc: 0.7141 - f1: 0.2268 - val_loss: 0.2732 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8107 - val_f1: 0.0000e+00\n","\n","Epoch 00042: val_auc did not improve from 0.81154\n","Epoch 43/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.6150 - tp: 0.0000e+00 - fp: 1.6667 - tn: 64.0000 - fn: 12.5556 - accuracy: 0.8158 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6054 - f1: 0.0000e+00 - val_loss: 0.2697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8106 - val_f1: 0.0000e+00\n","\n","Epoch 00043: val_auc did not improve from 0.81154\n","Epoch 44/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.7723 - tp: 0.8889 - fp: 4.8889 - tn: 62.1111 - fn: 10.3333 - accuracy: 0.7901 - precision: 0.1460 - recall: 0.0835 - auc: 0.6038 - f1: 0.0683 - val_loss: 0.2719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8100 - val_f1: 0.0000e+00\n","\n","Epoch 00044: val_auc did not improve from 0.81154\n","Epoch 45/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0744 - tp: 0.0000e+00 - fp: 0.8889 - tn: 72.1111 - fn: 5.2222 - accuracy: 0.9231 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4537 - f1: 0.0000e+00 - val_loss: 0.2759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8100 - val_f1: 0.0000e+00\n","\n","Epoch 00045: val_auc did not improve from 0.81154\n","Epoch 46/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2178 - tp: 0.4444 - fp: 0.8889 - tn: 65.0000 - fn: 11.8889 - accuracy: 0.8491 - precision: 0.1481 - recall: 0.0237 - auc: 0.8289 - f1: 0.0249 - val_loss: 0.2748 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8097 - val_f1: 0.0000e+00\n","\n","Epoch 00046: val_auc did not improve from 0.81154\n","Restoring model weights from the end of the best epoch.\n","Epoch 00046: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 12%|█▎        | 3/24 [39:48<4:44:26, 812.70s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 15.6838 - tp: 0.2222 - fp: 6.1111 - tn: 61.1111 - fn: 10.7778 - accuracy: 0.7814 - precision: 0.0171 - recall: 0.0111 - auc: 0.3372 - f1: 0.0062 - val_loss: 0.3235 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6055 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.60547, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 17s 2s/step - loss: 15.2068 - tp: 0.0000e+00 - fp: 14.6667 - tn: 58.1111 - fn: 5.4444 - accuracy: 0.7199 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2972 - f1: 0.0000e+00 - val_loss: 0.3026 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7300 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.60547 to 0.73003, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 17s 2s/step - loss: 12.6844 - tp: 1.0000 - fp: 1.6667 - tn: 65.6667 - fn: 9.8889 - accuracy: 0.8588 - precision: 0.2519 - recall: 0.0567 - auc: 0.4973 - f1: 0.0456 - val_loss: 0.3085 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7649 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.73003 to 0.76494, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 17s 2s/step - loss: 9.7319 - tp: 4.0000 - fp: 13.7778 - tn: 56.2222 - fn: 4.2222 - accuracy: 0.7267 - precision: 0.2316 - recall: 0.5841 - auc: 0.6280 - f1: 0.1685 - val_loss: 0.2994 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7490 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc did not improve from 0.76494\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.0351 - tp: 0.0000e+00 - fp: 2.0000 - tn: 69.6667 - fn: 6.5556 - accuracy: 0.8946 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4596 - f1: 0.0000e+00 - val_loss: 0.3014 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7801 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.76494 to 0.78011, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.3027 - tp: 0.5556 - fp: 7.2222 - tn: 58.6667 - fn: 11.7778 - accuracy: 0.7389 - precision: 0.0548 - recall: 0.0351 - auc: 0.4090 - f1: 0.0563 - val_loss: 0.2989 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7739 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.78011\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.2293 - tp: 0.0000e+00 - fp: 3.3333 - tn: 64.2222 - fn: 10.6667 - accuracy: 0.8177 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3685 - f1: 0.0000e+00 - val_loss: 0.2962 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7821 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.78011 to 0.78208, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7543 - tp: 0.0000e+00 - fp: 1.6667 - tn: 69.3333 - fn: 7.2222 - accuracy: 0.8895 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5316 - f1: 0.0000e+00 - val_loss: 0.2951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7873 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.78208 to 0.78727, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.4370 - tp: 1.3333 - fp: 6.2222 - tn: 64.5556 - fn: 6.1111 - accuracy: 0.8456 - precision: 0.2986 - recall: 0.1906 - auc: 0.7500 - f1: 0.1704 - val_loss: 0.2928 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7860 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.78727\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.6039 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.7778 - fn: 6.4444 - accuracy: 0.9050 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6290 - f1: 0.0000e+00 - val_loss: 0.2914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7887 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.78727 to 0.78868, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.1159 - tp: 2.6667 - fp: 3.7778 - tn: 64.1111 - fn: 7.6667 - accuracy: 0.8518 - precision: 0.4056 - recall: 0.2142 - auc: 0.6808 - f1: 0.2497 - val_loss: 0.2888 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7891 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.78868 to 0.78910, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.3318 - tp: 0.6667 - fp: 3.1111 - tn: 63.2222 - fn: 11.2222 - accuracy: 0.8258 - precision: 0.1000 - recall: 0.0353 - auc: 0.5715 - f1: 0.0318 - val_loss: 0.2869 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7973 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.78910 to 0.79727, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.8844 - tp: 0.7778 - fp: 2.8889 - tn: 65.3333 - fn: 9.2222 - accuracy: 0.8318 - precision: 0.1944 - recall: 0.0723 - auc: 0.4291 - f1: 0.0746 - val_loss: 0.2842 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7949 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.79727\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.7833 - tp: 0.0000e+00 - fp: 2.4444 - tn: 67.1111 - fn: 8.6667 - accuracy: 0.8511 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4482 - f1: 0.0000e+00 - val_loss: 0.2830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7922 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.79727\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.9646 - tp: 0.0000e+00 - fp: 2.3333 - tn: 65.4444 - fn: 10.4444 - accuracy: 0.8294 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3920 - f1: 0.0000e+00 - val_loss: 0.2812 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7888 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.79727\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3560 - tp: 0.6667 - fp: 1.1111 - tn: 68.7778 - fn: 7.6667 - accuracy: 0.8923 - precision: 0.2593 - recall: 0.0653 - auc: 0.6721 - f1: 0.0561 - val_loss: 0.2788 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7885 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.79727\n","Epoch 17/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.3553 - tp: 0.0000e+00 - fp: 3.3333 - tn: 67.5556 - fn: 7.3333 - accuracy: 0.8487 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7552 - f1: 0.0000e+00 - val_loss: 0.2783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7900 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.79727\n","Epoch 18/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.4880 - tp: 0.0000e+00 - fp: 1.0000 - tn: 69.5556 - fn: 7.6667 - accuracy: 0.8860 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6987 - f1: 0.0000e+00 - val_loss: 0.2740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7940 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.79727\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.1893 - tp: 1.8889 - fp: 4.7778 - tn: 66.0000 - fn: 5.5556 - accuracy: 0.8659 - precision: 0.3593 - recall: 0.3043 - auc: 0.6799 - f1: 0.2398 - val_loss: 0.2815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7916 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.79727\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6855 - tp: 0.3333 - fp: 2.4444 - tn: 68.5556 - fn: 6.8889 - accuracy: 0.8937 - precision: 0.0469 - recall: 0.0303 - auc: 0.6858 - f1: 0.0218 - val_loss: 0.2765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7976 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.79727 to 0.79764, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9911 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.2222 - fn: 7.0000 - accuracy: 0.8708 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6036 - f1: 0.0000e+00 - val_loss: 0.2834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7970 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.79764\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1848 - tp: 0.0000e+00 - fp: 1.4444 - tn: 67.6667 - fn: 9.1111 - accuracy: 0.8970 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6979 - f1: 0.0000e+00 - val_loss: 0.2763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8019 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.79764 to 0.80190, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2319 - tp: 3.1111 - fp: 9.2222 - tn: 59.4444 - fn: 6.4444 - accuracy: 0.8114 - precision: 0.2378 - recall: 0.3817 - auc: 0.7025 - f1: 0.1543 - val_loss: 0.2760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8013 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.80190\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3670 - tp: 0.0000e+00 - fp: 0.3333 - tn: 69.2222 - fn: 8.6667 - accuracy: 0.8903 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7434 - f1: 0.0000e+00 - val_loss: 0.2730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8014 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.80190\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4294 - tp: 1.5556 - fp: 4.7778 - tn: 66.6667 - fn: 5.2222 - accuracy: 0.8781 - precision: 0.2601 - recall: 0.2271 - auc: 0.6487 - f1: 0.1926 - val_loss: 0.2769 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7988 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.80190\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5427 - tp: 1.0000 - fp: 2.8889 - tn: 65.6667 - fn: 8.6667 - accuracy: 0.8528 - precision: 0.1548 - recall: 0.0727 - auc: 0.8216 - f1: 0.0586 - val_loss: 0.2716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8033 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc improved from 0.80190 to 0.80334, saving model to gs://new_cxr_30/models/cxr_model/model-026.h5\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4899 - tp: 2.6667 - fp: 2.8889 - tn: 66.1111 - fn: 6.5556 - accuracy: 0.8738 - precision: 0.4947 - recall: 0.3375 - auc: 0.7775 - f1: 0.2366 - val_loss: 0.2708 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8020 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.80334\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9079 - tp: 0.0000e+00 - fp: 1.3333 - tn: 69.7778 - fn: 7.1111 - accuracy: 0.9079 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7010 - f1: 0.0000e+00 - val_loss: 0.2668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8038 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc improved from 0.80334 to 0.80381, saving model to gs://new_cxr_30/models/cxr_model/model-028.h5\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.1051 - tp: 0.7778 - fp: 6.8889 - tn: 62.5556 - fn: 8.0000 - accuracy: 0.8065 - precision: 0.0880 - recall: 0.0990 - auc: 0.6507 - f1: 0.0746 - val_loss: 0.2734 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8011 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.80381\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.8037 - tp: 0.0000e+00 - fp: 5.7778 - tn: 63.5556 - fn: 8.8889 - accuracy: 0.8246 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5269 - f1: 0.0000e+00 - val_loss: 0.2729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8002 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.80381\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9863 - tp: 1.0000 - fp: 1.8889 - tn: 69.5556 - fn: 5.7778 - accuracy: 0.9058 - precision: 0.3519 - recall: 0.2809 - auc: 0.6679 - f1: 0.2106 - val_loss: 0.2739 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7965 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.80381\n","Epoch 32/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0896 - tp: 0.4444 - fp: 1.8889 - tn: 67.2222 - fn: 8.6667 - accuracy: 0.8751 - precision: 0.1111 - recall: 0.0234 - auc: 0.7663 - f1: 0.0185 - val_loss: 0.2725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7911 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.80381\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.2213 - tp: 2.6667 - fp: 10.2222 - tn: 60.3333 - fn: 5.0000 - accuracy: 0.7952 - precision: 0.2192 - recall: 0.4254 - auc: 0.7527 - f1: 0.2443 - val_loss: 0.2954 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7935 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.80381\n","Epoch 34/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.7398 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.1111 - fn: 10.1111 - accuracy: 0.8628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6977 - f1: 0.0000e+00 - val_loss: 0.2741 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7973 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.80381\n","Epoch 35/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5437 - tp: 2.2222 - fp: 8.1111 - tn: 61.3333 - fn: 6.5556 - accuracy: 0.7993 - precision: 0.2131 - recall: 0.2265 - auc: 0.6397 - f1: 0.1697 - val_loss: 0.2874 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8013 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.80381\n","Epoch 36/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.9799 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.1111 - fn: 11.1111 - accuracy: 0.8625 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7732 - f1: 0.0000e+00 - val_loss: 0.2683 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8010 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.80381\n","Epoch 37/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0199 - tp: 5.3333 - fp: 8.5556 - tn: 56.4444 - fn: 7.8889 - accuracy: 0.8033 - precision: 0.4486 - recall: 0.4897 - auc: 0.6937 - f1: 0.4092 - val_loss: 0.2726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7983 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.80381\n","Epoch 38/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3731 - tp: 0.0000e+00 - fp: 1.6667 - tn: 70.1111 - fn: 6.4444 - accuracy: 0.8967 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6087 - f1: 0.0000e+00 - val_loss: 0.2716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8021 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.80381\n","Restoring model weights from the end of the best epoch.\n","Epoch 00038: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 17%|█▋        | 4/24 [51:52<4:19:14, 777.73s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 14.5041 - tp: 1.2222 - fp: 6.7778 - tn: 60.4444 - fn: 9.7778 - accuracy: 0.8190 - precision: 0.1008 - recall: 0.0885 - auc: 0.3432 - f1: 0.0531 - val_loss: 0.2995 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7548 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.75480, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.9390 - tp: 0.5556 - fp: 8.2222 - tn: 64.5556 - fn: 4.8889 - accuracy: 0.8222 - precision: 0.0505 - recall: 0.0694 - auc: 0.4374 - f1: 0.0338 - val_loss: 0.2953 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7710 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.75480 to 0.77101, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.6370 - tp: 2.1111 - fp: 11.3333 - tn: 56.0000 - fn: 8.7778 - accuracy: 0.7311 - precision: 0.1636 - recall: 0.2548 - auc: 0.4896 - f1: 0.1626 - val_loss: 0.2914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7803 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.77101 to 0.78028, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.6178 - tp: 0.0000e+00 - fp: 10.5556 - tn: 59.4444 - fn: 8.2222 - accuracy: 0.7358 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2988 - f1: 0.0000e+00 - val_loss: 0.2902 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7787 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc did not improve from 0.78028\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9866 - tp: 0.0000e+00 - fp: 5.3333 - tn: 66.3333 - fn: 6.5556 - accuracy: 0.8626 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4924 - f1: 0.0000e+00 - val_loss: 0.2894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7824 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.78028 to 0.78236, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.5852 - tp: 0.5556 - fp: 2.8889 - tn: 63.0000 - fn: 11.7778 - accuracy: 0.8118 - precision: 0.0626 - recall: 0.0284 - auc: 0.6676 - f1: 0.0194 - val_loss: 0.2855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7829 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.78236 to 0.78292, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.9098 - tp: 2.8889 - fp: 5.4444 - tn: 62.1111 - fn: 7.7778 - accuracy: 0.8360 - precision: 0.3861 - recall: 0.3616 - auc: 0.6814 - f1: 0.3112 - val_loss: 0.2860 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7914 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.78292 to 0.79143, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.2980 - tp: 1.3333 - fp: 5.2222 - tn: 65.7778 - fn: 5.8889 - accuracy: 0.8673 - precision: 0.1616 - recall: 0.1707 - auc: 0.4679 - f1: 0.1168 - val_loss: 0.2903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7915 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.79143 to 0.79148, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0445 - tp: 0.3333 - fp: 2.4444 - tn: 68.3333 - fn: 7.1111 - accuracy: 0.8666 - precision: 0.0667 - recall: 0.0286 - auc: 0.7502 - f1: 0.0125 - val_loss: 0.2855 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7866 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.79148\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9254 - tp: 0.0000e+00 - fp: 9.1111 - tn: 62.6667 - fn: 6.4444 - accuracy: 0.7712 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5244 - f1: 0.0000e+00 - val_loss: 0.2879 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7857 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.79148\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.9667 - tp: 1.3333 - fp: 3.0000 - tn: 64.8889 - fn: 9.0000 - accuracy: 0.8467 - precision: 0.1944 - recall: 0.0951 - auc: 0.5322 - f1: 0.0570 - val_loss: 0.2837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7896 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.79148\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.0984 - tp: 0.0000e+00 - fp: 1.8889 - tn: 64.4444 - fn: 11.8889 - accuracy: 0.8338 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4198 - f1: 0.0000e+00 - val_loss: 0.2807 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7931 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.79148 to 0.79309, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2237 - tp: 0.7778 - fp: 3.1111 - tn: 65.1111 - fn: 9.2222 - accuracy: 0.8393 - precision: 0.1759 - recall: 0.0723 - auc: 0.6256 - f1: 0.0746 - val_loss: 0.2823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7964 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.79309 to 0.79640, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.9988 - tp: 0.0000e+00 - fp: 3.4444 - tn: 66.1111 - fn: 8.6667 - accuracy: 0.8254 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4986 - f1: 0.0000e+00 - val_loss: 0.2820 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7922 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.79640\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.4761 - tp: 0.0000e+00 - fp: 3.6667 - tn: 64.1111 - fn: 10.4444 - accuracy: 0.8074 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5729 - f1: 0.0000e+00 - val_loss: 0.2840 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7897 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.79640\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7119 - tp: 0.5556 - fp: 1.0000 - tn: 68.8889 - fn: 7.7778 - accuracy: 0.8817 - precision: 0.2778 - recall: 0.0494 - auc: 0.7246 - f1: 0.0563 - val_loss: 0.2856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7924 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.79640\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6156 - tp: 0.0000e+00 - fp: 6.2222 - tn: 64.6667 - fn: 7.3333 - accuracy: 0.8084 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7532 - f1: 0.0000e+00 - val_loss: 0.2993 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7912 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.79640\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2555 - tp: 0.5556 - fp: 5.1111 - tn: 65.4444 - fn: 7.1111 - accuracy: 0.8645 - precision: 0.0410 - recall: 0.0471 - auc: 0.6212 - f1: 0.0331 - val_loss: 0.2938 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7962 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.79640\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.5378 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.7778 - fn: 7.4444 - accuracy: 0.8951 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6851 - f1: 0.0000e+00 - val_loss: 0.2918 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8004 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.79640 to 0.80042, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.5516 - tp: 1.3333 - fp: 5.8889 - tn: 65.1111 - fn: 5.8889 - accuracy: 0.8709 - precision: 0.1039 - recall: 0.1255 - auc: 0.6838 - f1: 0.0563 - val_loss: 0.2894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7997 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.80042\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6074 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.2222 - fn: 7.0000 - accuracy: 0.8905 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6052 - f1: 0.0000e+00 - val_loss: 0.2982 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7948 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.80042\n","Epoch 22/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.0947 - tp: 0.6667 - fp: 3.1111 - tn: 66.0000 - fn: 8.4444 - accuracy: 0.8857 - precision: 0.0772 - recall: 0.0370 - auc: 0.7140 - f1: 0.0218 - val_loss: 0.2749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8057 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.80042 to 0.80570, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.6514 - tp: 2.6667 - fp: 7.2222 - tn: 61.4444 - fn: 6.8889 - accuracy: 0.8196 - precision: 0.2409 - recall: 0.2929 - auc: 0.5825 - f1: 0.1438 - val_loss: 0.2832 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8045 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.80570\n","Epoch 24/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.3023 - tp: 1.3333 - fp: 3.0000 - tn: 66.5556 - fn: 7.3333 - accuracy: 0.8688 - precision: 0.2481 - recall: 0.1324 - auc: 0.6439 - f1: 0.1417 - val_loss: 0.2856 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8041 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.80570\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9635 - tp: 0.0000e+00 - fp: 0.3333 - tn: 71.1111 - fn: 6.7778 - accuracy: 0.9126 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6671 - f1: 0.0000e+00 - val_loss: 0.2796 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8045 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.80570\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9943 - tp: 0.0000e+00 - fp: 3.7778 - tn: 64.7778 - fn: 9.6667 - accuracy: 0.8226 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7054 - f1: 0.0000e+00 - val_loss: 0.2830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8036 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.80570\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2333 - tp: 1.5556 - fp: 0.7778 - tn: 68.2222 - fn: 7.6667 - accuracy: 0.8880 - precision: 0.7963 - recall: 0.1832 - auc: 0.8019 - f1: 0.1685 - val_loss: 0.2818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8058 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc improved from 0.80570 to 0.80581, saving model to gs://new_cxr_30/models/cxr_model/model-027.h5\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6195 - tp: 0.0000e+00 - fp: 1.2222 - tn: 69.8889 - fn: 7.1111 - accuracy: 0.9035 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5681 - f1: 0.0000e+00 - val_loss: 0.2717 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8054 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.80581\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.1763 - tp: 0.7778 - fp: 5.8889 - tn: 63.5556 - fn: 8.0000 - accuracy: 0.8262 - precision: 0.0992 - recall: 0.0990 - auc: 0.6958 - f1: 0.0746 - val_loss: 0.2841 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8019 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.80581\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.6496 - tp: 0.0000e+00 - fp: 6.5556 - tn: 62.7778 - fn: 8.8889 - accuracy: 0.8026 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5104 - f1: 0.0000e+00 - val_loss: 0.2834 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8018 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.80581\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0812 - tp: 0.3333 - fp: 2.8889 - tn: 68.5556 - fn: 6.4444 - accuracy: 0.8691 - precision: 0.0833 - recall: 0.0309 - auc: 0.7065 - f1: 0.0437 - val_loss: 0.2811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8014 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.80581\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2508 - tp: 0.4444 - fp: 0.0000e+00 - tn: 69.1111 - fn: 8.6667 - accuracy: 0.9077 - precision: 0.2222 - recall: 0.0234 - auc: 0.6970 - f1: 0.0185 - val_loss: 0.2718 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7944 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.80581\n","Epoch 33/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0881 - tp: 2.6667 - fp: 6.3333 - tn: 64.2222 - fn: 5.0000 - accuracy: 0.8432 - precision: 0.3018 - recall: 0.4254 - auc: 0.7183 - f1: 0.2785 - val_loss: 0.2904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8017 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.80581\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.9718 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.1111 - fn: 10.1111 - accuracy: 0.8628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7703 - f1: 0.0000e+00 - val_loss: 0.2763 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8017 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.80581\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.8473 - tp: 0.2222 - fp: 2.6667 - tn: 66.7778 - fn: 8.5556 - accuracy: 0.8498 - precision: 0.0370 - recall: 0.0185 - auc: 0.4386 - f1: 0.0185 - val_loss: 0.2751 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8034 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.80581\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9340 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.1111 - fn: 11.1111 - accuracy: 0.8625 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7577 - f1: 0.0000e+00 - val_loss: 0.2746 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8009 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.80581\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.0500 - tp: 2.3333 - fp: 2.5556 - tn: 62.4444 - fn: 10.8889 - accuracy: 0.8300 - precision: 0.4841 - recall: 0.1650 - auc: 0.7461 - f1: 0.2011 - val_loss: 0.2697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8000 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.80581\n","Restoring model weights from the end of the best epoch.\n","Epoch 00037: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 21%|██        | 5/24 [1:03:39<3:58:12, 752.22s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 0, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 17.4837 - tp: 1.3333 - fp: 7.4444 - tn: 59.7778 - fn: 9.6667 - accuracy: 0.7888 - precision: 0.0939 - recall: 0.0772 - auc: 0.3416 - f1: 0.0621 - val_loss: 0.3022 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7917 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.79165, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.5247 - tp: 0.0000e+00 - fp: 2.6667 - tn: 70.1111 - fn: 5.4444 - accuracy: 0.9097 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3949 - f1: 0.0000e+00 - val_loss: 0.2958 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7947 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.79165 to 0.79471, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.5625 - tp: 1.2222 - fp: 9.1111 - tn: 58.2222 - fn: 9.6667 - accuracy: 0.7443 - precision: 0.1074 - recall: 0.1120 - auc: 0.5524 - f1: 0.0731 - val_loss: 0.2872 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7948 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.79471 to 0.79480, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 10.5147 - tp: 0.0000e+00 - fp: 12.0000 - tn: 58.0000 - fn: 8.2222 - accuracy: 0.7160 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4152 - f1: 0.0000e+00 - val_loss: 0.2830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7888 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc did not improve from 0.79480\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.4901 - tp: 0.4444 - fp: 3.8889 - tn: 67.7778 - fn: 6.1111 - accuracy: 0.8875 - precision: 0.0519 - recall: 0.0494 - auc: 0.4896 - f1: 0.0207 - val_loss: 0.2815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7935 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.79480\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.3098 - tp: 0.0000e+00 - fp: 2.6667 - tn: 63.2222 - fn: 12.3333 - accuracy: 0.8036 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6829 - f1: 0.0000e+00 - val_loss: 0.2808 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7923 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.79480\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.1044 - tp: 1.4444 - fp: 8.8889 - tn: 58.6667 - fn: 9.2222 - accuracy: 0.7558 - precision: 0.1281 - recall: 0.1249 - auc: 0.4708 - f1: 0.1299 - val_loss: 0.2794 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7949 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.79480 to 0.79485, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.5311 - tp: 0.0000e+00 - fp: 1.2222 - tn: 69.7778 - fn: 7.2222 - accuracy: 0.9062 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4922 - f1: 0.0000e+00 - val_loss: 0.2804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7902 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.79485\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.5638 - tp: 2.0000 - fp: 9.6667 - tn: 61.1111 - fn: 5.4444 - accuracy: 0.7730 - precision: 0.1792 - recall: 0.3239 - auc: 0.6761 - f1: 0.1263 - val_loss: 0.2815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7957 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.79485 to 0.79573, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.3010 - tp: 0.0000e+00 - fp: 4.4444 - tn: 67.3333 - fn: 6.4444 - accuracy: 0.8585 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6144 - f1: 0.0000e+00 - val_loss: 0.2811 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7999 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.79573 to 0.79991, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.6110 - tp: 1.8889 - fp: 3.3333 - tn: 64.5556 - fn: 8.4444 - accuracy: 0.8451 - precision: 0.2047 - recall: 0.1231 - auc: 0.6461 - f1: 0.1154 - val_loss: 0.2790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7981 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.79991\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1679 - tp: 2.1111 - fp: 5.1111 - tn: 61.2222 - fn: 9.7778 - accuracy: 0.8158 - precision: 0.2635 - recall: 0.1610 - auc: 0.5906 - f1: 0.1632 - val_loss: 0.2770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8004 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.79991 to 0.80044, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.4123 - tp: 0.4444 - fp: 1.8889 - tn: 66.3333 - fn: 9.5556 - accuracy: 0.8461 - precision: 0.1481 - recall: 0.0298 - auc: 0.6039 - f1: 0.0311 - val_loss: 0.2775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7969 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.80044\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9752 - tp: 1.4444 - fp: 3.3333 - tn: 66.2222 - fn: 7.2222 - accuracy: 0.8621 - precision: 0.2897 - recall: 0.1647 - auc: 0.5901 - f1: 0.1703 - val_loss: 0.2787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7943 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.80044\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.0151 - tp: 1.0000 - fp: 3.1111 - tn: 64.6667 - fn: 9.4444 - accuracy: 0.8481 - precision: 0.3278 - recall: 0.1516 - auc: 0.5987 - f1: 0.2106 - val_loss: 0.2774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7934 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.80044\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5261 - tp: 0.0000e+00 - fp: 1.3333 - tn: 68.5556 - fn: 8.3333 - accuracy: 0.8795 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6928 - f1: 0.0000e+00 - val_loss: 0.2761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7944 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.80044\n","Epoch 17/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.8377 - tp: 0.5556 - fp: 4.0000 - tn: 66.8889 - fn: 6.7778 - accuracy: 0.8470 - precision: 0.0847 - recall: 0.0608 - auc: 0.6831 - f1: 0.0563 - val_loss: 0.2797 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7917 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.80044\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.8316 - tp: 0.0000e+00 - fp: 0.6667 - tn: 69.8889 - fn: 7.6667 - accuracy: 0.9003 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5816 - f1: 0.0000e+00 - val_loss: 0.2715 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7984 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.80044\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.3691 - tp: 1.0000 - fp: 3.7778 - tn: 67.0000 - fn: 6.4444 - accuracy: 0.8497 - precision: 0.2148 - recall: 0.1707 - auc: 0.5814 - f1: 0.1053 - val_loss: 0.2770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7950 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.80044\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1620 - tp: 0.3333 - fp: 3.0000 - tn: 68.0000 - fn: 6.8889 - accuracy: 0.8881 - precision: 0.0406 - recall: 0.0303 - auc: 0.6987 - f1: 0.0218 - val_loss: 0.2743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8030 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.80044 to 0.80303, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7400 - tp: 0.0000e+00 - fp: 1.6667 - tn: 69.5556 - fn: 7.0000 - accuracy: 0.8684 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6664 - f1: 0.0000e+00 - val_loss: 0.2838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8029 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.80303\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7122 - tp: 1.1111 - fp: 0.6667 - tn: 68.4444 - fn: 8.0000 - accuracy: 0.9126 - precision: 0.2722 - recall: 0.0657 - auc: 0.7193 - f1: 0.0498 - val_loss: 0.2698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8104 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.80303 to 0.81041, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.7283 - tp: 2.6667 - fp: 13.2222 - tn: 55.4444 - fn: 6.8889 - accuracy: 0.7194 - precision: 0.1571 - recall: 0.3530 - auc: 0.5939 - f1: 0.1117 - val_loss: 0.2783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8072 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.81041\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0986 - tp: 0.0000e+00 - fp: 2.6667 - tn: 66.8889 - fn: 8.6667 - accuracy: 0.8612 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7732 - f1: 0.0000e+00 - val_loss: 0.2754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8094 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.81041\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3338 - tp: 0.8889 - fp: 1.8889 - tn: 69.5556 - fn: 5.8889 - accuracy: 0.8956 - precision: 0.2963 - recall: 0.1459 - auc: 0.6645 - f1: 0.1024 - val_loss: 0.2759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8068 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.81041\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5720 - tp: 0.6667 - fp: 2.4444 - tn: 66.1111 - fn: 9.0000 - accuracy: 0.8576 - precision: 0.2167 - recall: 0.0553 - auc: 0.7775 - f1: 0.0561 - val_loss: 0.2748 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8084 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.81041\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8854 - tp: 1.0000 - fp: 0.0000e+00 - tn: 69.0000 - fn: 8.2222 - accuracy: 0.8894 - precision: 1.0000 - recall: 0.1384 - auc: 0.8566 - f1: 0.1263 - val_loss: 0.2731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8073 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.81041\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9577 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.2222 - fn: 7.1111 - accuracy: 0.9062 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6639 - f1: 0.0000e+00 - val_loss: 0.2681 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8082 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.81041\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3013 - tp: 1.0000 - fp: 3.1111 - tn: 66.3333 - fn: 7.7778 - accuracy: 0.8820 - precision: 0.3278 - recall: 0.2657 - auc: 0.7079 - f1: 0.3159 - val_loss: 0.2759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8079 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.81041\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.7263 - tp: 0.3333 - fp: 4.7778 - tn: 64.5556 - fn: 8.5556 - accuracy: 0.8286 - precision: 0.0386 - recall: 0.0244 - auc: 0.5775 - f1: 0.0291 - val_loss: 0.2736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8011 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.81041\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9620 - tp: 0.0000e+00 - fp: 2.8889 - tn: 68.5556 - fn: 6.7778 - accuracy: 0.8663 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7266 - f1: 0.0000e+00 - val_loss: 0.2767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7995 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.81041\n","Epoch 32/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1653 - tp: 0.4444 - fp: 0.2222 - tn: 68.8889 - fn: 8.6667 - accuracy: 0.9060 - precision: 0.1481 - recall: 0.0234 - auc: 0.7267 - f1: 0.0159 - val_loss: 0.2716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 43.0000 - val_accuracy: 0.9059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7921 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.81041\n","Restoring model weights from the end of the best epoch.\n","Epoch 00032: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|██▌       | 6/24 [1:13:47<3:30:58, 703.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 5.8636 - tp: 0.4444 - fp: 4.8889 - tn: 63.8889 - fn: 9.0000 - accuracy: 0.8078 - precision: 0.0564 - recall: 0.0314 - auc: 0.5851 - f1: 0.0207 - val_loss: 0.3848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6290 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.62897, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.7787 - tp: 0.0000e+00 - fp: 9.8889 - tn: 59.1111 - fn: 9.2222 - accuracy: 0.7014 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4199 - f1: 0.0000e+00 - val_loss: 0.3871 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6878 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.62897 to 0.68778, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.2992 - tp: 0.0000e+00 - fp: 6.0000 - tn: 66.8889 - fn: 5.3333 - accuracy: 0.8622 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4820 - f1: 0.0000e+00 - val_loss: 0.3794 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7109 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.68778 to 0.71094, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.1749 - tp: 3.0000 - fp: 8.5556 - tn: 55.4444 - fn: 11.2222 - accuracy: 0.7600 - precision: 0.2279 - recall: 0.1857 - auc: 0.5210 - f1: 0.1620 - val_loss: 0.3740 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7226 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.71094 to 0.72265, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.6742 - tp: 0.0000e+00 - fp: 0.2222 - tn: 71.7778 - fn: 6.2222 - accuracy: 0.9236 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7627 - f1: 0.0000e+00 - val_loss: 0.3717 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7297 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.72265 to 0.72971, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.8712 - tp: 0.0000e+00 - fp: 7.4444 - tn: 60.7778 - fn: 10.0000 - accuracy: 0.7825 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5228 - f1: 0.0000e+00 - val_loss: 0.3786 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7285 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.72971\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.2434 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 73.4444 - fn: 4.7778 - accuracy: 0.9428 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7112 - f1: 0.0000e+00 - val_loss: 0.3759 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7350 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.72971 to 0.73495, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 6.9326 - tp: 2.5556 - fp: 10.5556 - tn: 56.0000 - fn: 9.1111 - accuracy: 0.7495 - precision: 0.1582 - recall: 0.1815 - auc: 0.4701 - f1: 0.1502 - val_loss: 0.3828 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7355 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.73495 to 0.73555, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.7205 - tp: 1.1111 - fp: 1.8889 - tn: 63.4444 - fn: 11.7778 - accuracy: 0.8144 - precision: 0.2111 - recall: 0.0612 - auc: 0.5550 - f1: 0.0824 - val_loss: 0.3738 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7384 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.73555 to 0.73836, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.3640 - tp: 1.0000 - fp: 2.0000 - tn: 70.2222 - fn: 5.0000 - accuracy: 0.9019 - precision: 0.3333 - recall: 0.2671 - auc: 0.5876 - f1: 0.1579 - val_loss: 0.3830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7391 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.73836 to 0.73914, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9986 - tp: 0.0000e+00 - fp: 1.8889 - tn: 65.0000 - fn: 11.3333 - accuracy: 0.8200 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7032 - f1: 0.0000e+00 - val_loss: 0.3747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7386 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.73914\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.0730 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.7778 - fn: 6.4444 - accuracy: 0.9147 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5946 - f1: 0.0000e+00 - val_loss: 0.3775 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7399 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.73914 to 0.73989, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.6804 - tp: 0.6667 - fp: 3.6667 - tn: 65.3333 - fn: 8.5556 - accuracy: 0.8520 - precision: 0.0667 - recall: 0.0488 - auc: 0.7105 - f1: 0.0249 - val_loss: 0.3682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7396 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.73989\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3981 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.6667 - fn: 7.5556 - accuracy: 0.9199 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5236 - f1: 0.0000e+00 - val_loss: 0.3725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7428 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.73989 to 0.74278, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.6661 - tp: 0.2222 - fp: 2.3333 - tn: 71.0000 - fn: 4.6667 - accuracy: 0.9302 - precision: 0.0317 - recall: 0.0247 - auc: 0.3426 - f1: 0.0185 - val_loss: 0.3713 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7463 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc improved from 0.74278 to 0.74628, saving model to gs://new_cxr_30/models/cxr_model/model-015.h5\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1477 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.8889 - fn: 6.3333 - accuracy: 0.9173 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6700 - f1: 0.0000e+00 - val_loss: 0.3747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7458 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.74628\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.8836 - tp: 0.6667 - fp: 0.0000e+00 - tn: 71.3333 - fn: 6.2222 - accuracy: 0.9287 - precision: 0.6667 - recall: 0.0803 - auc: 0.5760 - f1: 0.0748 - val_loss: 0.3636 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7526 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.74628 to 0.75258, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.2613 - tp: 1.6667 - fp: 4.3333 - tn: 65.6667 - fn: 6.5556 - accuracy: 0.8725 - precision: 0.2706 - recall: 0.2217 - auc: 0.7348 - f1: 0.1621 - val_loss: 0.3742 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7519 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.75258\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6216 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.4444 - fn: 6.7778 - accuracy: 0.9115 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8133 - f1: 0.0000e+00 - val_loss: 0.3731 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7525 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.75258\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1746 - tp: 0.0000e+00 - fp: 2.1111 - tn: 68.8889 - fn: 7.2222 - accuracy: 0.8775 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7556 - f1: 0.0000e+00 - val_loss: 0.3756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7523 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.75258\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6312 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.6667 - fn: 5.5556 - accuracy: 0.9288 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6754 - f1: 0.0000e+00 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7559 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc improved from 0.75258 to 0.75592, saving model to gs://new_cxr_30/models/cxr_model/model-021.h5\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4038 - tp: 0.0000e+00 - fp: 1.8889 - tn: 68.4444 - fn: 7.8889 - accuracy: 0.8857 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6758 - f1: 0.0000e+00 - val_loss: 0.3730 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7491 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.75592\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2295 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.0000 - fn: 8.2222 - accuracy: 0.9008 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7702 - f1: 0.0000e+00 - val_loss: 0.3547 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7560 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc improved from 0.75592 to 0.75605, saving model to gs://new_cxr_30/models/cxr_model/model-023.h5\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5173 - tp: 1.7778 - fp: 6.5556 - tn: 61.8889 - fn: 8.0000 - accuracy: 0.8071 - precision: 0.1865 - recall: 0.1609 - auc: 0.6693 - f1: 0.1106 - val_loss: 0.3726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7495 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.75605\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.6702 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9646 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4782 - f1: 0.0000e+00 - val_loss: 0.3683 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7498 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.75605\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4039 - tp: 0.0000e+00 - fp: 3.7778 - tn: 68.4444 - fn: 6.0000 - accuracy: 0.8809 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5316 - f1: 0.0000e+00 - val_loss: 0.3591 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7553 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.75605\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3442 - tp: 0.0000e+00 - fp: 1.4444 - tn: 67.2222 - fn: 9.5556 - accuracy: 0.8547 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5908 - f1: 0.0000e+00 - val_loss: 0.3613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7557 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.75605\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.8406 - tp: 0.5556 - fp: 0.3333 - tn: 65.2222 - fn: 12.1111 - accuracy: 0.8120 - precision: 0.3889 - recall: 0.0366 - auc: 0.7806 - f1: 0.0563 - val_loss: 0.3605 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7573 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc improved from 0.75605 to 0.75732, saving model to gs://new_cxr_30/models/cxr_model/model-028.h5\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.4355 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.4444 - fn: 5.7778 - accuracy: 0.9341 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7310 - f1: 0.0000e+00 - val_loss: 0.3678 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7537 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.75732\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7957 - tp: 0.6667 - fp: 4.0000 - tn: 63.6667 - fn: 9.8889 - accuracy: 0.8349 - precision: 0.1148 - recall: 0.0511 - auc: 0.7550 - f1: 0.0561 - val_loss: 0.3579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7529 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.75732\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3019 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.6667 - fn: 8.5556 - accuracy: 0.8971 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7663 - f1: 0.0000e+00 - val_loss: 0.3648 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7481 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.75732\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0657 - tp: 1.8889 - fp: 2.6667 - tn: 68.2222 - fn: 5.4444 - accuracy: 0.9052 - precision: 0.4963 - recall: 0.3333 - auc: 0.7228 - f1: 0.3471 - val_loss: 0.3542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7477 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.75732\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7321 - tp: 0.0000e+00 - fp: 1.8889 - tn: 63.6667 - fn: 12.6667 - accuracy: 0.8115 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8351 - f1: 0.0000e+00 - val_loss: 0.3666 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7427 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.75732\n","Epoch 34/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.8630 - tp: 0.4444 - fp: 3.0000 - tn: 61.4444 - fn: 13.3333 - accuracy: 0.7786 - precision: 0.0751 - recall: 0.0261 - auc: 0.6522 - f1: 0.0414 - val_loss: 0.3615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7461 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.75732\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.6702 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.1111 - fn: 4.1111 - accuracy: 0.9605 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2514 - f1: 0.0000e+00 - val_loss: 0.4131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7387 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.75732\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2048 - tp: 0.0000e+00 - fp: 0.5556 - tn: 70.5556 - fn: 7.1111 - accuracy: 0.9126 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6505 - f1: 0.0000e+00 - val_loss: 0.3501 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7458 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.75732\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.5771 - tp: 4.3333 - fp: 3.8889 - tn: 60.5556 - fn: 9.4444 - accuracy: 0.8138 - precision: 0.4955 - recall: 0.2870 - auc: 0.7168 - f1: 0.2706 - val_loss: 0.3466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7489 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.75732\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7784 - tp: 0.0000e+00 - fp: 2.2222 - tn: 67.7778 - fn: 8.2222 - accuracy: 0.8709 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6092 - f1: 0.0000e+00 - val_loss: 0.3777 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7463 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.75732\n","Restoring model weights from the end of the best epoch.\n","Epoch 00038: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 29%|██▉       | 7/24 [1:26:01<3:22:06, 713.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 7.1643 - tp: 0.7778 - fp: 7.6667 - tn: 61.1111 - fn: 8.6667 - accuracy: 0.7661 - precision: 0.0713 - recall: 0.0592 - auc: 0.5500 - f1: 0.0923 - val_loss: 0.3697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6332 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.63316, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.8522 - tp: 1.0000 - fp: 3.0000 - tn: 66.0000 - fn: 8.2222 - accuracy: 0.8252 - precision: 0.2667 - recall: 0.1216 - auc: 0.3496 - f1: 0.0790 - val_loss: 0.3673 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6901 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.63316 to 0.69008, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.3739 - tp: 0.4444 - fp: 2.6667 - tn: 70.2222 - fn: 4.8889 - accuracy: 0.9105 - precision: 0.0741 - recall: 0.0370 - auc: 0.4722 - f1: 0.0159 - val_loss: 0.3631 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7047 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.69008 to 0.70468, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.8685 - tp: 3.2222 - fp: 11.0000 - tn: 53.0000 - fn: 11.0000 - accuracy: 0.7334 - precision: 0.1841 - recall: 0.1839 - auc: 0.5960 - f1: 0.1201 - val_loss: 0.3576 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7171 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.70468 to 0.71711, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5125 - tp: 1.1111 - fp: 2.8889 - tn: 69.1111 - fn: 5.1111 - accuracy: 0.8852 - precision: 0.2444 - recall: 0.1592 - auc: 0.6616 - f1: 0.1710 - val_loss: 0.3612 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7299 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.71711 to 0.72986, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.7360 - tp: 0.6667 - fp: 4.5556 - tn: 63.6667 - fn: 9.3333 - accuracy: 0.8181 - precision: 0.0753 - recall: 0.0456 - auc: 0.5893 - f1: 0.0553 - val_loss: 0.3563 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7330 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.72986 to 0.73297, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5033 - tp: 1.0000 - fp: 3.7778 - tn: 69.6667 - fn: 3.7778 - accuracy: 0.8939 - precision: 0.2111 - recall: 0.3731 - auc: 0.6652 - f1: 0.1263 - val_loss: 0.3715 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.73297 to 0.73327, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.5778 - tp: 1.1111 - fp: 6.7778 - tn: 59.7778 - fn: 10.5556 - accuracy: 0.7901 - precision: 0.1099 - recall: 0.0716 - auc: 0.5084 - f1: 0.0720 - val_loss: 0.3582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7392 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.73327 to 0.73919, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.7877 - tp: 1.0000 - fp: 1.7778 - tn: 63.5556 - fn: 11.8889 - accuracy: 0.8207 - precision: 0.4519 - recall: 0.1012 - auc: 0.6702 - f1: 0.1053 - val_loss: 0.3598 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7404 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.73919 to 0.74038, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.8143 - tp: 0.0000e+00 - fp: 1.7778 - tn: 70.4444 - fn: 6.0000 - accuracy: 0.8957 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4234 - f1: 0.0000e+00 - val_loss: 0.3634 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7419 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.74038 to 0.74191, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.4627 - tp: 0.0000e+00 - fp: 4.5556 - tn: 62.3333 - fn: 11.3333 - accuracy: 0.7762 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5904 - f1: 0.0000e+00 - val_loss: 0.3626 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7437 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.74191 to 0.74366, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.1912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.7778 - fn: 6.4444 - accuracy: 0.9345 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5689 - f1: 0.0000e+00 - val_loss: 0.3638 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7435 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.74366\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.5285 - tp: 0.3333 - fp: 5.5556 - tn: 63.4444 - fn: 8.8889 - accuracy: 0.8259 - precision: 0.0313 - recall: 0.0244 - auc: 0.7623 - f1: 0.0175 - val_loss: 0.3603 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7438 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.74366 to 0.74383, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.2429 - tp: 0.2222 - fp: 0.0000e+00 - tn: 70.6667 - fn: 7.3333 - accuracy: 0.9217 - precision: 0.2222 - recall: 0.0159 - auc: 0.5373 - f1: 0.0185 - val_loss: 0.3642 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7414 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.74383\n","Epoch 15/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.0473 - tp: 0.3333 - fp: 0.0000e+00 - tn: 73.3333 - fn: 4.5556 - accuracy: 0.9514 - precision: 0.3333 - recall: 0.0386 - auc: 0.5369 - f1: 0.0291 - val_loss: 0.3642 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7428 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.74383\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.6454 - tp: 0.0000e+00 - fp: 2.2222 - tn: 69.6667 - fn: 6.3333 - accuracy: 0.8940 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7816 - f1: 0.0000e+00 - val_loss: 0.3718 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7430 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.74383\n","Epoch 17/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5325 - tp: 0.0000e+00 - fp: 1.1111 - tn: 70.2222 - fn: 6.8889 - accuracy: 0.9097 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5958 - f1: 0.0000e+00 - val_loss: 0.3649 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7482 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.74383 to 0.74817, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.2645 - tp: 0.7778 - fp: 1.4444 - tn: 68.5556 - fn: 7.4444 - accuracy: 0.8941 - precision: 0.2778 - recall: 0.0923 - auc: 0.6985 - f1: 0.0746 - val_loss: 0.3626 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7553 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.74817 to 0.75534, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.3382 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.4444 - fn: 6.7778 - accuracy: 0.9115 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8478 - f1: 0.0000e+00 - val_loss: 0.3682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7552 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.75534\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3678 - tp: 0.8889 - fp: 2.4444 - tn: 68.5556 - fn: 6.3333 - accuracy: 0.8840 - precision: 0.1981 - recall: 0.1001 - auc: 0.7365 - f1: 0.0859 - val_loss: 0.3706 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7538 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.75534\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9491 - tp: 0.0000e+00 - fp: 1.1111 - tn: 71.5556 - fn: 5.5556 - accuracy: 0.9182 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6092 - f1: 0.0000e+00 - val_loss: 0.3689 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7502 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.75534\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0657 - tp: 0.2222 - fp: 1.3333 - tn: 69.0000 - fn: 7.6667 - accuracy: 0.8935 - precision: 0.0444 - recall: 0.0185 - auc: 0.7464 - f1: 0.0185 - val_loss: 0.3636 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7530 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.75534\n","Epoch 23/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9469 - tp: 0.0000e+00 - fp: 0.2222 - tn: 69.7778 - fn: 8.2222 - accuracy: 0.8990 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6303 - f1: 0.0000e+00 - val_loss: 0.3536 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7523 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.75534\n","Epoch 24/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.7590 - tp: 2.5556 - fp: 9.0000 - tn: 59.4444 - fn: 7.2222 - accuracy: 0.7921 - precision: 0.2034 - recall: 0.2723 - auc: 0.6426 - f1: 0.2254 - val_loss: 0.3729 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7489 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.75534\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.4551 - tp: 0.0000e+00 - fp: 0.5556 - tn: 73.8889 - fn: 3.7778 - accuracy: 0.9593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6093 - f1: 0.0000e+00 - val_loss: 0.3686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7469 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.75534\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3048 - tp: 0.0000e+00 - fp: 0.6667 - tn: 71.5556 - fn: 6.0000 - accuracy: 0.9193 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5467 - f1: 0.0000e+00 - val_loss: 0.3532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7505 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.75534\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.8470 - tp: 1.3333 - fp: 5.7778 - tn: 62.8889 - fn: 8.2222 - accuracy: 0.8248 - precision: 0.1758 - recall: 0.1186 - auc: 0.5619 - f1: 0.0779 - val_loss: 0.3722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7446 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.75534\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.3163 - tp: 0.0000e+00 - fp: 1.1111 - tn: 64.4444 - fn: 12.6667 - accuracy: 0.8001 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7470 - f1: 0.0000e+00 - val_loss: 0.3561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7496 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.75534\n","Restoring model weights from the end of the best epoch.\n","Epoch 00028: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 33%|███▎      | 8/24 [1:34:52<2:54:40, 655.03s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 8.5432 - tp: 1.8889 - fp: 4.7778 - tn: 64.0000 - fn: 7.5556 - accuracy: 0.8442 - precision: 0.3068 - recall: 0.2258 - auc: 0.6237 - f1: 0.1540 - val_loss: 0.3719 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7203 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.72035, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 17s 2s/step - loss: 14.0814 - tp: 0.0000e+00 - fp: 7.6667 - tn: 61.3333 - fn: 9.2222 - accuracy: 0.7466 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3300 - f1: 0.0000e+00 - val_loss: 0.3789 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7270 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.72035 to 0.72703, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9923 - tp: 0.0000e+00 - fp: 3.7778 - tn: 69.1111 - fn: 5.3333 - accuracy: 0.9000 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4178 - f1: 0.0000e+00 - val_loss: 0.3662 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7365 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.72703 to 0.73653, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.0490 - tp: 4.5556 - fp: 7.7778 - tn: 56.2222 - fn: 9.6667 - accuracy: 0.7716 - precision: 0.2970 - recall: 0.2604 - auc: 0.6098 - f1: 0.2373 - val_loss: 0.3649 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7378 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.73653 to 0.73776, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.9064 - tp: 0.0000e+00 - fp: 1.0000 - tn: 71.0000 - fn: 6.2222 - accuracy: 0.9056 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4728 - f1: 0.0000e+00 - val_loss: 0.3766 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7360 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.73776\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.3964 - tp: 1.5556 - fp: 9.0000 - tn: 59.2222 - fn: 8.4444 - accuracy: 0.7813 - precision: 0.0893 - recall: 0.1098 - auc: 0.5267 - f1: 0.0918 - val_loss: 0.3756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7368 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.73776\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.2587 - tp: 1.2222 - fp: 0.0000e+00 - tn: 73.4444 - fn: 3.5556 - accuracy: 0.9642 - precision: 1.0000 - recall: 0.3954 - auc: 0.6208 - f1: 0.3344 - val_loss: 0.3823 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7364 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.73776\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 8.3128 - tp: 2.3333 - fp: 9.0000 - tn: 57.5556 - fn: 9.3333 - accuracy: 0.7669 - precision: 0.2009 - recall: 0.1845 - auc: 0.5386 - f1: 0.1707 - val_loss: 0.3784 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7331 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.73776\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.8797 - tp: 1.0000 - fp: 3.1111 - tn: 62.2222 - fn: 11.8889 - accuracy: 0.8016 - precision: 0.1722 - recall: 0.0570 - auc: 0.5903 - f1: 0.0770 - val_loss: 0.3736 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7342 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.73776\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.7617 - tp: 0.0000e+00 - fp: 3.0000 - tn: 69.2222 - fn: 6.0000 - accuracy: 0.8624 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4359 - f1: 0.0000e+00 - val_loss: 0.3830 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7291 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.73776\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 6.7261 - tp: 0.6667 - fp: 6.8889 - tn: 60.0000 - fn: 10.6667 - accuracy: 0.7750 - precision: 0.0661 - recall: 0.0492 - auc: 0.5432 - f1: 0.0280 - val_loss: 0.3880 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7364 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.73776\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.7778 - fn: 6.4444 - accuracy: 0.9345 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4609 - f1: 0.0000e+00 - val_loss: 0.3774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7418 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.73776 to 0.74181, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7635 - tp: 3.4444 - fp: 4.2222 - tn: 64.7778 - fn: 5.7778 - accuracy: 0.8767 - precision: 0.4699 - recall: 0.3401 - auc: 0.7475 - f1: 0.3461 - val_loss: 0.3713 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7429 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.74181 to 0.74287, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.4564 - tp: 0.0000e+00 - fp: 0.8889 - tn: 69.7778 - fn: 7.5556 - accuracy: 0.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - f1: 0.0000e+00 - val_loss: 0.3670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7434 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.74287 to 0.74342, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.1196 - tp: 0.0000e+00 - fp: 4.4444 - tn: 68.8889 - fn: 4.8889 - accuracy: 0.8939 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4297 - f1: 0.0000e+00 - val_loss: 0.3801 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7430 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.74342\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.8889 - fn: 6.3333 - accuracy: 0.9173 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7746 - f1: 0.0000e+00 - val_loss: 0.3747 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7482 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.74342 to 0.74823, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3013 - tp: 0.0000e+00 - fp: 2.3333 - tn: 69.0000 - fn: 6.8889 - accuracy: 0.8973 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5845 - f1: 0.0000e+00 - val_loss: 0.3714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7503 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.74823 to 0.75034, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2342 - tp: 0.0000e+00 - fp: 6.3333 - tn: 63.6667 - fn: 8.2222 - accuracy: 0.8261 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5843 - f1: 0.0000e+00 - val_loss: 0.3802 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7483 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.75034\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.6498 - tp: 0.6667 - fp: 0.5556 - tn: 70.8889 - fn: 6.1111 - accuracy: 0.9132 - precision: 0.3889 - recall: 0.0796 - auc: 0.7800 - f1: 0.0748 - val_loss: 0.3844 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7488 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.75034\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9261 - tp: 1.0000 - fp: 2.7778 - tn: 68.2222 - fn: 6.2222 - accuracy: 0.8768 - precision: 0.2889 - recall: 0.1742 - auc: 0.6663 - f1: 0.1263 - val_loss: 0.3809 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7544 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.75034 to 0.75438, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2032 - tp: 0.5556 - fp: 4.3333 - tn: 68.3333 - fn: 5.0000 - accuracy: 0.8881 - precision: 0.0734 - recall: 0.0730 - auc: 0.6444 - f1: 0.0338 - val_loss: 0.3893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7499 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.75438\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9315 - tp: 0.0000e+00 - fp: 0.4444 - tn: 69.8889 - fn: 7.8889 - accuracy: 0.8994 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6227 - f1: 0.0000e+00 - val_loss: 0.3649 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7569 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.75438 to 0.75688, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6438 - tp: 0.0000e+00 - fp: 3.5556 - tn: 66.4444 - fn: 8.2222 - accuracy: 0.8576 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6517 - f1: 0.0000e+00 - val_loss: 0.3637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7548 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.75688\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3130 - tp: 1.8889 - fp: 6.2222 - tn: 62.2222 - fn: 7.8889 - accuracy: 0.8170 - precision: 0.2192 - recall: 0.2165 - auc: 0.7024 - f1: 0.2073 - val_loss: 0.3720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7562 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.75688\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.6730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9646 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4929 - f1: 0.0000e+00 - val_loss: 0.3704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7567 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.75688\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2487 - tp: 0.0000e+00 - fp: 3.2222 - tn: 69.0000 - fn: 6.0000 - accuracy: 0.8855 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6376 - f1: 0.0000e+00 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7569 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.75688\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0961 - tp: 0.7778 - fp: 6.2222 - tn: 62.4444 - fn: 8.7778 - accuracy: 0.8151 - precision: 0.1253 - recall: 0.0732 - auc: 0.5671 - f1: 0.0497 - val_loss: 0.3751 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7511 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.75688\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.6622 - tp: 1.6667 - fp: 1.8889 - tn: 63.6667 - fn: 11.0000 - accuracy: 0.8131 - precision: 0.5074 - recall: 0.1214 - auc: 0.6856 - f1: 0.1580 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7498 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.75688\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.6202 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.4444 - fn: 5.7778 - accuracy: 0.9341 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6439 - f1: 0.0000e+00 - val_loss: 0.3810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7490 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.75688\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6341 - tp: 0.0000e+00 - fp: 2.8889 - tn: 64.7778 - fn: 10.5556 - accuracy: 0.8395 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7729 - f1: 0.0000e+00 - val_loss: 0.3689 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7518 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.75688\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3134 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.6667 - fn: 8.5556 - accuracy: 0.8971 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7450 - f1: 0.0000e+00 - val_loss: 0.3668 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7501 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.75688\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1225 - tp: 1.2222 - fp: 3.7778 - tn: 67.1111 - fn: 6.1111 - accuracy: 0.8684 - precision: 0.1810 - recall: 0.1296 - auc: 0.7393 - f1: 0.0898 - val_loss: 0.3787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7459 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.75688\n","Restoring model weights from the end of the best epoch.\n","Epoch 00032: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 38%|███▊      | 9/24 [1:45:05<2:40:28, 641.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 7.7712 - tp: 2.3333 - fp: 5.4444 - tn: 63.3333 - fn: 7.1111 - accuracy: 0.8444 - precision: 0.3518 - recall: 0.2509 - auc: 0.6306 - f1: 0.2728 - val_loss: 0.3774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6128 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.61275, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 18.7938 - tp: 0.0000e+00 - fp: 4.1111 - tn: 64.8889 - fn: 9.2222 - accuracy: 0.7978 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4323 - f1: 0.0000e+00 - val_loss: 0.3725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6956 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.61275 to 0.69562, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.7822 - tp: 0.7778 - fp: 3.3333 - tn: 69.5556 - fn: 4.5556 - accuracy: 0.9140 - precision: 0.0852 - recall: 0.0714 - auc: 0.4775 - f1: 0.0342 - val_loss: 0.3566 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7205 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.69562 to 0.72050, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 9.7690 - tp: 0.6667 - fp: 12.1111 - tn: 51.8889 - fn: 13.5556 - accuracy: 0.6668 - precision: 0.0333 - recall: 0.0299 - auc: 0.5830 - f1: 0.0194 - val_loss: 0.3542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7333 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.72050 to 0.73333, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.5691 - tp: 0.0000e+00 - fp: 1.8889 - tn: 70.1111 - fn: 6.2222 - accuracy: 0.8928 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3789 - f1: 0.0000e+00 - val_loss: 0.3557 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7337 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.73333 to 0.73367, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 10.2548 - tp: 3.1111 - fp: 9.8889 - tn: 58.3333 - fn: 6.8889 - accuracy: 0.7852 - precision: 0.2138 - recall: 0.2720 - auc: 0.5123 - f1: 0.1995 - val_loss: 0.3591 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7340 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.73367 to 0.73401, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.8132 - tp: 1.0000 - fp: 1.8889 - tn: 71.5556 - fn: 3.7778 - accuracy: 0.9386 - precision: 0.4074 - recall: 0.3731 - auc: 0.6579 - f1: 0.3159 - val_loss: 0.3597 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7330 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.73401\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.0246 - tp: 2.7778 - fp: 10.7778 - tn: 55.7778 - fn: 8.8889 - accuracy: 0.7398 - precision: 0.1858 - recall: 0.2075 - auc: 0.5718 - f1: 0.1764 - val_loss: 0.3699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7308 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.73401\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.8418 - tp: 0.6667 - fp: 5.5556 - tn: 59.7778 - fn: 12.2222 - accuracy: 0.7749 - precision: 0.1001 - recall: 0.0429 - auc: 0.5313 - f1: 0.0561 - val_loss: 0.3581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7348 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.73401 to 0.73480, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.7515 - tp: 0.0000e+00 - fp: 4.7778 - tn: 67.4444 - fn: 6.0000 - accuracy: 0.8333 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4956 - f1: 0.0000e+00 - val_loss: 0.3702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7319 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.73480\n","Epoch 11/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.9295 - tp: 1.0000 - fp: 3.6667 - tn: 63.2222 - fn: 10.3333 - accuracy: 0.8130 - precision: 0.2287 - recall: 0.0705 - auc: 0.5570 - f1: 0.0779 - val_loss: 0.3613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7321 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.73480\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.7254 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.7778 - fn: 6.4444 - accuracy: 0.9345 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4483 - f1: 0.0000e+00 - val_loss: 0.3629 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7368 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.73480 to 0.73680, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6037 - tp: 3.3333 - fp: 6.6667 - tn: 62.3333 - fn: 5.8889 - accuracy: 0.8528 - precision: 0.4105 - recall: 0.3242 - auc: 0.7848 - f1: 0.3361 - val_loss: 0.3606 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7350 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.73680\n","Epoch 14/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2663 - tp: 0.5556 - fp: 0.0000e+00 - tn: 70.6667 - fn: 7.0000 - accuracy: 0.9244 - precision: 0.3333 - recall: 0.0410 - auc: 0.5730 - f1: 0.0622 - val_loss: 0.3572 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7355 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.73680\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2027 - tp: 0.0000e+00 - fp: 4.2222 - tn: 69.1111 - fn: 4.8889 - accuracy: 0.8824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4077 - f1: 0.0000e+00 - val_loss: 0.3615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7383 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc improved from 0.73680 to 0.73829, saving model to gs://new_cxr_30/models/cxr_model/model-015.h5\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.2508 - tp: 0.0000e+00 - fp: 0.7778 - tn: 71.1111 - fn: 6.3333 - accuracy: 0.9080 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6798 - f1: 0.0000e+00 - val_loss: 0.3605 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7416 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.73829 to 0.74161, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8936 - tp: 0.6667 - fp: 1.2222 - tn: 70.1111 - fn: 6.2222 - accuracy: 0.9173 - precision: 0.2593 - recall: 0.0803 - auc: 0.7180 - f1: 0.0561 - val_loss: 0.3571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7427 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.74161 to 0.74268, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1832 - tp: 2.6667 - fp: 2.3333 - tn: 67.6667 - fn: 5.5556 - accuracy: 0.9005 - precision: 0.4881 - recall: 0.3299 - auc: 0.7444 - f1: 0.3135 - val_loss: 0.3615 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7401 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.74268\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.3948 - tp: 0.0000e+00 - fp: 0.7778 - tn: 70.6667 - fn: 6.7778 - accuracy: 0.9049 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8341 - f1: 0.0000e+00 - val_loss: 0.3606 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7422 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.74268\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3904 - tp: 0.0000e+00 - fp: 3.7778 - tn: 67.2222 - fn: 7.2222 - accuracy: 0.8520 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7625 - f1: 0.0000e+00 - val_loss: 0.3616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7436 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.74268 to 0.74357, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9181 - tp: 0.0000e+00 - fp: 2.6667 - tn: 70.0000 - fn: 5.5556 - accuracy: 0.9017 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6586 - f1: 0.0000e+00 - val_loss: 0.3635 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7424 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.74357\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5985 - tp: 0.0000e+00 - fp: 0.3333 - tn: 70.0000 - fn: 7.8889 - accuracy: 0.9001 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5996 - f1: 0.0000e+00 - val_loss: 0.3540 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7472 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.74357 to 0.74717, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3458 - tp: 0.0000e+00 - fp: 1.3333 - tn: 68.6667 - fn: 8.2222 - accuracy: 0.8870 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6730 - f1: 0.0000e+00 - val_loss: 0.3481 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7484 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc improved from 0.74717 to 0.74838, saving model to gs://new_cxr_30/models/cxr_model/model-023.h5\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3707 - tp: 1.7778 - fp: 8.5556 - tn: 59.8889 - fn: 8.0000 - accuracy: 0.7723 - precision: 0.1500 - recall: 0.1609 - auc: 0.6603 - f1: 0.0964 - val_loss: 0.3598 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7433 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.74838\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.8627 - tp: 0.0000e+00 - fp: 0.5556 - tn: 73.8889 - fn: 3.7778 - accuracy: 0.9593 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3552 - f1: 0.0000e+00 - val_loss: 0.3533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7443 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.74838\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8401 - tp: 0.0000e+00 - fp: 4.4444 - tn: 67.7778 - fn: 6.0000 - accuracy: 0.8542 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5742 - f1: 0.0000e+00 - val_loss: 0.3634 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7444 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.74838\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.4432 - tp: 1.3333 - fp: 7.3333 - tn: 61.3333 - fn: 8.2222 - accuracy: 0.8104 - precision: 0.1566 - recall: 0.1186 - auc: 0.5767 - f1: 0.0708 - val_loss: 0.3725 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7374 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.74838\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 7.1755 - tp: 0.0000e+00 - fp: 0.3333 - tn: 65.2222 - fn: 12.6667 - accuracy: 0.8067 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6715 - f1: 0.0000e+00 - val_loss: 0.3550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7431 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.74838\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1489 - tp: 0.0000e+00 - fp: 1.7778 - tn: 70.6667 - fn: 5.7778 - accuracy: 0.9085 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6166 - f1: 0.0000e+00 - val_loss: 0.3637 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7401 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.74838\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0244 - tp: 1.7778 - fp: 2.1111 - tn: 65.5556 - fn: 8.7778 - accuracy: 0.8778 - precision: 0.6667 - recall: 0.2632 - auc: 0.8467 - f1: 0.3905 - val_loss: 0.3473 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7443 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.74838\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4228 - tp: 0.2222 - fp: 0.2222 - tn: 69.4444 - fn: 8.3333 - accuracy: 0.8971 - precision: 0.1111 - recall: 0.0139 - auc: 0.7525 - f1: 0.0093 - val_loss: 0.3515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7420 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.74838\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2566 - tp: 1.5556 - fp: 4.6667 - tn: 66.2222 - fn: 5.7778 - accuracy: 0.8684 - precision: 0.3185 - recall: 0.2500 - auc: 0.7451 - f1: 0.2443 - val_loss: 0.3716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7375 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.74838\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.5729 - tp: 0.5556 - fp: 1.8889 - tn: 63.6667 - fn: 12.1111 - accuracy: 0.8178 - precision: 0.2037 - recall: 0.0348 - auc: 0.6640 - f1: 0.0844 - val_loss: 0.3512 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7416 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.74838\n","Restoring model weights from the end of the best epoch.\n","Epoch 00033: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 42%|████▏     | 10/24 [1:55:48<2:29:52, 642.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 8.5721 - tp: 0.6667 - fp: 5.0000 - tn: 63.7778 - fn: 8.7778 - accuracy: 0.8255 - precision: 0.0714 - recall: 0.0453 - auc: 0.5064 - f1: 0.0403 - val_loss: 0.3940 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6756 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.67559, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 15.7582 - tp: 3.0000 - fp: 7.1111 - tn: 61.8889 - fn: 6.2222 - accuracy: 0.8111 - precision: 0.3321 - recall: 0.3647 - auc: 0.5672 - f1: 0.1895 - val_loss: 0.4261 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7000 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.67559 to 0.70002, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.9310 - tp: 0.5556 - fp: 7.7778 - tn: 65.1111 - fn: 4.7778 - accuracy: 0.8610 - precision: 0.0382 - recall: 0.0529 - auc: 0.3798 - f1: 0.0370 - val_loss: 0.3932 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7199 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.70002 to 0.71994, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.1415 - tp: 6.5556 - fp: 9.1111 - tn: 54.8889 - fn: 7.6667 - accuracy: 0.7875 - precision: 0.3884 - recall: 0.4464 - auc: 0.7464 - f1: 0.3584 - val_loss: 0.3882 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7283 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.71994 to 0.72827, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.6464 - tp: 0.5556 - fp: 3.0000 - tn: 69.0000 - fn: 5.6667 - accuracy: 0.8964 - precision: 0.0820 - recall: 0.0515 - auc: 0.5522 - f1: 0.0452 - val_loss: 0.3860 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7373 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.72827 to 0.73734, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.6103 - tp: 1.5556 - fp: 6.5556 - tn: 61.6667 - fn: 8.4444 - accuracy: 0.8003 - precision: 0.1270 - recall: 0.1153 - auc: 0.4879 - f1: 0.0811 - val_loss: 0.3909 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7411 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.73734 to 0.74115, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9488 - tp: 1.0000 - fp: 1.3333 - tn: 72.1111 - fn: 3.7778 - accuracy: 0.9485 - precision: 0.5556 - recall: 0.3731 - auc: 0.7098 - f1: 0.3159 - val_loss: 0.3881 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7385 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.74115\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.3043 - tp: 3.8889 - fp: 11.2222 - tn: 55.3333 - fn: 7.7778 - accuracy: 0.7585 - precision: 0.2501 - recall: 0.3139 - auc: 0.6695 - f1: 0.1918 - val_loss: 0.4250 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7360 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.74115\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 14.9989 - tp: 1.6667 - fp: 5.6667 - tn: 59.6667 - fn: 11.2222 - accuracy: 0.7865 - precision: 0.1032 - recall: 0.0880 - auc: 0.5255 - f1: 0.0505 - val_loss: 0.3854 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7424 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.74115 to 0.74244, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.3671 - tp: 0.0000e+00 - fp: 2.0000 - tn: 70.2222 - fn: 6.0000 - accuracy: 0.8821 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5106 - f1: 0.0000e+00 - val_loss: 0.3965 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7339 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.74244\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.8108 - tp: 1.4444 - fp: 10.7778 - tn: 56.1111 - fn: 9.8889 - accuracy: 0.7319 - precision: 0.0943 - recall: 0.1123 - auc: 0.5188 - f1: 0.0653 - val_loss: 0.3941 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7374 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.74244\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9657 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.8889 - fn: 6.4444 - accuracy: 0.9273 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5482 - f1: 0.0000e+00 - val_loss: 0.3724 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7460 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.74244 to 0.74598, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1641 - tp: 3.1111 - fp: 7.2222 - tn: 61.7778 - fn: 6.1111 - accuracy: 0.8080 - precision: 0.2709 - recall: 0.3157 - auc: 0.6292 - f1: 0.2437 - val_loss: 0.3875 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7395 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.74598\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6935 - tp: 0.4444 - fp: 3.7778 - tn: 66.8889 - fn: 7.1111 - accuracy: 0.8923 - precision: 0.0317 - recall: 0.0317 - auc: 0.6243 - f1: 0.0139 - val_loss: 0.3728 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7471 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.74598 to 0.74715, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.5929 - tp: 0.7778 - fp: 0.8889 - tn: 72.4444 - fn: 4.1111 - accuracy: 0.9452 - precision: 0.3889 - recall: 0.1441 - auc: 0.4356 - f1: 0.0746 - val_loss: 0.3827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7468 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.74715\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9506 - tp: 1.0000 - fp: 1.4444 - tn: 70.4444 - fn: 5.3333 - accuracy: 0.9238 - precision: 0.6019 - recall: 0.2559 - auc: 0.7063 - f1: 0.3159 - val_loss: 0.3878 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7446 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.74715\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8380 - tp: 0.7778 - fp: 0.0000e+00 - tn: 71.3333 - fn: 6.1111 - accuracy: 0.9311 - precision: 0.7778 - recall: 0.1173 - auc: 0.7285 - f1: 0.0995 - val_loss: 0.3754 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7520 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.74715 to 0.75196, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2993 - tp: 2.1111 - fp: 5.3333 - tn: 64.6667 - fn: 6.1111 - accuracy: 0.8513 - precision: 0.2336 - recall: 0.2325 - auc: 0.5530 - f1: 0.1332 - val_loss: 0.3815 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7521 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.75196 to 0.75206, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.7133 - tp: 0.3333 - fp: 1.8889 - tn: 69.5556 - fn: 6.4444 - accuracy: 0.8927 - precision: 0.0815 - recall: 0.0313 - auc: 0.8073 - f1: 0.0291 - val_loss: 0.3787 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7530 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.75206 to 0.75296, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6932 - tp: 0.0000e+00 - fp: 0.5556 - tn: 70.4444 - fn: 7.2222 - accuracy: 0.8923 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8192 - f1: 0.0000e+00 - val_loss: 0.3824 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7554 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.75296 to 0.75536, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4775 - tp: 0.0000e+00 - fp: 2.0000 - tn: 70.6667 - fn: 5.5556 - accuracy: 0.9102 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5425 - f1: 0.0000e+00 - val_loss: 0.3904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7530 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.75536\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2571 - tp: 0.0000e+00 - fp: 1.5556 - tn: 68.7778 - fn: 7.8889 - accuracy: 0.8900 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6406 - f1: 0.0000e+00 - val_loss: 0.3748 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7550 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.75536\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7796 - tp: 0.2222 - fp: 0.7778 - tn: 69.2222 - fn: 8.0000 - accuracy: 0.8932 - precision: 0.1111 - recall: 0.0148 - auc: 0.6773 - f1: 0.0185 - val_loss: 0.3654 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7565 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc improved from 0.75536 to 0.75653, saving model to gs://new_cxr_30/models/cxr_model/model-023.h5\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2861 - tp: 2.6667 - fp: 5.7778 - tn: 62.6667 - fn: 7.1111 - accuracy: 0.8397 - precision: 0.2790 - recall: 0.2908 - auc: 0.6174 - f1: 0.1798 - val_loss: 0.3723 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7571 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc improved from 0.75653 to 0.75711, saving model to gs://new_cxr_30/models/cxr_model/model-024.h5\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.6409 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9646 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5331 - f1: 0.0000e+00 - val_loss: 0.3667 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7581 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc improved from 0.75711 to 0.75813, saving model to gs://new_cxr_30/models/cxr_model/model-025.h5\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2259 - tp: 0.0000e+00 - fp: 2.4444 - tn: 69.7778 - fn: 6.0000 - accuracy: 0.8949 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6325 - f1: 0.0000e+00 - val_loss: 0.3698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7570 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.75813\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0338 - tp: 1.1111 - fp: 5.1111 - tn: 63.5556 - fn: 8.4444 - accuracy: 0.8299 - precision: 0.2202 - recall: 0.0970 - auc: 0.5616 - f1: 0.0815 - val_loss: 0.3816 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7494 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.75813\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 7.0943 - tp: 0.5556 - fp: 0.2222 - tn: 65.3333 - fn: 12.1111 - accuracy: 0.8130 - precision: 0.4444 - recall: 0.0366 - auc: 0.6496 - f1: 0.0563 - val_loss: 0.3646 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7551 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.75813\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.3175 - tp: 0.7778 - fp: 1.0000 - tn: 71.4444 - fn: 5.0000 - accuracy: 0.9237 - precision: 0.3889 - recall: 0.1575 - auc: 0.7917 - f1: 0.1492 - val_loss: 0.3679 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7564 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.75813\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5641 - tp: 2.5556 - fp: 3.1111 - tn: 64.5556 - fn: 8.0000 - accuracy: 0.8710 - precision: 0.5702 - recall: 0.3143 - auc: 0.7640 - f1: 0.4241 - val_loss: 0.3674 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7524 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.75813\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6417 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.6667 - fn: 8.5556 - accuracy: 0.8971 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6795 - f1: 0.0000e+00 - val_loss: 0.3598 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7534 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.75813\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3593 - tp: 1.5556 - fp: 5.5556 - tn: 65.3333 - fn: 5.7778 - accuracy: 0.8521 - precision: 0.1944 - recall: 0.2130 - auc: 0.7679 - f1: 0.1268 - val_loss: 0.3697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7499 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.75813\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.1960 - tp: 0.2222 - fp: 0.0000e+00 - tn: 65.5556 - fn: 12.4444 - accuracy: 0.8302 - precision: 0.2222 - recall: 0.0131 - auc: 0.6907 - f1: 0.0278 - val_loss: 0.3527 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7524 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.75813\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.5314 - tp: 0.4444 - fp: 2.2222 - tn: 62.2222 - fn: 13.3333 - accuracy: 0.7798 - precision: 0.1037 - recall: 0.0261 - auc: 0.7347 - f1: 0.0622 - val_loss: 0.3707 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7533 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.75813\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.3990 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.1111 - fn: 4.1111 - accuracy: 0.9605 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3871 - f1: 0.0000e+00 - val_loss: 0.3838 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7465 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.75813\n","Restoring model weights from the end of the best epoch.\n","Epoch 00035: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 46%|████▌     | 11/24 [2:07:10<2:21:49, 654.57s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 1, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 11.5294 - tp: 1.3333 - fp: 9.2222 - tn: 59.5556 - fn: 8.1111 - accuracy: 0.7453 - precision: 0.0775 - recall: 0.0879 - auc: 0.5354 - f1: 0.0522 - val_loss: 0.3814 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7045 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.70453, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 20.0344 - tp: 0.0000e+00 - fp: 4.8889 - tn: 64.1111 - fn: 9.2222 - accuracy: 0.7989 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3703 - f1: 0.0000e+00 - val_loss: 0.3687 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7176 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.70453 to 0.71760, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.8945 - tp: 0.3333 - fp: 3.5556 - tn: 69.3333 - fn: 5.0000 - accuracy: 0.9026 - precision: 0.0476 - recall: 0.0344 - auc: 0.5942 - f1: 0.0291 - val_loss: 0.3561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7287 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.71760 to 0.72869, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.7766 - tp: 4.5556 - fp: 10.7778 - tn: 53.2222 - fn: 9.6667 - accuracy: 0.7279 - precision: 0.2318 - recall: 0.2505 - auc: 0.5071 - f1: 0.1818 - val_loss: 0.3548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7365 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.72869 to 0.73655, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.0447 - tp: 1.1111 - fp: 5.6667 - tn: 66.3333 - fn: 5.1111 - accuracy: 0.8652 - precision: 0.1296 - recall: 0.1592 - auc: 0.7000 - f1: 0.0645 - val_loss: 0.3596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7341 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.73655\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.8224 - tp: 2.2222 - fp: 8.3333 - tn: 59.8889 - fn: 7.7778 - accuracy: 0.7859 - precision: 0.1457 - recall: 0.1710 - auc: 0.5462 - f1: 0.1053 - val_loss: 0.3665 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7388 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.73655 to 0.73878, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.3853 - tp: 0.2222 - fp: 0.0000e+00 - tn: 73.4444 - fn: 4.5556 - accuracy: 0.9445 - precision: 0.2222 - recall: 0.0222 - auc: 0.7113 - f1: 0.0185 - val_loss: 0.3602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7430 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.73878 to 0.74302, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.5666 - tp: 3.4444 - fp: 12.5556 - tn: 54.0000 - fn: 8.2222 - accuracy: 0.7206 - precision: 0.2234 - recall: 0.3326 - auc: 0.5726 - f1: 0.2358 - val_loss: 0.3714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7412 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.74302\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.4333 - tp: 1.0000 - fp: 6.2222 - tn: 59.1111 - fn: 11.8889 - accuracy: 0.7654 - precision: 0.0842 - recall: 0.0570 - auc: 0.5540 - f1: 0.0480 - val_loss: 0.3679 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7410 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.74302\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0597 - tp: 0.0000e+00 - fp: 0.5556 - tn: 71.6667 - fn: 6.0000 - accuracy: 0.9172 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4782 - f1: 0.0000e+00 - val_loss: 0.3696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7451 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.74302 to 0.74510, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.0982 - tp: 0.0000e+00 - fp: 4.5556 - tn: 62.3333 - fn: 11.3333 - accuracy: 0.7792 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5089 - f1: 0.0000e+00 - val_loss: 0.3726 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7494 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.74510 to 0.74943, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7796 - tp: 0.0000e+00 - fp: 2.0000 - tn: 69.7778 - fn: 6.4444 - accuracy: 0.9064 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4465 - f1: 0.0000e+00 - val_loss: 0.3590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7517 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.74943 to 0.75170, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.4621 - tp: 1.4444 - fp: 6.0000 - tn: 63.0000 - fn: 7.7778 - accuracy: 0.8051 - precision: 0.1640 - recall: 0.1314 - auc: 0.6458 - f1: 0.0875 - val_loss: 0.3675 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7513 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.75170\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.2507 - tp: 0.8889 - fp: 1.6667 - tn: 69.0000 - fn: 6.6667 - accuracy: 0.9139 - precision: 0.2130 - recall: 0.0670 - auc: 0.5775 - f1: 0.0407 - val_loss: 0.3599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7528 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.75170 to 0.75277, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.1650 - tp: 0.0000e+00 - fp: 2.8889 - tn: 70.4444 - fn: 4.8889 - accuracy: 0.9070 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4255 - f1: 0.0000e+00 - val_loss: 0.3774 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7510 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.75277\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3355 - tp: 1.1111 - fp: 2.6667 - tn: 69.2222 - fn: 5.2222 - accuracy: 0.9027 - precision: 0.2101 - recall: 0.1377 - auc: 0.6613 - f1: 0.1162 - val_loss: 0.3716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7553 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.75277 to 0.75526, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7491 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.3333 - fn: 6.8889 - accuracy: 0.9217 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7314 - f1: 0.0000e+00 - val_loss: 0.3706 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7552 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.75526\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6333 - tp: 2.4444 - fp: 4.4444 - tn: 65.5556 - fn: 5.7778 - accuracy: 0.8789 - precision: 0.3259 - recall: 0.3140 - auc: 0.6274 - f1: 0.2311 - val_loss: 0.3770 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7552 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.75526\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3865 - tp: 0.0000e+00 - fp: 4.0000 - tn: 67.4444 - fn: 6.7778 - accuracy: 0.8662 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6780 - f1: 0.0000e+00 - val_loss: 0.3804 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7560 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.75526 to 0.75598, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.0491 - tp: 0.5556 - fp: 1.8889 - tn: 69.1111 - fn: 6.6667 - accuracy: 0.8869 - precision: 0.2037 - recall: 0.0594 - auc: 0.6130 - f1: 0.0563 - val_loss: 0.3762 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7627 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.75598 to 0.76266, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6459 - tp: 0.0000e+00 - fp: 1.5556 - tn: 71.1111 - fn: 5.5556 - accuracy: 0.9037 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5008 - f1: 0.0000e+00 - val_loss: 0.3768 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7628 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc improved from 0.76266 to 0.76275, saving model to gs://new_cxr_30/models/cxr_model/model-021.h5\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5044 - tp: 0.0000e+00 - fp: 2.7778 - tn: 67.5556 - fn: 7.8889 - accuracy: 0.8775 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6578 - f1: 0.0000e+00 - val_loss: 0.3737 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7618 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.76275\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4573 - tp: 0.2222 - fp: 0.2222 - tn: 69.7778 - fn: 8.0000 - accuracy: 0.9008 - precision: 0.1111 - recall: 0.0148 - auc: 0.7061 - f1: 0.0139 - val_loss: 0.3598 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7569 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.76275\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0341 - tp: 2.5556 - fp: 4.4444 - tn: 64.0000 - fn: 7.2222 - accuracy: 0.8588 - precision: 0.3343 - recall: 0.2723 - auc: 0.7334 - f1: 0.2447 - val_loss: 0.3707 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7559 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.76275\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.4268 - tp: 0.4444 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.3333 - accuracy: 0.9685 - precision: 0.4444 - recall: 0.0683 - auc: 0.5862 - f1: 0.0622 - val_loss: 0.3601 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7570 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.76275\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5294 - tp: 0.0000e+00 - fp: 3.1111 - tn: 69.1111 - fn: 6.0000 - accuracy: 0.8879 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5592 - f1: 0.0000e+00 - val_loss: 0.3639 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7583 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.76275\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0725 - tp: 1.0000 - fp: 6.0000 - tn: 62.6667 - fn: 8.5556 - accuracy: 0.8159 - precision: 0.0864 - recall: 0.0785 - auc: 0.5751 - f1: 0.0489 - val_loss: 0.3709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7536 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.76275\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.3720 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 65.5556 - fn: 12.6667 - accuracy: 0.8094 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6881 - f1: 0.0000e+00 - val_loss: 0.3536 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7560 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.76275\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.8017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.4444 - fn: 5.7778 - accuracy: 0.9341 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5610 - f1: 0.0000e+00 - val_loss: 0.3679 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7559 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.76275\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.5444 - tp: 0.0000e+00 - fp: 3.4444 - tn: 64.2222 - fn: 10.5556 - accuracy: 0.8347 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7976 - f1: 0.0000e+00 - val_loss: 0.3533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7566 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.76275\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3893 - tp: 0.2222 - fp: 0.0000e+00 - tn: 69.6667 - fn: 8.3333 - accuracy: 0.8989 - precision: 0.2222 - recall: 0.0139 - auc: 0.6854 - f1: 0.0111 - val_loss: 0.3472 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 405.0000 - val_fn: 58.0000 - val_accuracy: 0.8747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7564 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.76275\n","Restoring model weights from the end of the best epoch.\n","Epoch 00031: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 12/24 [2:17:09<2:07:31, 637.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 33s 3s/step - loss: 9.7554 - tp: 1.7778 - fp: 12.8889 - tn: 55.8889 - fn: 7.6667 - accuracy: 0.7099 - precision: 0.1100 - recall: 0.1903 - auc: 0.5229 - f1: 0.0585 - val_loss: 0.3330 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7670 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.76696, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 15.3876 - tp: 0.5556 - fp: 1.1111 - tn: 68.8889 - fn: 7.6667 - accuracy: 0.8782 - precision: 0.1111 - recall: 0.0410 - auc: 0.5325 - f1: 0.0257 - val_loss: 0.3254 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7561 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc did not improve from 0.76696\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.8104 - tp: 3.4444 - fp: 10.2222 - tn: 57.4444 - fn: 7.1111 - accuracy: 0.7744 - precision: 0.2256 - recall: 0.3249 - auc: 0.5276 - f1: 0.2769 - val_loss: 0.3179 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7838 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.76696 to 0.78384, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.0416 - tp: 0.7778 - fp: 7.1111 - tn: 58.6667 - fn: 11.6667 - accuracy: 0.7795 - precision: 0.0556 - recall: 0.0405 - auc: 0.5575 - f1: 0.0352 - val_loss: 0.3124 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7866 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.78384 to 0.78658, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7042 - tp: 1.8889 - fp: 5.0000 - tn: 66.1111 - fn: 5.2222 - accuracy: 0.8653 - precision: 0.2791 - recall: 0.4075 - auc: 0.7222 - f1: 0.2262 - val_loss: 0.3091 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8039 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.78658 to 0.80385, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.2490 - tp: 1.0000 - fp: 5.6667 - tn: 60.8889 - fn: 10.6667 - accuracy: 0.8008 - precision: 0.1120 - recall: 0.0655 - auc: 0.4852 - f1: 0.0495 - val_loss: 0.3059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8072 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.80385 to 0.80723, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9279 - tp: 0.0000e+00 - fp: 3.2222 - tn: 68.8889 - fn: 6.1111 - accuracy: 0.8737 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4480 - f1: 0.0000e+00 - val_loss: 0.3080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8088 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.80723 to 0.80881, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.9744 - tp: 0.8889 - fp: 4.0000 - tn: 64.4444 - fn: 8.8889 - accuracy: 0.8491 - precision: 0.1056 - recall: 0.0634 - auc: 0.5839 - f1: 0.0387 - val_loss: 0.3039 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8107 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.80881 to 0.81068, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.6903 - tp: 0.6667 - fp: 6.8889 - tn: 62.4444 - fn: 8.2222 - accuracy: 0.7857 - precision: 0.0741 - recall: 0.0632 - auc: 0.5157 - f1: 0.0561 - val_loss: 0.3074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8142 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.81068 to 0.81423, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.7591 - tp: 0.0000e+00 - fp: 0.2222 - tn: 70.8889 - fn: 7.1111 - accuracy: 0.8963 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4763 - f1: 0.0000e+00 - val_loss: 0.3059 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8153 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.81423 to 0.81529, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.3095 - tp: 0.8889 - fp: 2.7778 - tn: 65.3333 - fn: 9.2222 - accuracy: 0.8270 - precision: 0.2315 - recall: 0.0878 - auc: 0.6461 - f1: 0.0819 - val_loss: 0.3080 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8159 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.81529 to 0.81591, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.2124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.6667 - fn: 6.5556 - accuracy: 0.9298 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4246 - f1: 0.0000e+00 - val_loss: 0.3060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8135 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.81591\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9863 - tp: 1.4444 - fp: 5.2222 - tn: 63.7778 - fn: 7.7778 - accuracy: 0.8517 - precision: 0.1799 - recall: 0.1338 - auc: 0.6691 - f1: 0.0747 - val_loss: 0.3065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8164 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.81591 to 0.81640, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7964 - tp: 0.6667 - fp: 0.0000e+00 - tn: 70.6667 - fn: 6.8889 - accuracy: 0.9143 - precision: 0.4444 - recall: 0.0558 - auc: 0.7196 - f1: 0.0899 - val_loss: 0.3044 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8167 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.81640 to 0.81672, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9321 - tp: 0.0000e+00 - fp: 3.6667 - tn: 65.8889 - fn: 8.6667 - accuracy: 0.8511 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6321 - f1: 0.0000e+00 - val_loss: 0.3047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8129 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.81672\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.4288 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.0000 - fn: 6.2222 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6242 - f1: 0.0000e+00 - val_loss: 0.3065 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8102 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.81672\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9191 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.0000 - fn: 7.2222 - accuracy: 0.9191 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6415 - f1: 0.0000e+00 - val_loss: 0.3003 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8099 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.81672\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.1117 - tp: 0.7778 - fp: 7.2222 - tn: 62.1111 - fn: 8.1111 - accuracy: 0.7992 - precision: 0.0818 - recall: 0.0857 - auc: 0.7275 - f1: 0.0497 - val_loss: 0.3024 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8069 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.81672\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4044 - tp: 0.0000e+00 - fp: 1.1111 - tn: 70.8889 - fn: 6.2222 - accuracy: 0.8996 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6207 - f1: 0.0000e+00 - val_loss: 0.3060 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8101 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.81672\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.5521 - tp: 0.0000e+00 - fp: 1.1111 - tn: 69.7778 - fn: 7.3333 - accuracy: 0.8926 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8465 - f1: 0.0000e+00 - val_loss: 0.3038 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8123 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.81672\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0560 - tp: 0.0000e+00 - fp: 2.3333 - tn: 69.3333 - fn: 6.5556 - accuracy: 0.8947 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7067 - f1: 0.0000e+00 - val_loss: 0.3061 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8121 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.81672\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7242 - tp: 0.0000e+00 - fp: 1.2222 - tn: 68.0000 - fn: 9.0000 - accuracy: 0.8707 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7274 - f1: 0.0000e+00 - val_loss: 0.2993 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8141 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.81672\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8547 - tp: 0.2222 - fp: 1.7778 - tn: 67.2222 - fn: 9.0000 - accuracy: 0.8658 - precision: 0.0741 - recall: 0.0131 - auc: 0.6527 - f1: 0.0139 - val_loss: 0.2976 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8180 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc improved from 0.81672 to 0.81800, saving model to gs://new_cxr_30/models/cxr_model/model-023.h5\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9266 - tp: 2.5556 - fp: 6.1111 - tn: 60.8889 - fn: 8.6667 - accuracy: 0.8242 - precision: 0.2446 - recall: 0.1919 - auc: 0.7453 - f1: 0.1668 - val_loss: 0.2940 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8191 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc improved from 0.81800 to 0.81911, saving model to gs://new_cxr_30/models/cxr_model/model-024.h5\n","Epoch 25/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.4002 - tp: 0.3333 - fp: 0.0000e+00 - tn: 70.3333 - fn: 7.5556 - accuracy: 0.9197 - precision: 0.3333 - recall: 0.0234 - auc: 0.4552 - f1: 0.0218 - val_loss: 0.2963 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8191 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.81911\n","Epoch 26/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6494 - tp: 0.6667 - fp: 2.5556 - tn: 67.0000 - fn: 8.0000 - accuracy: 0.8516 - precision: 0.1556 - recall: 0.0734 - auc: 0.7080 - f1: 0.0748 - val_loss: 0.2966 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8153 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.81911\n","Epoch 27/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.2069 - tp: 0.8889 - fp: 3.5556 - tn: 65.3333 - fn: 8.4444 - accuracy: 0.8403 - precision: 0.1323 - recall: 0.0695 - auc: 0.4750 - f1: 0.1062 - val_loss: 0.2955 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8158 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.81911\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.1710 - tp: 1.7778 - fp: 3.4444 - tn: 63.2222 - fn: 9.7778 - accuracy: 0.8248 - precision: 0.3593 - recall: 0.1497 - auc: 0.7630 - f1: 0.1024 - val_loss: 0.2937 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8161 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.81911\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.5968 - tp: 0.0000e+00 - fp: 0.8889 - tn: 67.8889 - fn: 9.4444 - accuracy: 0.8830 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6914 - f1: 0.0000e+00 - val_loss: 0.2925 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8172 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.81911\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6353 - tp: 1.5556 - fp: 8.0000 - tn: 59.4444 - fn: 9.2222 - accuracy: 0.7920 - precision: 0.1820 - recall: 0.1310 - auc: 0.6069 - f1: 0.0906 - val_loss: 0.3015 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8182 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.81911\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.6242 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 65.6667 - fn: 12.5556 - accuracy: 0.8288 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7200 - f1: 0.0000e+00 - val_loss: 0.2914 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8207 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc improved from 0.81911 to 0.82071, saving model to gs://new_cxr_30/models/cxr_model/model-031.h5\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.0864 - tp: 1.6667 - fp: 10.3333 - tn: 58.7778 - fn: 7.4444 - accuracy: 0.7690 - precision: 0.1754 - recall: 0.2035 - auc: 0.5204 - f1: 0.1584 - val_loss: 0.3034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8189 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.82071\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.7588 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.0000 - fn: 11.2222 - accuracy: 0.8600 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7011 - f1: 0.0000e+00 - val_loss: 0.2967 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8203 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.82071\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.6192 - tp: 2.3333 - fp: 4.1111 - tn: 61.3333 - fn: 10.4444 - accuracy: 0.7952 - precision: 0.4684 - recall: 0.1802 - auc: 0.7162 - f1: 0.2113 - val_loss: 0.2978 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8168 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.82071\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3986 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.2222 - fn: 6.0000 - accuracy: 0.9449 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2672 - f1: 0.0000e+00 - val_loss: 0.3207 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8162 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.82071\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6242 - tp: 0.2222 - fp: 1.0000 - tn: 70.1111 - fn: 6.8889 - accuracy: 0.9060 - precision: 0.0556 - recall: 0.0171 - auc: 0.5792 - f1: 0.0111 - val_loss: 0.2933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8201 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.82071\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.2024 - tp: 3.0000 - fp: 4.6667 - tn: 59.8889 - fn: 10.6667 - accuracy: 0.7719 - precision: 0.4213 - recall: 0.2348 - auc: 0.6815 - f1: 0.1579 - val_loss: 0.3010 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8141 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.82071\n","Epoch 38/500\n","8/8 [==============================] - 21s 3s/step - loss: 5.2522 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 66.8889 - fn: 11.3333 - accuracy: 0.8394 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5596 - f1: 0.0000e+00 - val_loss: 0.2933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8213 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc improved from 0.82071 to 0.82133, saving model to gs://new_cxr_30/models/cxr_model/model-038.h5\n","Epoch 39/500\n","8/8 [==============================] - 21s 3s/step - loss: 5.6917 - tp: 1.0000 - fp: 4.1111 - tn: 60.6667 - fn: 12.4444 - accuracy: 0.7717 - precision: 0.1373 - recall: 0.0564 - auc: 0.6089 - f1: 0.0873 - val_loss: 0.2919 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8219 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc improved from 0.82133 to 0.82192, saving model to gs://new_cxr_30/models/cxr_model/model-039.h5\n","Epoch 40/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.3417 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.8889 - fn: 3.3333 - accuracy: 0.9600 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4099 - f1: 0.0000e+00 - val_loss: 0.3219 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8156 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc did not improve from 0.82192\n","Epoch 41/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.6055 - tp: 0.0000e+00 - fp: 1.0000 - tn: 66.4444 - fn: 10.7778 - accuracy: 0.8537 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7056 - f1: 0.0000e+00 - val_loss: 0.2896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8203 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc did not improve from 0.82192\n","Epoch 42/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.0889 - tp: 0.0000e+00 - fp: 2.0000 - tn: 69.5556 - fn: 6.6667 - accuracy: 0.8795 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6625 - f1: 0.0000e+00 - val_loss: 0.2949 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8194 - val_f1: 0.0000e+00\n","\n","Epoch 00042: val_auc did not improve from 0.82192\n","Epoch 43/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.2959 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.6667 - fn: 7.5556 - accuracy: 0.8898 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7257 - f1: 0.0000e+00 - val_loss: 0.2923 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8203 - val_f1: 0.0000e+00\n","\n","Epoch 00043: val_auc did not improve from 0.82192\n","Epoch 44/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.2433 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.7778 - fn: 9.4444 - accuracy: 0.8805 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5556 - f1: 0.0000e+00 - val_loss: 0.2829 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8242 - val_f1: 0.0000e+00\n","\n","Epoch 00044: val_auc improved from 0.82192 to 0.82419, saving model to gs://new_cxr_30/models/cxr_model/model-044.h5\n","Epoch 45/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.8241 - tp: 0.0000e+00 - fp: 0.6667 - tn: 69.5556 - fn: 8.0000 - accuracy: 0.9151 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5014 - f1: 0.0000e+00 - val_loss: 0.2827 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8223 - val_f1: 0.0000e+00\n","\n","Epoch 00045: val_auc did not improve from 0.82419\n","Epoch 46/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.9985 - tp: 1.0000 - fp: 3.3333 - tn: 67.7778 - fn: 6.1111 - accuracy: 0.8737 - precision: 0.2537 - recall: 0.1929 - auc: 0.7963 - f1: 0.1263 - val_loss: 0.2973 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8269 - val_f1: 0.0000e+00\n","\n","Epoch 00046: val_auc improved from 0.82419 to 0.82685, saving model to gs://new_cxr_30/models/cxr_model/model-046.h5\n","Epoch 47/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.2114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.4444 - fn: 9.7778 - accuracy: 0.8691 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6647 - f1: 0.0000e+00 - val_loss: 0.2803 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8240 - val_f1: 0.0000e+00\n","\n","Epoch 00047: val_auc did not improve from 0.82685\n","Epoch 48/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.2453 - tp: 0.0000e+00 - fp: 2.2222 - tn: 68.7778 - fn: 7.2222 - accuracy: 0.8781 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7246 - f1: 0.0000e+00 - val_loss: 0.2872 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8258 - val_f1: 0.0000e+00\n","\n","Epoch 00048: val_auc did not improve from 0.82685\n","Epoch 49/500\n","8/8 [==============================] - 21s 3s/step - loss: 5.2825 - tp: 0.0000e+00 - fp: 0.4444 - tn: 67.2222 - fn: 10.5556 - accuracy: 0.8489 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5945 - f1: 0.0000e+00 - val_loss: 0.2795 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8250 - val_f1: 0.0000e+00\n","\n","Epoch 00049: val_auc did not improve from 0.82685\n","Epoch 50/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.7357 - tp: 0.0000e+00 - fp: 5.0000 - tn: 65.0000 - fn: 8.2222 - accuracy: 0.8202 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7007 - f1: 0.0000e+00 - val_loss: 0.2849 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8234 - val_f1: 0.0000e+00\n","\n","Epoch 00050: val_auc did not improve from 0.82685\n","Epoch 51/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.8937 - tp: 0.0000e+00 - fp: 0.8889 - tn: 70.5556 - fn: 6.7778 - accuracy: 0.8864 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8077 - f1: 0.0000e+00 - val_loss: 0.3186 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8209 - val_f1: 0.0000e+00\n","\n","Epoch 00051: val_auc did not improve from 0.82685\n","Epoch 52/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6668 - tp: 0.5556 - fp: 0.7778 - tn: 68.5556 - fn: 8.3333 - accuracy: 0.8877 - precision: 0.2778 - recall: 0.0445 - auc: 0.7384 - f1: 0.0422 - val_loss: 0.2749 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8218 - val_f1: 0.0000e+00\n","\n","Epoch 00052: val_auc did not improve from 0.82685\n","Epoch 53/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.3981 - tp: 1.3333 - fp: 9.2222 - tn: 58.5556 - fn: 9.1111 - accuracy: 0.7701 - precision: 0.1417 - recall: 0.2268 - auc: 0.6733 - f1: 0.1388 - val_loss: 0.2779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8239 - val_f1: 0.0000e+00\n","\n","Epoch 00053: val_auc did not improve from 0.82685\n","Epoch 54/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.6833 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.7778 - fn: 6.4444 - accuracy: 0.9034 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7352 - f1: 0.0000e+00 - val_loss: 0.2918 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8223 - val_f1: 0.0000e+00\n","\n","Epoch 00054: val_auc did not improve from 0.82685\n","Epoch 55/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.8904 - tp: 0.0000e+00 - fp: 0.7778 - tn: 68.1111 - fn: 9.3333 - accuracy: 0.8626 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6738 - f1: 0.0000e+00 - val_loss: 0.2760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8214 - val_f1: 0.0000e+00\n","\n","Epoch 00055: val_auc did not improve from 0.82685\n","Epoch 56/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9258 - tp: 1.1111 - fp: 2.5556 - tn: 66.8889 - fn: 7.6667 - accuracy: 0.8626 - precision: 0.2333 - recall: 0.0982 - auc: 0.6010 - f1: 0.1433 - val_loss: 0.2837 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8227 - val_f1: 0.0000e+00\n","\n","Epoch 00056: val_auc did not improve from 0.82685\n","Restoring model weights from the end of the best epoch.\n","Epoch 00056: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 54%|█████▍    | 13/24 [2:35:54<2:23:58, 785.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 7.2454 - tp: 0.0000e+00 - fp: 8.4444 - tn: 60.3333 - fn: 9.4444 - accuracy: 0.7044 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5138 - f1: 0.0000e+00 - val_loss: 0.3308 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7900 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.79003, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1932 - tp: 1.1111 - fp: 3.1111 - tn: 66.8889 - fn: 7.1111 - accuracy: 0.8484 - precision: 0.1852 - recall: 0.1027 - auc: 0.6453 - f1: 0.0563 - val_loss: 0.3255 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7919 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.79003 to 0.79185, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.5143 - tp: 2.1111 - fp: 5.1111 - tn: 62.5556 - fn: 8.4444 - accuracy: 0.8341 - precision: 0.2435 - recall: 0.1582 - auc: 0.4370 - f1: 0.1388 - val_loss: 0.3181 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7931 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.79185 to 0.79311, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.3981 - tp: 2.0000 - fp: 1.8889 - tn: 63.8889 - fn: 10.4444 - accuracy: 0.8593 - precision: 0.6032 - recall: 0.2022 - auc: 0.6269 - f1: 0.2730 - val_loss: 0.3127 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8006 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.79311 to 0.80058, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.0965 - tp: 0.0000e+00 - fp: 1.0000 - tn: 70.1111 - fn: 7.1111 - accuracy: 0.8937 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6703 - f1: 0.0000e+00 - val_loss: 0.3129 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8062 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.80058 to 0.80617, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.3764 - tp: 1.5556 - fp: 4.8889 - tn: 61.6667 - fn: 10.1111 - accuracy: 0.8169 - precision: 0.3296 - recall: 0.1295 - auc: 0.6171 - f1: 0.1686 - val_loss: 0.3112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8040 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.80617\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9387 - tp: 0.0000e+00 - fp: 1.6667 - tn: 70.4444 - fn: 6.1111 - accuracy: 0.9066 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5767 - f1: 0.0000e+00 - val_loss: 0.3118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8061 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.80617\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.8721 - tp: 1.2222 - fp: 7.1111 - tn: 61.3333 - fn: 8.5556 - accuracy: 0.8222 - precision: 0.1182 - recall: 0.0975 - auc: 0.5649 - f1: 0.0561 - val_loss: 0.3109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8093 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.80617 to 0.80925, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.8708 - tp: 0.0000e+00 - fp: 0.3333 - tn: 69.0000 - fn: 8.8889 - accuracy: 0.8795 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5270 - f1: 0.0000e+00 - val_loss: 0.3113 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8133 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.80925 to 0.81329, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5653 - tp: 1.3333 - fp: 0.0000e+00 - tn: 71.1111 - fn: 5.7778 - accuracy: 0.9147 - precision: 0.8889 - recall: 0.1690 - auc: 0.6149 - f1: 0.1438 - val_loss: 0.3116 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8139 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.81329 to 0.81391, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.2229 - tp: 0.0000e+00 - fp: 1.0000 - tn: 67.1111 - fn: 10.1111 - accuracy: 0.8432 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7090 - f1: 0.0000e+00 - val_loss: 0.3095 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8131 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.81391\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.9048 - tp: 0.5556 - fp: 2.4444 - tn: 69.2222 - fn: 6.0000 - accuracy: 0.9037 - precision: 0.1389 - recall: 0.0596 - auc: 0.6008 - f1: 0.0422 - val_loss: 0.3118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8136 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.81391\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.1216 - tp: 1.4444 - fp: 2.6667 - tn: 66.3333 - fn: 7.7778 - accuracy: 0.8784 - precision: 0.2735 - recall: 0.1198 - auc: 0.7637 - f1: 0.0788 - val_loss: 0.3054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8142 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.81391 to 0.81418, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7064 - tp: 1.1111 - fp: 2.6667 - tn: 68.0000 - fn: 6.4444 - accuracy: 0.8814 - precision: 0.2648 - recall: 0.1567 - auc: 0.6386 - f1: 0.1302 - val_loss: 0.3112 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8096 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.81418\n","Epoch 15/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.8688 - tp: 0.0000e+00 - fp: 1.6667 - tn: 67.8889 - fn: 8.6667 - accuracy: 0.8718 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6300 - f1: 0.0000e+00 - val_loss: 0.3073 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8153 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc improved from 0.81418 to 0.81527, saving model to gs://new_cxr_30/models/cxr_model/model-015.h5\n","Epoch 16/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.8179 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.0000 - fn: 6.2222 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4792 - f1: 0.0000e+00 - val_loss: 0.3137 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8111 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.81527\n","Epoch 17/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.4721 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.0000 - fn: 7.2222 - accuracy: 0.9191 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8425 - f1: 0.0000e+00 - val_loss: 0.3026 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8114 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.81527\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9480 - tp: 3.2222 - fp: 9.4444 - tn: 59.8889 - fn: 5.6667 - accuracy: 0.7987 - precision: 0.2713 - recall: 0.4132 - auc: 0.7464 - f1: 0.3322 - val_loss: 0.3089 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8116 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.81527\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.7818 - tp: 0.0000e+00 - fp: 0.6667 - tn: 71.3333 - fn: 6.2222 - accuracy: 0.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7109 - f1: 0.0000e+00 - val_loss: 0.3114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8138 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.81527\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.3504 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9032 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8479 - f1: 0.0000e+00 - val_loss: 0.3047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8127 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.81527\n","Epoch 21/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.4133 - tp: 0.0000e+00 - fp: 3.0000 - tn: 68.6667 - fn: 6.5556 - accuracy: 0.8777 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6361 - f1: 0.0000e+00 - val_loss: 0.3162 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8131 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.81527\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6090 - tp: 0.0000e+00 - fp: 1.0000 - tn: 68.2222 - fn: 9.0000 - accuracy: 0.8725 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5676 - f1: 0.0000e+00 - val_loss: 0.3017 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8104 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.81527\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4922 - tp: 0.7778 - fp: 0.8889 - tn: 68.1111 - fn: 8.4444 - accuracy: 0.8862 - precision: 0.3889 - recall: 0.0889 - auc: 0.7051 - f1: 0.0995 - val_loss: 0.3020 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8124 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.81527\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0188 - tp: 2.0000 - fp: 4.1111 - tn: 62.8889 - fn: 9.2222 - accuracy: 0.8413 - precision: 0.2697 - recall: 0.1451 - auc: 0.6579 - f1: 0.1433 - val_loss: 0.2986 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8152 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.81527\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3493 - tp: 0.7778 - fp: 0.8889 - tn: 69.4444 - fn: 7.1111 - accuracy: 0.9135 - precision: 0.3889 - recall: 0.0984 - auc: 0.4996 - f1: 0.0746 - val_loss: 0.3027 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8144 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.81527\n","Restoring model weights from the end of the best epoch.\n","Epoch 00025: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 58%|█████▊    | 14/24 [2:43:52<1:55:25, 692.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 5.4171 - tp: 0.6667 - fp: 3.8889 - tn: 64.8889 - fn: 8.7778 - accuracy: 0.8151 - precision: 0.1296 - recall: 0.0608 - auc: 0.6512 - f1: 0.1122 - val_loss: 0.3227 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7934 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.79343, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 14.3751 - tp: 0.0000e+00 - fp: 7.1111 - tn: 62.8889 - fn: 8.2222 - accuracy: 0.7943 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3826 - f1: 0.0000e+00 - val_loss: 0.3157 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7939 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.79343 to 0.79395, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.8114 - tp: 2.7778 - fp: 8.3333 - tn: 59.3333 - fn: 7.7778 - accuracy: 0.8071 - precision: 0.1984 - recall: 0.2148 - auc: 0.5263 - f1: 0.1292 - val_loss: 0.3056 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7897 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc did not improve from 0.79395\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.4321 - tp: 3.4444 - fp: 8.5556 - tn: 57.2222 - fn: 9.0000 - accuracy: 0.7768 - precision: 0.2261 - recall: 0.2077 - auc: 0.6994 - f1: 0.1999 - val_loss: 0.3087 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7985 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.79395 to 0.79853, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9512 - tp: 1.0000 - fp: 0.0000e+00 - tn: 71.1111 - fn: 6.1111 - accuracy: 0.9331 - precision: 1.0000 - recall: 0.2593 - auc: 0.7234 - f1: 0.3159 - val_loss: 0.3054 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7976 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.79853\n","Epoch 6/500\n","8/8 [==============================] - 17s 2s/step - loss: 7.7908 - tp: 2.8889 - fp: 9.2222 - tn: 57.3333 - fn: 8.7778 - accuracy: 0.7734 - precision: 0.2168 - recall: 0.2210 - auc: 0.5096 - f1: 0.1431 - val_loss: 0.3114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8044 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.79853 to 0.80445, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.5624 - tp: 0.0000e+00 - fp: 0.8889 - tn: 71.2222 - fn: 6.1111 - accuracy: 0.9207 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5825 - f1: 0.0000e+00 - val_loss: 0.3075 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8059 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.80445 to 0.80593, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.2426 - tp: 1.3333 - fp: 10.6667 - tn: 57.7778 - fn: 8.4444 - accuracy: 0.7617 - precision: 0.0847 - recall: 0.1114 - auc: 0.6064 - f1: 0.0561 - val_loss: 0.3133 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8063 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.80593 to 0.80634, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.1543 - tp: 0.4444 - fp: 2.1111 - tn: 67.2222 - fn: 8.4444 - accuracy: 0.8657 - precision: 0.0963 - recall: 0.0335 - auc: 0.4260 - f1: 0.0249 - val_loss: 0.3096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8078 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.80634 to 0.80785, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0484 - tp: 0.0000e+00 - fp: 2.0000 - tn: 69.1111 - fn: 7.1111 - accuracy: 0.8691 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5991 - f1: 0.0000e+00 - val_loss: 0.3131 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8091 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.80785 to 0.80906, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.7809 - tp: 0.3333 - fp: 1.8889 - tn: 66.2222 - fn: 9.7778 - accuracy: 0.8496 - precision: 0.0593 - recall: 0.0238 - auc: 0.6449 - f1: 0.0218 - val_loss: 0.3101 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8090 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.80906\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.6667 - fn: 6.5556 - accuracy: 0.9298 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4593 - f1: 0.0000e+00 - val_loss: 0.3074 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8010 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.80906\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1983 - tp: 1.4444 - fp: 3.1111 - tn: 65.8889 - fn: 7.7778 - accuracy: 0.8532 - precision: 0.2796 - recall: 0.1338 - auc: 0.8006 - f1: 0.1158 - val_loss: 0.3063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8042 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.80906\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.7597 - tp: 1.3333 - fp: 2.7778 - tn: 67.8889 - fn: 6.2222 - accuracy: 0.8848 - precision: 0.2944 - recall: 0.1783 - auc: 0.7956 - f1: 0.1646 - val_loss: 0.3090 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8036 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.80906\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2005 - tp: 1.3333 - fp: 3.1111 - tn: 66.4444 - fn: 7.3333 - accuracy: 0.8715 - precision: 0.2079 - recall: 0.1227 - auc: 0.5954 - f1: 0.0641 - val_loss: 0.3143 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8037 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.80906\n","Epoch 16/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.0517 - tp: 0.0000e+00 - fp: 0.3333 - tn: 71.6667 - fn: 6.2222 - accuracy: 0.9087 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5537 - f1: 0.0000e+00 - val_loss: 0.3155 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8066 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.80906\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.0137 - tp: 0.0000e+00 - fp: 1.7778 - tn: 69.2222 - fn: 7.2222 - accuracy: 0.8991 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7258 - f1: 0.0000e+00 - val_loss: 0.3041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8033 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.80906\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.8197 - tp: 2.8889 - fp: 5.2222 - tn: 64.1111 - fn: 6.0000 - accuracy: 0.8526 - precision: 0.3593 - recall: 0.3725 - auc: 0.7127 - f1: 0.2749 - val_loss: 0.3145 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7995 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.80906\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3411 - tp: 0.0000e+00 - fp: 1.8889 - tn: 70.1111 - fn: 6.2222 - accuracy: 0.8948 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6755 - f1: 0.0000e+00 - val_loss: 0.3237 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7981 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.80906\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9046 - tp: 0.0000e+00 - fp: 2.0000 - tn: 68.8889 - fn: 7.3333 - accuracy: 0.8865 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8199 - f1: 0.0000e+00 - val_loss: 0.3118 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7960 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.80906\n","Restoring model weights from the end of the best epoch.\n","Epoch 00020: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 62%|██████▎   | 15/24 [2:50:15<1:29:52, 599.15s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 10.1923 - tp: 0.0000e+00 - fp: 8.4444 - tn: 60.3333 - fn: 9.4444 - accuracy: 0.7410 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5983 - f1: 0.0000e+00 - val_loss: 0.3382 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7570 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.75700, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 18.9142 - tp: 1.0000 - fp: 8.1111 - tn: 61.8889 - fn: 7.2222 - accuracy: 0.8014 - precision: 0.0704 - recall: 0.0888 - auc: 0.4704 - f1: 0.0498 - val_loss: 0.3257 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7702 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.75700 to 0.77021, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.8219 - tp: 2.1111 - fp: 5.5556 - tn: 62.1111 - fn: 8.4444 - accuracy: 0.8438 - precision: 0.1756 - recall: 0.1312 - auc: 0.4809 - f1: 0.0836 - val_loss: 0.3172 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7731 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.77021 to 0.77314, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.6912 - tp: 2.0000 - fp: 3.1111 - tn: 62.6667 - fn: 10.4444 - accuracy: 0.8344 - precision: 0.3656 - recall: 0.1409 - auc: 0.7259 - f1: 0.1243 - val_loss: 0.3096 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7909 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.77314 to 0.79091, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.8169 - tp: 1.7778 - fp: 6.2222 - tn: 64.8889 - fn: 5.3333 - accuracy: 0.8459 - precision: 0.2284 - recall: 0.3705 - auc: 0.6993 - f1: 0.2325 - val_loss: 0.3107 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8089 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.79091 to 0.80891, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 9.4936 - tp: 2.0000 - fp: 7.8889 - tn: 58.6667 - fn: 9.6667 - accuracy: 0.7762 - precision: 0.1530 - recall: 0.1372 - auc: 0.5220 - f1: 0.0612 - val_loss: 0.3066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8075 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.80891\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2384 - tp: 0.2222 - fp: 1.3333 - tn: 70.7778 - fn: 5.8889 - accuracy: 0.9080 - precision: 0.0741 - recall: 0.0185 - auc: 0.4579 - f1: 0.0185 - val_loss: 0.3040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8144 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.80891 to 0.81440, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.9629 - tp: 1.2222 - fp: 8.4444 - tn: 60.0000 - fn: 8.5556 - accuracy: 0.7797 - precision: 0.0973 - recall: 0.0975 - auc: 0.5834 - f1: 0.0786 - val_loss: 0.3046 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8160 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.81440 to 0.81598, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.0999 - tp: 0.3333 - fp: 2.6667 - tn: 66.6667 - fn: 8.5556 - accuracy: 0.8566 - precision: 0.0593 - recall: 0.0234 - auc: 0.4827 - f1: 0.0218 - val_loss: 0.3038 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8175 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.81598 to 0.81751, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.2046 - tp: 0.0000e+00 - fp: 3.5556 - tn: 67.5556 - fn: 7.1111 - accuracy: 0.8537 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6000 - f1: 0.0000e+00 - val_loss: 0.3062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8165 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.81751\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1902 - tp: 0.3333 - fp: 3.0000 - tn: 65.1111 - fn: 9.7778 - accuracy: 0.8287 - precision: 0.0503 - recall: 0.0238 - auc: 0.6898 - f1: 0.0291 - val_loss: 0.3034 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8169 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.81751\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1600 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.6667 - fn: 6.5556 - accuracy: 0.9298 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5352 - f1: 0.0000e+00 - val_loss: 0.3040 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8114 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.81751\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.6155 - tp: 1.4444 - fp: 5.1111 - tn: 63.8889 - fn: 7.7778 - accuracy: 0.8422 - precision: 0.1872 - recall: 0.1338 - auc: 0.6787 - f1: 0.0871 - val_loss: 0.3019 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8116 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.81751\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.4946 - tp: 0.3333 - fp: 2.8889 - tn: 67.7778 - fn: 7.2222 - accuracy: 0.8591 - precision: 0.0833 - recall: 0.0264 - auc: 0.6633 - f1: 0.0218 - val_loss: 0.3036 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8072 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.81751\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0052 - tp: 1.5556 - fp: 4.0000 - tn: 65.5556 - fn: 7.1111 - accuracy: 0.8699 - precision: 0.4210 - recall: 0.1663 - auc: 0.6994 - f1: 0.1585 - val_loss: 0.3049 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8053 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.81751\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7659 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.0000 - fn: 6.2222 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6184 - f1: 0.0000e+00 - val_loss: 0.3025 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8046 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.81751\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6712 - tp: 1.1111 - fp: 1.6667 - tn: 69.3333 - fn: 6.1111 - accuracy: 0.9121 - precision: 0.3519 - recall: 0.1400 - auc: 0.7827 - f1: 0.0964 - val_loss: 0.2973 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8007 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.81751\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.3531 - tp: 0.7778 - fp: 4.4444 - tn: 64.8889 - fn: 8.1111 - accuracy: 0.8434 - precision: 0.1257 - recall: 0.0857 - auc: 0.5767 - f1: 0.0746 - val_loss: 0.3026 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8038 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.81751\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.4175 - tp: 0.3333 - fp: 0.6667 - tn: 71.3333 - fn: 5.8889 - accuracy: 0.9098 - precision: 0.1667 - recall: 0.0346 - auc: 0.6471 - f1: 0.0291 - val_loss: 0.3046 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8042 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.81751\n","Restoring model weights from the end of the best epoch.\n","Epoch 00019: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|██████▋   | 16/24 [2:56:21<1:10:32, 529.04s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 33.3036 - tp: 2.6667 - fp: 20.1111 - tn: 48.6667 - fn: 6.7778 - accuracy: 0.6353 - precision: 0.1073 - recall: 0.2854 - auc: 0.5179 - f1: 0.0647 - val_loss: 0.3919 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7190 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.71904, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 30.7025 - tp: 0.4444 - fp: 6.2222 - tn: 63.7778 - fn: 7.7778 - accuracy: 0.8313 - precision: 0.0347 - recall: 0.0375 - auc: 0.4892 - f1: 0.0207 - val_loss: 0.3313 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.71904 to 0.77701, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 18.2055 - tp: 0.0000e+00 - fp: 6.1111 - tn: 61.5556 - fn: 10.5556 - accuracy: 0.7793 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3782 - f1: 0.0000e+00 - val_loss: 0.3223 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7962 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.77701 to 0.79616, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 12.2684 - tp: 5.7778 - fp: 19.2222 - tn: 46.5556 - fn: 6.6667 - accuracy: 0.6633 - precision: 0.2516 - recall: 0.5797 - auc: 0.6548 - f1: 0.3398 - val_loss: 0.3274 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8023 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.79616 to 0.80233, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.8492 - tp: 2.2222 - fp: 4.1111 - tn: 67.0000 - fn: 4.8889 - accuracy: 0.8945 - precision: 0.3644 - recall: 0.2722 - auc: 0.6539 - f1: 0.2388 - val_loss: 0.3239 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8046 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.80233 to 0.80457, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.3455 - tp: 1.8889 - fp: 5.3333 - tn: 61.2222 - fn: 9.7778 - accuracy: 0.7913 - precision: 0.2066 - recall: 0.1271 - auc: 0.5443 - f1: 0.1085 - val_loss: 0.3221 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8062 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.80457 to 0.80617, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.5396 - tp: 1.2222 - fp: 3.8889 - tn: 68.2222 - fn: 4.8889 - accuracy: 0.8805 - precision: 0.1780 - recall: 0.1437 - auc: 0.4377 - f1: 0.0964 - val_loss: 0.3228 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8121 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.80617 to 0.81209, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.2795 - tp: 2.2222 - fp: 6.7778 - tn: 61.6667 - fn: 7.5556 - accuracy: 0.8296 - precision: 0.3005 - recall: 0.2588 - auc: 0.6114 - f1: 0.2197 - val_loss: 0.3303 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8077 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.81209\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 7.0625 - tp: 0.5556 - fp: 2.3333 - tn: 67.0000 - fn: 8.3333 - accuracy: 0.8646 - precision: 0.0778 - recall: 0.0382 - auc: 0.6477 - f1: 0.0286 - val_loss: 0.3177 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8079 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.81209\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.7085 - tp: 1.7778 - fp: 3.8889 - tn: 67.2222 - fn: 5.3333 - accuracy: 0.8551 - precision: 0.3093 - recall: 0.2774 - auc: 0.5596 - f1: 0.2545 - val_loss: 0.3263 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8045 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.81209\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.0476 - tp: 0.8889 - fp: 2.8889 - tn: 65.2222 - fn: 9.2222 - accuracy: 0.8458 - precision: 0.1519 - recall: 0.0661 - auc: 0.7114 - f1: 0.0567 - val_loss: 0.3201 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8040 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.81209\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.4239 - tp: 0.0000e+00 - fp: 1.4444 - tn: 70.2222 - fn: 6.5556 - accuracy: 0.9135 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5273 - f1: 0.0000e+00 - val_loss: 0.3192 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7994 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.81209\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.4634 - tp: 2.5556 - fp: 7.6667 - tn: 61.3333 - fn: 6.6667 - accuracy: 0.8056 - precision: 0.2127 - recall: 0.2317 - auc: 0.6479 - f1: 0.1426 - val_loss: 0.3176 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8008 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.81209\n","Epoch 14/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3933 - tp: 1.3333 - fp: 4.0000 - tn: 66.6667 - fn: 6.2222 - accuracy: 0.8564 - precision: 0.2323 - recall: 0.1783 - auc: 0.5490 - f1: 0.1987 - val_loss: 0.3148 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7977 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.81209\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9600 - tp: 1.4444 - fp: 6.0000 - tn: 63.5556 - fn: 7.2222 - accuracy: 0.8247 - precision: 0.1605 - recall: 0.1385 - auc: 0.7448 - f1: 0.0971 - val_loss: 0.3283 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8004 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.81209\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.0000 - fn: 6.2222 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6631 - f1: 0.0000e+00 - val_loss: 0.3284 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8031 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.81209\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5045 - tp: 0.0000e+00 - fp: 0.7778 - tn: 70.2222 - fn: 7.2222 - accuracy: 0.9121 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6318 - f1: 0.0000e+00 - val_loss: 0.3114 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7989 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.81209\n","Restoring model weights from the end of the best epoch.\n","Epoch 00017: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 71%|███████   | 17/24 [3:01:51<54:43, 469.02s/it]  "],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 2, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 33s 3s/step - loss: 12.1921 - tp: 0.0000e+00 - fp: 9.5556 - tn: 59.2222 - fn: 9.4444 - accuracy: 0.7435 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5611 - f1: 0.0000e+00 - val_loss: 0.3350 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7656 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.76555, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 20.9682 - tp: 0.5556 - fp: 6.3333 - tn: 63.6667 - fn: 7.6667 - accuracy: 0.8231 - precision: 0.0382 - recall: 0.0410 - auc: 0.4978 - f1: 0.0248 - val_loss: 0.3152 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7892 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.76555 to 0.78924, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.1232 - tp: 0.7778 - fp: 7.4444 - tn: 60.2222 - fn: 9.7778 - accuracy: 0.8091 - precision: 0.0387 - recall: 0.0407 - auc: 0.4623 - f1: 0.0178 - val_loss: 0.3130 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7937 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.78924 to 0.79368, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.7329 - tp: 3.3333 - fp: 2.1111 - tn: 63.6667 - fn: 9.1111 - accuracy: 0.8702 - precision: 0.6947 - recall: 0.2761 - auc: 0.6124 - f1: 0.3396 - val_loss: 0.3108 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8029 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.79368 to 0.80292, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9807 - tp: 1.8889 - fp: 5.2222 - tn: 65.8889 - fn: 5.2222 - accuracy: 0.8514 - precision: 0.2643 - recall: 0.4075 - auc: 0.6590 - f1: 0.2077 - val_loss: 0.3109 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8022 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.80292\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.9556 - tp: 3.1111 - fp: 8.5556 - tn: 58.0000 - fn: 8.5556 - accuracy: 0.7764 - precision: 0.1934 - recall: 0.2084 - auc: 0.4437 - f1: 0.1155 - val_loss: 0.3098 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8090 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.80292 to 0.80896, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.8465 - tp: 0.0000e+00 - fp: 1.3333 - tn: 70.7778 - fn: 6.1111 - accuracy: 0.9173 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4199 - f1: 0.0000e+00 - val_loss: 0.3063 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8130 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.80896 to 0.81297, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.8589 - tp: 2.1111 - fp: 9.0000 - tn: 59.4444 - fn: 7.6667 - accuracy: 0.7711 - precision: 0.1936 - recall: 0.2800 - auc: 0.6620 - f1: 0.1657 - val_loss: 0.3064 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8128 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.81297\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1902 - tp: 0.7778 - fp: 4.6667 - tn: 64.6667 - fn: 8.1111 - accuracy: 0.8312 - precision: 0.1188 - recall: 0.0854 - auc: 0.5125 - f1: 0.0497 - val_loss: 0.3079 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8098 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.81297\n","Epoch 10/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.6491 - tp: 0.4444 - fp: 4.5556 - tn: 66.5556 - fn: 6.6667 - accuracy: 0.8561 - precision: 0.0509 - recall: 0.0469 - auc: 0.3839 - f1: 0.0311 - val_loss: 0.3087 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8133 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.81297 to 0.81329, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.6964 - tp: 0.6667 - fp: 1.7778 - tn: 66.3333 - fn: 9.4444 - accuracy: 0.8550 - precision: 0.3185 - recall: 0.0534 - auc: 0.5402 - f1: 0.0561 - val_loss: 0.3082 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8117 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.81329\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.7705 - tp: 0.0000e+00 - fp: 1.1111 - tn: 70.5556 - fn: 6.5556 - accuracy: 0.9193 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5054 - f1: 0.0000e+00 - val_loss: 0.3018 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8127 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.81329\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.8521 - tp: 1.7778 - fp: 11.6667 - tn: 57.3333 - fn: 7.4444 - accuracy: 0.7394 - precision: 0.1107 - recall: 0.1556 - auc: 0.6308 - f1: 0.0922 - val_loss: 0.3066 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8165 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.81329 to 0.81650, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.1185 - tp: 0.2222 - fp: 2.8889 - tn: 67.7778 - fn: 7.3333 - accuracy: 0.8760 - precision: 0.0444 - recall: 0.0171 - auc: 0.7626 - f1: 0.0278 - val_loss: 0.2994 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8107 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.81650\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.5854 - tp: 0.0000e+00 - fp: 7.1111 - tn: 62.4444 - fn: 8.6667 - accuracy: 0.8036 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6242 - f1: 0.0000e+00 - val_loss: 0.3041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8129 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.81650\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.6798 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.0000 - fn: 6.2222 - accuracy: 0.9114 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7045 - f1: 0.0000e+00 - val_loss: 0.3032 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8124 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.81650\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.4134 - tp: 0.7778 - fp: 0.5556 - tn: 70.4444 - fn: 6.4444 - accuracy: 0.9239 - precision: 0.5741 - recall: 0.1150 - auc: 0.6016 - f1: 0.0746 - val_loss: 0.2918 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8145 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.81650\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.7630 - tp: 1.7778 - fp: 13.1111 - tn: 56.2222 - fn: 7.1111 - accuracy: 0.7173 - precision: 0.1246 - recall: 0.2640 - auc: 0.5762 - f1: 0.1329 - val_loss: 0.3047 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8119 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.81650\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.5285 - tp: 0.0000e+00 - fp: 0.8889 - tn: 71.1111 - fn: 6.2222 - accuracy: 0.9054 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6152 - f1: 0.0000e+00 - val_loss: 0.2985 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8101 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.81650\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.3691 - tp: 0.6667 - fp: 1.1111 - tn: 69.7778 - fn: 6.6667 - accuracy: 0.8981 - precision: 0.2778 - recall: 0.0733 - auc: 0.8726 - f1: 0.0561 - val_loss: 0.3018 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8058 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.81650\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3705 - tp: 0.0000e+00 - fp: 4.6667 - tn: 67.0000 - fn: 6.5556 - accuracy: 0.8673 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7002 - f1: 0.0000e+00 - val_loss: 0.3023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8007 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.81650\n","Epoch 22/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.1255 - tp: 1.3333 - fp: 1.4444 - tn: 67.7778 - fn: 7.6667 - accuracy: 0.8822 - precision: 0.4222 - recall: 0.1225 - auc: 0.6367 - f1: 0.0919 - val_loss: 0.2977 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8033 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.81650\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3974 - tp: 0.6667 - fp: 4.7778 - tn: 64.2222 - fn: 8.5556 - accuracy: 0.8333 - precision: 0.0513 - recall: 0.0392 - auc: 0.7525 - f1: 0.0167 - val_loss: 0.2951 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 414.0000 - val_fn: 49.0000 - val_accuracy: 0.8942 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8033 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.81650\n","Restoring model weights from the end of the best epoch.\n","Epoch 00023: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 18/24 [3:09:14<46:08, 461.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 5.5897 - tp: 0.0000e+00 - fp: 4.0000 - tn: 69.0000 - fn: 5.2222 - accuracy: 0.8379 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5402 - f1: 0.0000e+00 - val_loss: 0.3686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7317 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.73165, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.5557 - tp: 1.2222 - fp: 4.3333 - tn: 64.5556 - fn: 8.1111 - accuracy: 0.8636 - precision: 0.1799 - recall: 0.1012 - auc: 0.5919 - f1: 0.0842 - val_loss: 0.3608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7406 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.73165 to 0.74055, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.6413 - tp: 1.8889 - fp: 6.3333 - tn: 58.4444 - fn: 11.5556 - accuracy: 0.7833 - precision: 0.1433 - recall: 0.0937 - auc: 0.6255 - f1: 0.0654 - val_loss: 0.3599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7480 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.74055 to 0.74796, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.5809 - tp: 0.0000e+00 - fp: 3.8889 - tn: 66.7778 - fn: 7.5556 - accuracy: 0.8188 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4928 - f1: 0.0000e+00 - val_loss: 0.3616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7591 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.74796 to 0.75910, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 3s/step - loss: 6.4726 - tp: 0.7778 - fp: 8.3333 - tn: 60.1111 - fn: 9.0000 - accuracy: 0.7840 - precision: 0.0749 - recall: 0.0728 - auc: 0.5929 - f1: 0.0426 - val_loss: 0.3669 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7591 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.75910 to 0.75914, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 8.0652 - tp: 0.0000e+00 - fp: 2.3333 - tn: 64.4444 - fn: 11.4444 - accuracy: 0.8225 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6028 - f1: 0.0000e+00 - val_loss: 0.3550 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7552 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.75914\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.9537 - tp: 3.3333 - fp: 6.5556 - tn: 62.4444 - fn: 5.8889 - accuracy: 0.8322 - precision: 0.2913 - recall: 0.3379 - auc: 0.6825 - f1: 0.2471 - val_loss: 0.3613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7592 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.75914 to 0.75925, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8027 - tp: 0.0000e+00 - fp: 1.3333 - tn: 70.0000 - fn: 6.8889 - accuracy: 0.8823 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6465 - f1: 0.0000e+00 - val_loss: 0.3609 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7608 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.75925 to 0.76077, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.1770 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.7778 - fn: 5.4444 - accuracy: 0.9400 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6627 - f1: 0.0000e+00 - val_loss: 0.3590 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7599 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.76077\n","Epoch 10/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.6705 - tp: 0.0000e+00 - fp: 1.2222 - tn: 70.7778 - fn: 6.2222 - accuracy: 0.9136 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5712 - f1: 0.0000e+00 - val_loss: 0.3579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7649 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.76077 to 0.76489, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.2433 - tp: 0.5556 - fp: 7.3333 - tn: 59.8889 - fn: 10.4444 - accuracy: 0.7823 - precision: 0.0458 - recall: 0.0388 - auc: 0.5795 - f1: 0.0281 - val_loss: 0.3646 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7669 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.76489 to 0.76687, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8471 - tp: 0.0000e+00 - fp: 0.8889 - tn: 69.0000 - fn: 8.3333 - accuracy: 0.8875 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6816 - f1: 0.0000e+00 - val_loss: 0.3589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7674 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.76687 to 0.76737, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.3454 - tp: 0.0000e+00 - fp: 2.2222 - tn: 66.8889 - fn: 9.1111 - accuracy: 0.8335 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6119 - f1: 0.0000e+00 - val_loss: 0.3573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7671 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.76737\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.5709 - tp: 0.0000e+00 - fp: 0.8889 - tn: 72.7778 - fn: 4.5556 - accuracy: 0.9455 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3492 - f1: 0.0000e+00 - val_loss: 0.3577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7686 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.76737 to 0.76863, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9923 - tp: 0.0000e+00 - fp: 2.8889 - tn: 70.5556 - fn: 4.7778 - accuracy: 0.8852 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6783 - f1: 0.0000e+00 - val_loss: 0.3609 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7741 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc improved from 0.76863 to 0.77414, saving model to gs://new_cxr_30/models/cxr_model/model-015.h5\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6629 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6792 - f1: 0.0000e+00 - val_loss: 0.3522 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7778 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.77414 to 0.77781, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.4576 - tp: 1.3333 - fp: 5.8889 - tn: 61.0000 - fn: 10.0000 - accuracy: 0.8198 - precision: 0.2636 - recall: 0.0955 - auc: 0.6582 - f1: 0.0738 - val_loss: 0.3508 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7792 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.77781 to 0.77918, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.4616 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.2222 - fn: 11.0000 - accuracy: 0.8601 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6358 - f1: 0.0000e+00 - val_loss: 0.3497 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7769 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.77918\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6133 - tp: 0.0000e+00 - fp: 2.1111 - tn: 64.3333 - fn: 11.7778 - accuracy: 0.8166 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6211 - f1: 0.0000e+00 - val_loss: 0.3466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7764 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.77918\n","Epoch 20/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6379 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 68.4444 - fn: 9.7778 - accuracy: 0.8729 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6996 - f1: 0.0000e+00 - val_loss: 0.3527 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7768 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.77918\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.4392 - tp: 0.0000e+00 - fp: 1.3333 - tn: 66.5556 - fn: 10.3333 - accuracy: 0.8370 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6242 - f1: 0.0000e+00 - val_loss: 0.3450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7739 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.77918\n","Epoch 22/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.3524 - tp: 0.8889 - fp: 2.8889 - tn: 63.6667 - fn: 10.7778 - accuracy: 0.8074 - precision: 0.2333 - recall: 0.0879 - auc: 0.6828 - f1: 0.1365 - val_loss: 0.3450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7736 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.77918\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3352 - tp: 0.0000e+00 - fp: 2.0000 - tn: 68.8889 - fn: 7.3333 - accuracy: 0.8714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7004 - f1: 0.0000e+00 - val_loss: 0.3532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7798 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc improved from 0.77918 to 0.77979, saving model to gs://new_cxr_30/models/cxr_model/model-023.h5\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8315 - tp: 0.0000e+00 - fp: 0.7778 - tn: 68.5556 - fn: 8.8889 - accuracy: 0.8739 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6686 - f1: 0.0000e+00 - val_loss: 0.3492 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7797 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.77979\n","Epoch 25/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0231 - tp: 0.3333 - fp: 0.4444 - tn: 69.1111 - fn: 8.3333 - accuracy: 0.8957 - precision: 0.1667 - recall: 0.0241 - auc: 0.7145 - f1: 0.0291 - val_loss: 0.3486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7763 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.77979\n","Epoch 26/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.4611 - tp: 0.0000e+00 - fp: 0.6667 - tn: 70.5556 - fn: 7.0000 - accuracy: 0.9010 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8251 - f1: 0.0000e+00 - val_loss: 0.3538 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7799 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc improved from 0.77979 to 0.77985, saving model to gs://new_cxr_30/models/cxr_model/model-026.h5\n","Epoch 27/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.7565 - tp: 1.7778 - fp: 2.2222 - tn: 61.3333 - fn: 12.8889 - accuracy: 0.7993 - precision: 0.6217 - recall: 0.1250 - auc: 0.6127 - f1: 0.1582 - val_loss: 0.3404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7822 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc improved from 0.77985 to 0.78216, saving model to gs://new_cxr_30/models/cxr_model/model-027.h5\n","Epoch 28/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0286 - tp: 0.0000e+00 - fp: 3.8889 - tn: 70.1111 - fn: 4.2222 - accuracy: 0.8875 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3808 - f1: 0.0000e+00 - val_loss: 0.3800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7831 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc improved from 0.78216 to 0.78309, saving model to gs://new_cxr_30/models/cxr_model/model-028.h5\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1787 - tp: 0.0000e+00 - fp: 0.7778 - tn: 70.6667 - fn: 6.7778 - accuracy: 0.9165 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5754 - f1: 0.0000e+00 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7801 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.78309\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.6332 - tp: 1.4444 - fp: 3.2222 - tn: 67.8889 - fn: 5.6667 - accuracy: 0.8966 - precision: 0.3029 - recall: 0.1887 - auc: 0.6883 - f1: 0.1241 - val_loss: 0.3530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7799 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.78309\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 1.8794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4455 - f1: 0.0000e+00 - val_loss: 0.3790 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7805 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.78309\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.4162 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 73.8889 - fn: 4.3333 - accuracy: 0.9476 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5190 - f1: 0.0000e+00 - val_loss: 0.3575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7834 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc improved from 0.78309 to 0.78339, saving model to gs://new_cxr_30/models/cxr_model/model-032.h5\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.0720 - tp: 0.2222 - fp: 1.4444 - tn: 67.5556 - fn: 9.0000 - accuracy: 0.8639 - precision: 0.0741 - recall: 0.0148 - auc: 0.6592 - f1: 0.0185 - val_loss: 0.3406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7828 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.78339\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.7884 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.2222 - fn: 6.0000 - accuracy: 0.9239 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6143 - f1: 0.0000e+00 - val_loss: 0.3502 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7826 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.78339\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.5556 - fn: 10.6667 - accuracy: 0.8671 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7708 - f1: 0.0000e+00 - val_loss: 0.3377 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7796 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.78339\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4582 - tp: 0.0000e+00 - fp: 1.3333 - tn: 67.2222 - fn: 9.6667 - accuracy: 0.8568 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7441 - f1: 0.0000e+00 - val_loss: 0.3438 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7844 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc improved from 0.78339 to 0.78437, saving model to gs://new_cxr_30/models/cxr_model/model-036.h5\n","Epoch 37/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.0480 - tp: 1.4444 - fp: 1.1111 - tn: 67.4444 - fn: 8.2222 - accuracy: 0.9001 - precision: 0.5778 - recall: 0.2749 - auc: 0.7791 - f1: 0.3298 - val_loss: 0.3316 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7808 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.78437\n","Epoch 38/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.5423 - tp: 0.8889 - fp: 2.7778 - tn: 71.4444 - fn: 3.1111 - accuracy: 0.9144 - precision: 0.2315 - recall: 0.2243 - auc: 0.6944 - f1: 0.1024 - val_loss: 0.3760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7830 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.78437\n","Epoch 39/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.9706 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.7778 - fn: 8.4444 - accuracy: 0.8918 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6252 - f1: 0.0000e+00 - val_loss: 0.3385 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7777 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.78437\n","Epoch 40/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0257 - tp: 1.3333 - fp: 3.4444 - tn: 65.8889 - fn: 7.5556 - accuracy: 0.8751 - precision: 0.2336 - recall: 0.1250 - auc: 0.6922 - f1: 0.1168 - val_loss: 0.3420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7797 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc did not improve from 0.78437\n","Epoch 41/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.1275 - tp: 0.0000e+00 - fp: 1.4444 - tn: 69.1111 - fn: 7.6667 - accuracy: 0.8851 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7364 - f1: 0.0000e+00 - val_loss: 0.3624 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7801 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc did not improve from 0.78437\n","Epoch 42/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.5440 - tp: 0.0000e+00 - fp: 2.2222 - tn: 66.4444 - fn: 9.5556 - accuracy: 0.8690 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6136 - f1: 0.0000e+00 - val_loss: 0.3289 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7766 - val_f1: 0.0000e+00\n","\n","Epoch 00042: val_auc did not improve from 0.78437\n","Epoch 43/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.9778 - tp: 0.0000e+00 - fp: 4.4444 - tn: 62.7778 - fn: 11.0000 - accuracy: 0.7852 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5482 - f1: 0.0000e+00 - val_loss: 0.3416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7786 - val_f1: 0.0000e+00\n","\n","Epoch 00043: val_auc did not improve from 0.78437\n","Epoch 44/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.7171 - tp: 0.0000e+00 - fp: 1.4444 - tn: 69.0000 - fn: 7.7778 - accuracy: 0.8833 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5644 - f1: 0.0000e+00 - val_loss: 0.3507 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7801 - val_f1: 0.0000e+00\n","\n","Epoch 00044: val_auc did not improve from 0.78437\n","Epoch 45/500\n","8/8 [==============================] - 21s 3s/step - loss: 5.2944 - tp: 1.5556 - fp: 4.6667 - tn: 57.7778 - fn: 14.2222 - accuracy: 0.7660 - precision: 0.1340 - recall: 0.0687 - auc: 0.7292 - f1: 0.0695 - val_loss: 0.3264 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7789 - val_f1: 0.0000e+00\n","\n","Epoch 00045: val_auc did not improve from 0.78437\n","Epoch 46/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.7284 - tp: 1.8889 - fp: 4.0000 - tn: 67.6667 - fn: 4.6667 - accuracy: 0.8878 - precision: 0.3439 - recall: 0.3573 - auc: 0.7780 - f1: 0.2944 - val_loss: 0.3916 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7724 - val_f1: 0.0000e+00\n","\n","Epoch 00046: val_auc did not improve from 0.78437\n","Restoring model weights from the end of the best epoch.\n","Epoch 00046: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 79%|███████▉  | 19/24 [3:24:42<50:06, 601.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.001, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 6.0713 - tp: 1.0000 - fp: 6.0000 - tn: 67.0000 - fn: 4.2222 - accuracy: 0.8182 - precision: 0.1429 - recall: 0.2130 - auc: 0.6840 - f1: 0.0632 - val_loss: 0.4038 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7116 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.71157, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 3s/step - loss: 8.7481 - tp: 2.1111 - fp: 5.0000 - tn: 63.8889 - fn: 7.2222 - accuracy: 0.8749 - precision: 0.2314 - recall: 0.1614 - auc: 0.5882 - f1: 0.1034 - val_loss: 0.3661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7287 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.71157 to 0.72872, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 3s/step - loss: 8.1171 - tp: 1.8889 - fp: 6.3333 - tn: 58.4444 - fn: 11.5556 - accuracy: 0.7719 - precision: 0.2357 - recall: 0.2395 - auc: 0.5886 - f1: 0.2077 - val_loss: 0.3640 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7519 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.72872 to 0.75189, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.6744 - tp: 1.0000 - fp: 10.4444 - tn: 60.2222 - fn: 6.5556 - accuracy: 0.7681 - precision: 0.1107 - recall: 0.1621 - auc: 0.4504 - f1: 0.0902 - val_loss: 0.3715 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7524 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.75189 to 0.75243, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.6352 - tp: 0.6667 - fp: 3.2222 - tn: 65.2222 - fn: 9.1111 - accuracy: 0.8397 - precision: 0.0881 - recall: 0.0488 - auc: 0.6005 - f1: 0.0450 - val_loss: 0.3660 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7563 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.75243 to 0.75632, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.9913 - tp: 1.0000 - fp: 3.0000 - tn: 63.7778 - fn: 10.4444 - accuracy: 0.8216 - precision: 0.2667 - recall: 0.1264 - auc: 0.5968 - f1: 0.1263 - val_loss: 0.3630 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7604 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.75632 to 0.76038, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8121 - tp: 2.7778 - fp: 3.8889 - tn: 65.1111 - fn: 6.4444 - accuracy: 0.8667 - precision: 0.4128 - recall: 0.3349 - auc: 0.6294 - f1: 0.3197 - val_loss: 0.3647 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7571 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.76038\n","Epoch 8/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8024 - tp: 0.0000e+00 - fp: 1.5556 - tn: 69.7778 - fn: 6.8889 - accuracy: 0.8713 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5601 - f1: 0.0000e+00 - val_loss: 0.3663 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7627 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc improved from 0.76038 to 0.76272, saving model to gs://new_cxr_30/models/cxr_model/model-008.h5\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.1449 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.7778 - fn: 5.4444 - accuracy: 0.9400 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6494 - f1: 0.0000e+00 - val_loss: 0.3628 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7623 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.76272\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.3180 - tp: 0.7778 - fp: 0.0000e+00 - tn: 72.0000 - fn: 5.4444 - accuracy: 0.9444 - precision: 0.7778 - recall: 0.1424 - auc: 0.5772 - f1: 0.1492 - val_loss: 0.3628 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7647 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.76272 to 0.76468, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.0544 - tp: 1.6667 - fp: 2.5556 - tn: 64.6667 - fn: 9.3333 - accuracy: 0.8469 - precision: 0.3731 - recall: 0.1233 - auc: 0.5160 - f1: 0.1318 - val_loss: 0.3693 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7671 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.76468 to 0.76707, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8589 - tp: 0.0000e+00 - fp: 0.7778 - tn: 69.1111 - fn: 8.3333 - accuracy: 0.8878 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6535 - f1: 0.0000e+00 - val_loss: 0.3686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7651 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.76707\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1290 - tp: 0.0000e+00 - fp: 2.2222 - tn: 66.8889 - fn: 9.1111 - accuracy: 0.8533 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - f1: 0.0000e+00 - val_loss: 0.3652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7681 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.76707 to 0.76811, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.1170 - tp: 0.0000e+00 - fp: 0.2222 - tn: 73.4444 - fn: 4.5556 - accuracy: 0.9565 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4497 - f1: 0.0000e+00 - val_loss: 0.3697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7622 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.76811\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4110 - tp: 0.8889 - fp: 3.1111 - tn: 70.3333 - fn: 3.8889 - accuracy: 0.9055 - precision: 0.2389 - recall: 0.1833 - auc: 0.5823 - f1: 0.1365 - val_loss: 0.3765 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7670 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.76811\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.2201 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5736 - f1: 0.0000e+00 - val_loss: 0.3604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7665 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.76811\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0187 - tp: 1.7778 - fp: 7.0000 - tn: 59.8889 - fn: 9.5556 - accuracy: 0.8134 - precision: 0.2726 - recall: 0.1239 - auc: 0.4994 - f1: 0.0957 - val_loss: 0.3584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7736 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.76811 to 0.77356, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.3170 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.2222 - fn: 11.0000 - accuracy: 0.8601 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7218 - f1: 0.0000e+00 - val_loss: 0.3613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.77356 to 0.77703, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.3483 - tp: 2.6667 - fp: 4.8889 - tn: 61.5556 - fn: 9.1111 - accuracy: 0.8255 - precision: 0.5163 - recall: 0.2253 - auc: 0.6254 - f1: 0.2317 - val_loss: 0.3541 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7762 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.77703\n","Epoch 20/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9144 - tp: 1.0000 - fp: 1.3333 - tn: 67.1111 - fn: 8.7778 - accuracy: 0.8701 - precision: 0.4444 - recall: 0.1557 - auc: 0.7192 - f1: 0.1579 - val_loss: 0.3545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7765 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc did not improve from 0.77703\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8230 - tp: 1.4444 - fp: 0.5556 - tn: 67.3333 - fn: 8.8889 - accuracy: 0.8778 - precision: 0.7963 - recall: 0.1730 - auc: 0.6619 - f1: 0.2728 - val_loss: 0.3521 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7735 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.77703\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0308 - tp: 2.8889 - fp: 2.8889 - tn: 63.6667 - fn: 8.7778 - accuracy: 0.8544 - precision: 0.5257 - recall: 0.3192 - auc: 0.7778 - f1: 0.3170 - val_loss: 0.3533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7758 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.77703\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9053 - tp: 0.6667 - fp: 5.7778 - tn: 65.1111 - fn: 6.6667 - accuracy: 0.8356 - precision: 0.0781 - recall: 0.0799 - auc: 0.6633 - f1: 0.0561 - val_loss: 0.3563 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7744 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.77703\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0808 - tp: 0.0000e+00 - fp: 0.5556 - tn: 68.7778 - fn: 8.8889 - accuracy: 0.8779 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6517 - f1: 0.0000e+00 - val_loss: 0.3554 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7740 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.77703\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.2937 - tp: 1.2222 - fp: 2.1111 - tn: 67.4444 - fn: 7.4444 - accuracy: 0.8864 - precision: 0.3278 - recall: 0.1617 - auc: 0.6447 - f1: 0.1656 - val_loss: 0.3493 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7761 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.77703\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9194 - tp: 0.6667 - fp: 0.4444 - tn: 70.7778 - fn: 6.3333 - accuracy: 0.9098 - precision: 0.4444 - recall: 0.0754 - auc: 0.7218 - f1: 0.0748 - val_loss: 0.3525 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7763 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.77703\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.0258 - tp: 0.8889 - fp: 0.8889 - tn: 62.6667 - fn: 13.7778 - accuracy: 0.7925 - precision: 0.2407 - recall: 0.0450 - auc: 0.5880 - f1: 0.0622 - val_loss: 0.3460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7775 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc improved from 0.77703 to 0.77753, saving model to gs://new_cxr_30/models/cxr_model/model-027.h5\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.2676 - tp: 0.0000e+00 - fp: 0.8889 - tn: 73.1111 - fn: 4.2222 - accuracy: 0.9467 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4267 - f1: 0.0000e+00 - val_loss: 0.3682 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7739 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.77753\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1131 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.4444 - fn: 6.7778 - accuracy: 0.9231 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5251 - f1: 0.0000e+00 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7705 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.77753\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.5841 - tp: 1.4444 - fp: 1.8889 - tn: 69.2222 - fn: 5.6667 - accuracy: 0.9083 - precision: 0.3556 - recall: 0.1675 - auc: 0.6992 - f1: 0.1556 - val_loss: 0.3562 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7700 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.77753\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.0282 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4153 - f1: 0.0000e+00 - val_loss: 0.3760 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7768 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.77753\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.4316 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 73.8889 - fn: 4.3333 - accuracy: 0.9476 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5275 - f1: 0.0000e+00 - val_loss: 0.3565 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7734 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.77753\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.3406 - tp: 0.0000e+00 - fp: 1.3333 - tn: 67.6667 - fn: 9.2222 - accuracy: 0.8640 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6468 - f1: 0.0000e+00 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7741 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.77753\n","Epoch 34/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7879 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.2222 - fn: 6.0000 - accuracy: 0.9239 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6563 - f1: 0.0000e+00 - val_loss: 0.3537 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7722 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.77753\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.4352 - tp: 0.5556 - fp: 0.0000e+00 - tn: 67.5556 - fn: 10.1111 - accuracy: 0.8723 - precision: 0.5556 - recall: 0.0394 - auc: 0.6197 - f1: 0.0563 - val_loss: 0.3353 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7707 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.77753\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0102 - tp: 0.6667 - fp: 0.7778 - tn: 67.7778 - fn: 9.0000 - accuracy: 0.8769 - precision: 0.3333 - recall: 0.0529 - auc: 0.8180 - f1: 0.0320 - val_loss: 0.3427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7754 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.77753\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2590 - tp: 0.4444 - fp: 1.3333 - tn: 67.2222 - fn: 9.2222 - accuracy: 0.8830 - precision: 0.0889 - recall: 0.0234 - auc: 0.7422 - f1: 0.0159 - val_loss: 0.3280 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7711 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.77753\n","Restoring model weights from the end of the best epoch.\n","Epoch 00037: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 83%|████████▎ | 20/24 [3:36:50<42:37, 639.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 6.6668 - tp: 1.0000 - fp: 4.0000 - tn: 69.0000 - fn: 4.2222 - accuracy: 0.8577 - precision: 0.2000 - recall: 0.2130 - auc: 0.7116 - f1: 0.0790 - val_loss: 0.3686 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7295 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.72948, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 15.0656 - tp: 2.6667 - fp: 7.2222 - tn: 61.6667 - fn: 6.6667 - accuracy: 0.8350 - precision: 0.2241 - recall: 0.2579 - auc: 0.5267 - f1: 0.2314 - val_loss: 0.3548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7503 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.72948 to 0.75033, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 21.0309 - tp: 1.3333 - fp: 14.3333 - tn: 50.4444 - fn: 12.1111 - accuracy: 0.6502 - precision: 0.0705 - recall: 0.0781 - auc: 0.4206 - f1: 0.0561 - val_loss: 0.3496 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7611 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.75033 to 0.76107, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 3s/step - loss: 10.2630 - tp: 2.0000 - fp: 11.4444 - tn: 59.2222 - fn: 5.5556 - accuracy: 0.7524 - precision: 0.1620 - recall: 0.3242 - auc: 0.5621 - f1: 0.1404 - val_loss: 0.3714 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7650 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.76107 to 0.76496, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 16.4785 - tp: 1.3333 - fp: 7.4444 - tn: 61.0000 - fn: 8.4444 - accuracy: 0.8086 - precision: 0.1200 - recall: 0.1058 - auc: 0.5524 - f1: 0.0821 - val_loss: 0.3534 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7660 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.76496 to 0.76600, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 10.6107 - tp: 1.0000 - fp: 0.0000e+00 - tn: 66.7778 - fn: 10.4444 - accuracy: 0.8687 - precision: 1.0000 - recall: 0.1264 - auc: 0.5549 - f1: 0.1579 - val_loss: 0.3580 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7669 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.76600 to 0.76689, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.9085 - tp: 0.6667 - fp: 11.4444 - tn: 57.5556 - fn: 8.5556 - accuracy: 0.7535 - precision: 0.0444 - recall: 0.0586 - auc: 0.6223 - f1: 0.0320 - val_loss: 0.3617 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7670 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.76689 to 0.76704, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.4788 - tp: 0.0000e+00 - fp: 1.7778 - tn: 69.5556 - fn: 6.8889 - accuracy: 0.8673 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4523 - f1: 0.0000e+00 - val_loss: 0.3626 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7661 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.76704\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.3637 - tp: 0.4444 - fp: 2.4444 - tn: 70.3333 - fn: 5.0000 - accuracy: 0.9195 - precision: 0.0870 - recall: 0.0520 - auc: 0.6862 - f1: 0.0414 - val_loss: 0.3595 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7639 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.76704\n","Epoch 10/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8710 - tp: 0.0000e+00 - fp: 0.5556 - tn: 71.4444 - fn: 6.2222 - accuracy: 0.9306 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5923 - f1: 0.0000e+00 - val_loss: 0.3646 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7661 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.76704\n","Epoch 11/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.7768 - tp: 1.5556 - fp: 7.8889 - tn: 59.3333 - fn: 9.4444 - accuracy: 0.7901 - precision: 0.0931 - recall: 0.1025 - auc: 0.5743 - f1: 0.0910 - val_loss: 0.3659 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7675 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc improved from 0.76704 to 0.76746, saving model to gs://new_cxr_30/models/cxr_model/model-011.h5\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.5547 - tp: 0.2222 - fp: 1.3333 - tn: 68.5556 - fn: 8.1111 - accuracy: 0.8851 - precision: 0.0444 - recall: 0.0171 - auc: 0.5832 - f1: 0.0139 - val_loss: 0.3650 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7710 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.76746 to 0.77095, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.8785 - tp: 1.0000 - fp: 2.3333 - tn: 66.7778 - fn: 8.1111 - accuracy: 0.8698 - precision: 0.4299 - recall: 0.1436 - auc: 0.6679 - f1: 0.1579 - val_loss: 0.3591 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7738 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.77095 to 0.77382, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.9160 - tp: 0.0000e+00 - fp: 2.0000 - tn: 71.6667 - fn: 4.5556 - accuracy: 0.9188 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3105 - f1: 0.0000e+00 - val_loss: 0.3602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7742 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc improved from 0.77382 to 0.77423, saving model to gs://new_cxr_30/models/cxr_model/model-014.h5\n","Epoch 15/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.4767 - tp: 0.6667 - fp: 3.7778 - tn: 69.6667 - fn: 4.1111 - accuracy: 0.8877 - precision: 0.1135 - recall: 0.1185 - auc: 0.5743 - f1: 0.0561 - val_loss: 0.3653 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7703 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.77423\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5306 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5542 - f1: 0.0000e+00 - val_loss: 0.3555 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7708 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.77423\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.0511 - tp: 2.1111 - fp: 10.0000 - tn: 56.8889 - fn: 9.2222 - accuracy: 0.7823 - precision: 0.1892 - recall: 0.1541 - auc: 0.4921 - f1: 0.1064 - val_loss: 0.3587 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7698 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.77423\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.8917 - tp: 0.0000e+00 - fp: 0.2222 - tn: 67.0000 - fn: 11.0000 - accuracy: 0.8583 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5634 - f1: 0.0000e+00 - val_loss: 0.3466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7761 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.77423 to 0.77608, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.9355 - tp: 3.7778 - fp: 5.8889 - tn: 60.5556 - fn: 8.0000 - accuracy: 0.8200 - precision: 0.4607 - recall: 0.3129 - auc: 0.6397 - f1: 0.3105 - val_loss: 0.3622 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7749 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.77608\n","Epoch 20/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.1209 - tp: 0.0000e+00 - fp: 1.0000 - tn: 67.4444 - fn: 9.7778 - accuracy: 0.8645 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6433 - f1: 0.0000e+00 - val_loss: 0.3514 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7797 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.77608 to 0.77970, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.7744 - tp: 0.8889 - fp: 6.6667 - tn: 61.2222 - fn: 9.4444 - accuracy: 0.7851 - precision: 0.0790 - recall: 0.0654 - auc: 0.6038 - f1: 0.0629 - val_loss: 0.3575 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.77970\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.4354 - tp: 0.0000e+00 - fp: 0.3333 - tn: 66.2222 - fn: 11.6667 - accuracy: 0.8394 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6792 - f1: 0.0000e+00 - val_loss: 0.3466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7731 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.77970\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0872 - tp: 1.6667 - fp: 9.0000 - tn: 61.8889 - fn: 5.6667 - accuracy: 0.7796 - precision: 0.1613 - recall: 0.2468 - auc: 0.5313 - f1: 0.2024 - val_loss: 0.3596 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7784 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.77970\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9863 - tp: 0.2222 - fp: 0.0000e+00 - tn: 69.3333 - fn: 8.6667 - accuracy: 0.8849 - precision: 0.2222 - recall: 0.0159 - auc: 0.6383 - f1: 0.0139 - val_loss: 0.3481 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7803 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc improved from 0.77970 to 0.78031, saving model to gs://new_cxr_30/models/cxr_model/model-024.h5\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3241 - tp: 1.6667 - fp: 3.2222 - tn: 66.3333 - fn: 7.0000 - accuracy: 0.8640 - precision: 0.3167 - recall: 0.2198 - auc: 0.7521 - f1: 0.2111 - val_loss: 0.3574 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7790 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.78031\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.5568 - tp: 0.5556 - fp: 2.3333 - tn: 68.8889 - fn: 6.4444 - accuracy: 0.8891 - precision: 0.1296 - recall: 0.0596 - auc: 0.8423 - f1: 0.0563 - val_loss: 0.3577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7804 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc improved from 0.78031 to 0.78035, saving model to gs://new_cxr_30/models/cxr_model/model-026.h5\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 7.5838 - tp: 0.8889 - fp: 4.3333 - tn: 59.2222 - fn: 13.7778 - accuracy: 0.7426 - precision: 0.1136 - recall: 0.0450 - auc: 0.6171 - f1: 0.0622 - val_loss: 0.3466 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7764 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.78035\n","Epoch 28/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.6292 - tp: 0.4444 - fp: 1.6667 - tn: 72.3333 - fn: 3.7778 - accuracy: 0.9413 - precision: 0.1481 - recall: 0.0571 - auc: 0.4260 - f1: 0.0311 - val_loss: 0.3810 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7744 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.78035\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0391 - tp: 0.5556 - fp: 2.1111 - tn: 69.3333 - fn: 6.2222 - accuracy: 0.9093 - precision: 0.1481 - recall: 0.0583 - auc: 0.6417 - f1: 0.0844 - val_loss: 0.3450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7769 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.78035\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2976 - tp: 0.8889 - fp: 4.6667 - tn: 66.4444 - fn: 6.2222 - accuracy: 0.8771 - precision: 0.1898 - recall: 0.1319 - auc: 0.6195 - f1: 0.0819 - val_loss: 0.3552 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7769 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.78035\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.3122 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4756 - f1: 0.0000e+00 - val_loss: 0.3745 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7812 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc improved from 0.78035 to 0.78118, saving model to gs://new_cxr_30/models/cxr_model/model-031.h5\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.3505 - tp: 0.0000e+00 - fp: 0.8889 - tn: 73.0000 - fn: 4.3333 - accuracy: 0.9348 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5423 - f1: 0.0000e+00 - val_loss: 0.3584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7791 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.78118\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.7214 - tp: 0.4444 - fp: 0.8889 - tn: 68.1111 - fn: 8.7778 - accuracy: 0.8714 - precision: 0.2222 - recall: 0.0335 - auc: 0.4796 - f1: 0.0414 - val_loss: 0.3449 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7762 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.78118\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.2951 - tp: 0.0000e+00 - fp: 0.6667 - tn: 71.5556 - fn: 6.0000 - accuracy: 0.9169 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8318 - f1: 0.0000e+00 - val_loss: 0.3499 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7727 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.78118\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.2098 - tp: 0.5556 - fp: 0.3333 - tn: 67.2222 - fn: 10.1111 - accuracy: 0.8696 - precision: 0.3889 - recall: 0.0394 - auc: 0.6491 - f1: 0.0563 - val_loss: 0.3423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7732 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.78118\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3996 - tp: 2.0000 - fp: 3.7778 - tn: 64.7778 - fn: 7.6667 - accuracy: 0.8715 - precision: 0.4069 - recall: 0.3466 - auc: 0.7591 - f1: 0.3159 - val_loss: 0.3510 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7766 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.78118\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1731 - tp: 0.8889 - fp: 1.0000 - tn: 67.5556 - fn: 8.7778 - accuracy: 0.8918 - precision: 0.4037 - recall: 0.0688 - auc: 0.7516 - f1: 0.0640 - val_loss: 0.3269 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7727 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.78118\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.0017 - tp: 1.7778 - fp: 6.5556 - tn: 67.6667 - fn: 2.2222 - accuracy: 0.8655 - precision: 0.1975 - recall: 0.4487 - auc: 0.5986 - f1: 0.0910 - val_loss: 0.4036 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7755 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.78118\n","Epoch 39/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.9624 - tp: 0.0000e+00 - fp: 0.2222 - tn: 69.5556 - fn: 8.4444 - accuracy: 0.8901 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6435 - f1: 0.0000e+00 - val_loss: 0.3290 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7749 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.78118\n","Epoch 40/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.8606 - tp: 3.2222 - fp: 8.5556 - tn: 60.7778 - fn: 5.6667 - accuracy: 0.8204 - precision: 0.2508 - recall: 0.3741 - auc: 0.5868 - f1: 0.2217 - val_loss: 0.3474 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7800 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc did not improve from 0.78118\n","Epoch 41/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3737 - tp: 0.0000e+00 - fp: 1.3333 - tn: 69.2222 - fn: 7.6667 - accuracy: 0.8862 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6734 - f1: 0.0000e+00 - val_loss: 0.3431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7792 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc did not improve from 0.78118\n","Restoring model weights from the end of the best epoch.\n","Epoch 00041: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 88%|████████▊ | 21/24 [3:50:17<34:28, 689.63s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.002, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 32s 3s/step - loss: 6.0646 - tp: 2.0000 - fp: 2.4444 - tn: 70.5556 - fn: 3.2222 - accuracy: 0.9130 - precision: 0.4556 - recall: 0.4259 - auc: 0.7364 - f1: 0.1805 - val_loss: 0.3818 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7400 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.73997, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.1852 - tp: 2.5556 - fp: 7.1111 - tn: 61.7778 - fn: 6.7778 - accuracy: 0.8463 - precision: 0.2872 - recall: 0.4392 - auc: 0.6734 - f1: 0.2418 - val_loss: 0.3602 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7589 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.73997 to 0.75888, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 15.6575 - tp: 1.0000 - fp: 9.1111 - tn: 55.6667 - fn: 12.4444 - accuracy: 0.7242 - precision: 0.1130 - recall: 0.1475 - auc: 0.4415 - f1: 0.0902 - val_loss: 0.3552 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7625 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.75888 to 0.76248, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 8.0157 - tp: 2.8889 - fp: 14.1111 - tn: 56.5556 - fn: 4.6667 - accuracy: 0.7268 - precision: 0.1830 - recall: 0.4492 - auc: 0.6267 - f1: 0.1776 - val_loss: 0.3955 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7522 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc did not improve from 0.76248\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.2074 - tp: 0.2222 - fp: 3.7778 - tn: 64.6667 - fn: 9.5556 - accuracy: 0.8329 - precision: 0.0185 - recall: 0.0159 - auc: 0.5483 - f1: 0.0079 - val_loss: 0.3628 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7645 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.76248 to 0.76448, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 8.5674 - tp: 0.0000e+00 - fp: 5.4444 - tn: 61.3333 - fn: 11.4444 - accuracy: 0.7614 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4896 - f1: 0.0000e+00 - val_loss: 0.3665 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7702 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc improved from 0.76448 to 0.77019, saving model to gs://new_cxr_30/models/cxr_model/model-006.h5\n","Epoch 7/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.7465 - tp: 0.0000e+00 - fp: 5.2222 - tn: 63.7778 - fn: 9.2222 - accuracy: 0.8104 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5977 - f1: 0.0000e+00 - val_loss: 0.3650 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7680 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc did not improve from 0.77019\n","Epoch 8/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.5179 - tp: 0.0000e+00 - fp: 4.6667 - tn: 66.6667 - fn: 6.8889 - accuracy: 0.8346 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4787 - f1: 0.0000e+00 - val_loss: 0.3779 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7646 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.77019\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.7396 - tp: 0.2222 - fp: 0.0000e+00 - tn: 72.7778 - fn: 5.2222 - accuracy: 0.9417 - precision: 0.2222 - recall: 0.0222 - auc: 0.5433 - f1: 0.0185 - val_loss: 0.3584 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7733 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc improved from 0.77019 to 0.77328, saving model to gs://new_cxr_30/models/cxr_model/model-009.h5\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.3891 - tp: 0.5556 - fp: 5.0000 - tn: 67.0000 - fn: 5.6667 - accuracy: 0.8630 - precision: 0.0794 - recall: 0.0591 - auc: 0.5957 - f1: 0.0338 - val_loss: 0.3692 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7675 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc did not improve from 0.77328\n","Epoch 11/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.3982 - tp: 2.3333 - fp: 2.1111 - tn: 65.1111 - fn: 8.6667 - accuracy: 0.8617 - precision: 0.6278 - recall: 0.1807 - auc: 0.6514 - f1: 0.1600 - val_loss: 0.3651 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7697 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.77328\n","Epoch 12/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3596 - tp: 1.4444 - fp: 1.0000 - tn: 68.8889 - fn: 6.8889 - accuracy: 0.9045 - precision: 0.7037 - recall: 0.1615 - auc: 0.7070 - f1: 0.1586 - val_loss: 0.3743 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7700 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc did not improve from 0.77328\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.1804 - tp: 0.0000e+00 - fp: 2.0000 - tn: 67.1111 - fn: 9.1111 - accuracy: 0.8510 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5837 - f1: 0.0000e+00 - val_loss: 0.3608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7676 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc did not improve from 0.77328\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.9106 - tp: 0.0000e+00 - fp: 4.3333 - tn: 69.3333 - fn: 4.5556 - accuracy: 0.8943 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3136 - f1: 0.0000e+00 - val_loss: 0.3717 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7689 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.77328\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.5806 - tp: 0.0000e+00 - fp: 0.8889 - tn: 72.5556 - fn: 4.7778 - accuracy: 0.9188 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7376 - f1: 0.0000e+00 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7702 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.77328\n","Epoch 16/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.1566 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6605 - f1: 0.0000e+00 - val_loss: 0.3595 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7742 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc improved from 0.77328 to 0.77417, saving model to gs://new_cxr_30/models/cxr_model/model-016.h5\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 6.2530 - tp: 2.1111 - fp: 9.3333 - tn: 57.5556 - fn: 9.2222 - accuracy: 0.7715 - precision: 0.1787 - recall: 0.1541 - auc: 0.4911 - f1: 0.1190 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7699 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.77417\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.5770 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.2222 - fn: 11.0000 - accuracy: 0.8601 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6108 - f1: 0.0000e+00 - val_loss: 0.3614 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7750 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc improved from 0.77417 to 0.77499, saving model to gs://new_cxr_30/models/cxr_model/model-018.h5\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.3293 - tp: 1.3333 - fp: 8.3333 - tn: 58.1111 - fn: 10.4444 - accuracy: 0.7584 - precision: 0.1144 - recall: 0.0960 - auc: 0.6452 - f1: 0.0637 - val_loss: 0.3592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7767 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc improved from 0.77499 to 0.77671, saving model to gs://new_cxr_30/models/cxr_model/model-019.h5\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.5693 - tp: 0.0000e+00 - fp: 1.3333 - tn: 67.1111 - fn: 9.7778 - accuracy: 0.8504 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6653 - f1: 0.0000e+00 - val_loss: 0.3581 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7768 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.77671 to 0.77682, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.2552 - tp: 2.4444 - fp: 5.8889 - tn: 62.0000 - fn: 7.8889 - accuracy: 0.8243 - precision: 0.2315 - recall: 0.1933 - auc: 0.6042 - f1: 0.1619 - val_loss: 0.3720 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7769 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc improved from 0.77682 to 0.77690, saving model to gs://new_cxr_30/models/cxr_model/model-021.h5\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.8496 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 66.5556 - fn: 11.6667 - accuracy: 0.8421 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6450 - f1: 0.0000e+00 - val_loss: 0.3446 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7774 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.77690 to 0.77738, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6474 - tp: 2.4444 - fp: 10.7778 - tn: 60.1111 - fn: 4.8889 - accuracy: 0.7789 - precision: 0.1952 - recall: 0.3489 - auc: 0.6940 - f1: 0.2548 - val_loss: 0.3705 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7757 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.77738\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0315 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.3333 - fn: 8.8889 - accuracy: 0.8832 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5622 - f1: 0.0000e+00 - val_loss: 0.3551 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.77738\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8425 - tp: 0.6667 - fp: 5.4444 - tn: 64.1111 - fn: 8.0000 - accuracy: 0.8384 - precision: 0.0853 - recall: 0.0599 - auc: 0.6642 - f1: 0.0449 - val_loss: 0.3557 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7802 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc improved from 0.77738 to 0.78020, saving model to gs://new_cxr_30/models/cxr_model/model-025.h5\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7998 - tp: 0.0000e+00 - fp: 1.4444 - tn: 69.7778 - fn: 7.0000 - accuracy: 0.8830 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7715 - f1: 0.0000e+00 - val_loss: 0.3604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7792 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.78020\n","Epoch 27/500\n","8/8 [==============================] - 20s 3s/step - loss: 7.5447 - tp: 1.8889 - fp: 4.5556 - tn: 59.0000 - fn: 12.7778 - accuracy: 0.7569 - precision: 0.2753 - recall: 0.1151 - auc: 0.5512 - f1: 0.2117 - val_loss: 0.3488 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7789 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.78020\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7658 - tp: 0.0000e+00 - fp: 4.2222 - tn: 69.7778 - fn: 4.2222 - accuracy: 0.8979 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4631 - f1: 0.0000e+00 - val_loss: 0.3800 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7747 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.78020\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.3098 - tp: 0.0000e+00 - fp: 1.2222 - tn: 70.2222 - fn: 6.7778 - accuracy: 0.9126 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5802 - f1: 0.0000e+00 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7736 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.78020\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9987 - tp: 0.0000e+00 - fp: 5.6667 - tn: 65.4444 - fn: 7.1111 - accuracy: 0.8295 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5506 - f1: 0.0000e+00 - val_loss: 0.3592 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.78020\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.7224 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5172 - f1: 0.0000e+00 - val_loss: 0.3662 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7755 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.78020\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.4128 - tp: 0.0000e+00 - fp: 0.7778 - tn: 73.1111 - fn: 4.3333 - accuracy: 0.9406 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5670 - f1: 0.0000e+00 - val_loss: 0.3513 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7780 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.78020\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.1682 - tp: 0.2222 - fp: 0.0000e+00 - tn: 69.0000 - fn: 9.0000 - accuracy: 0.8820 - precision: 0.2222 - recall: 0.0148 - auc: 0.6280 - f1: 0.0185 - val_loss: 0.3411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7753 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.78020\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0363 - tp: 0.0000e+00 - fp: 1.5556 - tn: 70.6667 - fn: 6.0000 - accuracy: 0.9052 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6687 - f1: 0.0000e+00 - val_loss: 0.3571 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7755 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.78020\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9348 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.5556 - fn: 10.6667 - accuracy: 0.8671 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7567 - f1: 0.0000e+00 - val_loss: 0.3336 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7746 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.78020\n","Restoring model weights from the end of the best epoch.\n","Epoch 00035: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 92%|█████████▏| 22/24 [4:01:36<22:53, 686.62s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -2, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 23.2353 - tp: 0.7778 - fp: 18.1111 - tn: 54.8889 - fn: 4.4444 - accuracy: 0.6749 - precision: 0.0354 - recall: 0.1389 - auc: 0.4431 - f1: 0.0373 - val_loss: 0.4583 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6669 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.66688, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 20.2303 - tp: 1.4444 - fp: 5.5556 - tn: 63.3333 - fn: 7.8889 - accuracy: 0.8648 - precision: 0.0933 - recall: 0.0856 - auc: 0.5170 - f1: 0.0376 - val_loss: 0.3783 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4090 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc did not improve from 0.66688\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 20.8894 - tp: 1.2222 - fp: 6.5556 - tn: 58.2222 - fn: 12.2222 - accuracy: 0.7579 - precision: 0.1383 - recall: 0.0680 - auc: 0.4281 - f1: 0.0786 - val_loss: 0.3705 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7577 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.66688 to 0.75769, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 10.7708 - tp: 0.8889 - fp: 10.2222 - tn: 60.4444 - fn: 6.6667 - accuracy: 0.7270 - precision: 0.0758 - recall: 0.1250 - auc: 0.3513 - f1: 0.0585 - val_loss: 0.3758 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7714 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc improved from 0.75769 to 0.77143, saving model to gs://new_cxr_30/models/cxr_model/model-004.h5\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 9.7748 - tp: 0.0000e+00 - fp: 8.4444 - tn: 60.0000 - fn: 9.7778 - accuracy: 0.7867 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4557 - f1: 0.0000e+00 - val_loss: 0.3695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7594 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc did not improve from 0.77143\n","Epoch 6/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.2680 - tp: 0.0000e+00 - fp: 0.8889 - tn: 65.8889 - fn: 11.4444 - accuracy: 0.8361 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5963 - f1: 0.0000e+00 - val_loss: 0.3670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7710 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.77143\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.5938 - tp: 1.6667 - fp: 11.2222 - tn: 57.7778 - fn: 7.5556 - accuracy: 0.7554 - precision: 0.1408 - recall: 0.2319 - auc: 0.5853 - f1: 0.1373 - val_loss: 0.3701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7724 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.77143 to 0.77243, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.4812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.3333 - fn: 6.8889 - accuracy: 0.8963 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3553 - f1: 0.0000e+00 - val_loss: 0.3667 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7703 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.77243\n","Epoch 9/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.0169 - tp: 0.0000e+00 - fp: 3.2222 - tn: 69.5556 - fn: 5.4444 - accuracy: 0.8946 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4409 - f1: 0.0000e+00 - val_loss: 0.3661 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7669 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.77243\n","Epoch 10/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.5186 - tp: 0.0000e+00 - fp: 1.0000 - tn: 71.0000 - fn: 6.2222 - accuracy: 0.9153 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5829 - f1: 0.0000e+00 - val_loss: 0.3627 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7736 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.77243 to 0.77356, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.4125 - tp: 1.4444 - fp: 6.6667 - tn: 60.5556 - fn: 9.5556 - accuracy: 0.8005 - precision: 0.2531 - recall: 0.1208 - auc: 0.4499 - f1: 0.1100 - val_loss: 0.3696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7716 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.77356\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9017 - tp: 0.0000e+00 - fp: 1.6667 - tn: 68.2222 - fn: 8.3333 - accuracy: 0.8809 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5160 - f1: 0.0000e+00 - val_loss: 0.3648 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7762 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.77356 to 0.77619, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.7924 - tp: 0.0000e+00 - fp: 2.8889 - tn: 66.2222 - fn: 9.1111 - accuracy: 0.8265 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6414 - f1: 0.0000e+00 - val_loss: 0.3658 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7844 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.77619 to 0.78439, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.1972 - tp: 0.0000e+00 - fp: 1.5556 - tn: 72.1111 - fn: 4.5556 - accuracy: 0.9396 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3720 - f1: 0.0000e+00 - val_loss: 0.3625 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7804 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.78439\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 2.7479 - tp: 0.0000e+00 - fp: 2.2222 - tn: 71.2222 - fn: 4.7778 - accuracy: 0.9007 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7596 - f1: 0.0000e+00 - val_loss: 0.3696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7754 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.78439\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.1687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5396 - f1: 0.0000e+00 - val_loss: 0.3619 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7798 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.78439\n","Epoch 17/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.7329 - tp: 2.1111 - fp: 6.7778 - tn: 60.1111 - fn: 9.2222 - accuracy: 0.8079 - precision: 0.2349 - recall: 0.1541 - auc: 0.4246 - f1: 0.1190 - val_loss: 0.3608 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7799 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc did not improve from 0.78439\n","Epoch 18/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6466 - tp: 1.0000 - fp: 0.0000e+00 - tn: 67.2222 - fn: 10.0000 - accuracy: 0.8798 - precision: 1.0000 - recall: 0.1449 - auc: 0.6065 - f1: 0.2106 - val_loss: 0.3616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7785 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.78439\n","Epoch 19/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.1285 - tp: 1.0000 - fp: 7.0000 - tn: 59.4444 - fn: 10.7778 - accuracy: 0.7684 - precision: 0.0797 - recall: 0.0633 - auc: 0.6007 - f1: 0.0489 - val_loss: 0.3573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7789 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.78439\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6774 - tp: 0.0000e+00 - fp: 1.0000 - tn: 67.4444 - fn: 9.7778 - accuracy: 0.8531 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7145 - f1: 0.0000e+00 - val_loss: 0.3593 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7888 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.78439 to 0.78884, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.4613 - tp: 1.3333 - fp: 2.0000 - tn: 65.8889 - fn: 9.0000 - accuracy: 0.8473 - precision: 0.3815 - recall: 0.1175 - auc: 0.5991 - f1: 0.1234 - val_loss: 0.3566 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7853 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.78884\n","Epoch 22/500\n","8/8 [==============================] - 19s 3s/step - loss: 5.0977 - tp: 0.0000e+00 - fp: 0.7778 - tn: 65.7778 - fn: 11.6667 - accuracy: 0.8351 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6241 - f1: 0.0000e+00 - val_loss: 0.3521 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7867 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc did not improve from 0.78884\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.9288 - tp: 1.6667 - fp: 2.8889 - tn: 68.0000 - fn: 5.6667 - accuracy: 0.8871 - precision: 0.4333 - recall: 0.2468 - auc: 0.5648 - f1: 0.2327 - val_loss: 0.3632 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7833 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.78884\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.2035 - tp: 0.2222 - fp: 0.3333 - tn: 69.0000 - fn: 8.6667 - accuracy: 0.8822 - precision: 0.1111 - recall: 0.0159 - auc: 0.6098 - f1: 0.0139 - val_loss: 0.3533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7886 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.78884\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.0828 - tp: 0.0000e+00 - fp: 1.8889 - tn: 67.6667 - fn: 8.6667 - accuracy: 0.8644 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6239 - f1: 0.0000e+00 - val_loss: 0.3583 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7833 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.78884\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.0077 - tp: 0.5556 - fp: 2.7778 - tn: 68.4444 - fn: 6.4444 - accuracy: 0.8840 - precision: 0.1000 - recall: 0.0596 - auc: 0.7201 - f1: 0.0338 - val_loss: 0.3604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7816 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.78884\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.7067 - tp: 1.4444 - fp: 1.3333 - tn: 62.2222 - fn: 13.2222 - accuracy: 0.7947 - precision: 0.3452 - recall: 0.0741 - auc: 0.5768 - f1: 0.0835 - val_loss: 0.3515 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7873 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.78884\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.1582 - tp: 0.0000e+00 - fp: 0.8889 - tn: 73.1111 - fn: 4.2222 - accuracy: 0.9467 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4436 - f1: 0.0000e+00 - val_loss: 0.3684 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7859 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.78884\n","Epoch 29/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.8373 - tp: 0.0000e+00 - fp: 0.5556 - tn: 70.8889 - fn: 6.7778 - accuracy: 0.9178 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5774 - f1: 0.0000e+00 - val_loss: 0.3486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7882 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc did not improve from 0.78884\n","Epoch 30/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.7720 - tp: 0.0000e+00 - fp: 1.5556 - tn: 69.5556 - fn: 7.1111 - accuracy: 0.8995 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6521 - f1: 0.0000e+00 - val_loss: 0.3604 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7896 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc improved from 0.78884 to 0.78956, saving model to gs://new_cxr_30/models/cxr_model/model-030.h5\n","Epoch 31/500\n","8/8 [==============================] - 20s 3s/step - loss: 1.8699 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4723 - f1: 0.0000e+00 - val_loss: 0.3670 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7882 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.78956\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.3856 - tp: 0.0000e+00 - fp: 0.2222 - tn: 73.6667 - fn: 4.3333 - accuracy: 0.9458 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4359 - f1: 0.0000e+00 - val_loss: 0.3504 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7888 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.78956\n","Epoch 33/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.3305 - tp: 0.0000e+00 - fp: 0.6667 - tn: 68.3333 - fn: 9.2222 - accuracy: 0.8733 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5467 - f1: 0.0000e+00 - val_loss: 0.3530 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7906 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc improved from 0.78956 to 0.79060, saving model to gs://new_cxr_30/models/cxr_model/model-033.h5\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.2739 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 72.2222 - fn: 6.0000 - accuracy: 0.9239 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.8307 - f1: 0.0000e+00 - val_loss: 0.3542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7895 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.79060\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7231 - tp: 0.0000e+00 - fp: 0.6667 - tn: 66.8889 - fn: 10.6667 - accuracy: 0.8601 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7635 - f1: 0.0000e+00 - val_loss: 0.3473 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7877 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.79060\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.1557 - tp: 0.8889 - fp: 0.8889 - tn: 67.6667 - fn: 8.7778 - accuracy: 0.8752 - precision: 0.3704 - recall: 0.0668 - auc: 0.7906 - f1: 0.0459 - val_loss: 0.3478 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7889 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc did not improve from 0.79060\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0862 - tp: 0.5556 - fp: 1.7778 - tn: 66.7778 - fn: 9.1111 - accuracy: 0.8809 - precision: 0.0857 - recall: 0.0313 - auc: 0.7925 - f1: 0.0254 - val_loss: 0.3337 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7857 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.79060\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.9991 - tp: 0.8889 - fp: 7.1111 - tn: 67.1111 - fn: 3.1111 - accuracy: 0.8446 - precision: 0.1058 - recall: 0.2243 - auc: 0.6946 - f1: 0.0683 - val_loss: 0.4123 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7855 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.79060\n","Epoch 39/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.4225 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.7778 - fn: 8.4444 - accuracy: 0.8918 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7111 - f1: 0.0000e+00 - val_loss: 0.3450 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7853 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.79060\n","Epoch 40/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.1414 - tp: 2.3333 - fp: 5.3333 - tn: 64.0000 - fn: 6.5556 - accuracy: 0.8626 - precision: 0.3041 - recall: 0.2796 - auc: 0.6027 - f1: 0.2060 - val_loss: 0.3542 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7850 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc did not improve from 0.79060\n","Epoch 41/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0558 - tp: 0.0000e+00 - fp: 0.4444 - tn: 70.1111 - fn: 7.6667 - accuracy: 0.9048 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7452 - f1: 0.0000e+00 - val_loss: 0.3545 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7832 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc did not improve from 0.79060\n","Epoch 42/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.5336 - tp: 0.8889 - fp: 4.2222 - tn: 64.4444 - fn: 8.6667 - accuracy: 0.8539 - precision: 0.1048 - recall: 0.0652 - auc: 0.6260 - f1: 0.0781 - val_loss: 0.3504 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7845 - val_f1: 0.0000e+00\n","\n","Epoch 00042: val_auc did not improve from 0.79060\n","Epoch 43/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.6323 - tp: 0.0000e+00 - fp: 1.0000 - tn: 66.2222 - fn: 11.0000 - accuracy: 0.8376 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6040 - f1: 0.0000e+00 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7818 - val_f1: 0.0000e+00\n","\n","Epoch 00043: val_auc did not improve from 0.79060\n","Restoring model weights from the end of the best epoch.\n","Epoch 00043: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["\r 96%|█████████▌| 23/24 [4:15:40<12:13, 733.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["{'augment_bbox': 'B', 'batch_size': 16, 'class_weight': {0: 10, 1: 10}, 'cxr_hidden_dims': [128, 64], 'dropout': 0.5, 'epochs': 50, 'k-fold': 3, 'layers_not_trainable': 400, 'loss_function': 'binary_crossentropy', 'lr_init': 0.003, 'model_teacher': 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5', 'model_type': 'cxr_model', 'output_bias': array([-2.07156032]), 'pretrained_feature_layer': -4, 'tab_out_dim': 1}\n","With a batch size of 16, there will be 87 batches per training epoch and 28 batch(es) per validation run.\n","Epoch 1/500\n","8/8 [==============================] - 31s 3s/step - loss: 12.8490 - tp: 1.0000 - fp: 9.0000 - tn: 64.0000 - fn: 4.2222 - accuracy: 0.7590 - precision: 0.1000 - recall: 0.2130 - auc: 0.6130 - f1: 0.0486 - val_loss: 0.4218 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7161 - val_f1: 0.0000e+00\n","\n","Epoch 00001: val_auc improved from -inf to 0.71608, saving model to gs://new_cxr_30/models/cxr_model/model-001.h5\n","Epoch 2/500\n","8/8 [==============================] - 18s 2s/step - loss: 23.5756 - tp: 1.4444 - fp: 8.6667 - tn: 60.2222 - fn: 7.8889 - accuracy: 0.7986 - precision: 0.1217 - recall: 0.1567 - auc: 0.4806 - f1: 0.1158 - val_loss: 0.3613 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7386 - val_f1: 0.0000e+00\n","\n","Epoch 00002: val_auc improved from 0.71608 to 0.73856, saving model to gs://new_cxr_30/models/cxr_model/model-002.h5\n","Epoch 3/500\n","8/8 [==============================] - 18s 2s/step - loss: 32.5210 - tp: 2.2222 - fp: 15.6667 - tn: 49.1111 - fn: 11.2222 - accuracy: 0.6189 - precision: 0.1273 - recall: 0.3052 - auc: 0.4603 - f1: 0.1164 - val_loss: 0.3505 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7629 - val_f1: 0.0000e+00\n","\n","Epoch 00003: val_auc improved from 0.73856 to 0.76294, saving model to gs://new_cxr_30/models/cxr_model/model-003.h5\n","Epoch 4/500\n","8/8 [==============================] - 18s 2s/step - loss: 13.1948 - tp: 3.8889 - fp: 15.0000 - tn: 55.6667 - fn: 3.6667 - accuracy: 0.7458 - precision: 0.2291 - recall: 0.6113 - auc: 0.6385 - f1: 0.2480 - val_loss: 0.4023 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7601 - val_f1: 0.0000e+00\n","\n","Epoch 00004: val_auc did not improve from 0.76294\n","Epoch 5/500\n","8/8 [==============================] - 18s 2s/step - loss: 23.1257 - tp: 0.2222 - fp: 4.0000 - tn: 64.4444 - fn: 9.5556 - accuracy: 0.8337 - precision: 0.0148 - recall: 0.0159 - auc: 0.5628 - f1: 0.0069 - val_loss: 0.3561 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7690 - val_f1: 0.0000e+00\n","\n","Epoch 00005: val_auc improved from 0.76294 to 0.76896, saving model to gs://new_cxr_30/models/cxr_model/model-005.h5\n","Epoch 6/500\n","8/8 [==============================] - 18s 3s/step - loss: 10.3102 - tp: 1.0000 - fp: 5.4444 - tn: 61.3333 - fn: 10.4444 - accuracy: 0.7803 - precision: 0.1624 - recall: 0.1264 - auc: 0.5817 - f1: 0.0902 - val_loss: 0.3598 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7671 - val_f1: 0.0000e+00\n","\n","Epoch 00006: val_auc did not improve from 0.76896\n","Epoch 7/500\n","8/8 [==============================] - 18s 2s/step - loss: 7.7491 - tp: 1.8889 - fp: 8.4444 - tn: 60.5556 - fn: 7.3333 - accuracy: 0.7968 - precision: 0.1557 - recall: 0.1838 - auc: 0.4836 - f1: 0.1339 - val_loss: 0.3579 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7712 - val_f1: 0.0000e+00\n","\n","Epoch 00007: val_auc improved from 0.76896 to 0.77121, saving model to gs://new_cxr_30/models/cxr_model/model-007.h5\n","Epoch 8/500\n","8/8 [==============================] - 18s 2s/step - loss: 4.9004 - tp: 0.8889 - fp: 5.0000 - tn: 66.3333 - fn: 6.0000 - accuracy: 0.8370 - precision: 0.1397 - recall: 0.1314 - auc: 0.5772 - f1: 0.0683 - val_loss: 0.3665 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7704 - val_f1: 0.0000e+00\n","\n","Epoch 00008: val_auc did not improve from 0.77121\n","Epoch 9/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.4401 - tp: 0.5556 - fp: 0.8889 - tn: 71.8889 - fn: 4.8889 - accuracy: 0.9364 - precision: 0.1481 - recall: 0.0583 - auc: 0.5912 - f1: 0.0476 - val_loss: 0.3564 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7707 - val_f1: 0.0000e+00\n","\n","Epoch 00009: val_auc did not improve from 0.77121\n","Epoch 10/500\n","8/8 [==============================] - 18s 2s/step - loss: 3.9895 - tp: 0.0000e+00 - fp: 4.1111 - tn: 67.8889 - fn: 6.2222 - accuracy: 0.8613 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4494 - f1: 0.0000e+00 - val_loss: 0.3582 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7727 - val_f1: 0.0000e+00\n","\n","Epoch 00010: val_auc improved from 0.77121 to 0.77273, saving model to gs://new_cxr_30/models/cxr_model/model-010.h5\n","Epoch 11/500\n","8/8 [==============================] - 18s 2s/step - loss: 6.0061 - tp: 2.6667 - fp: 9.6667 - tn: 57.5556 - fn: 8.3333 - accuracy: 0.7661 - precision: 0.2128 - recall: 0.2139 - auc: 0.6123 - f1: 0.2219 - val_loss: 0.3699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7686 - val_f1: 0.0000e+00\n","\n","Epoch 00011: val_auc did not improve from 0.77273\n","Epoch 12/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.2715 - tp: 0.0000e+00 - fp: 0.3333 - tn: 69.5556 - fn: 8.3333 - accuracy: 0.8917 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6555 - f1: 0.0000e+00 - val_loss: 0.3621 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7743 - val_f1: 0.0000e+00\n","\n","Epoch 00012: val_auc improved from 0.77273 to 0.77434, saving model to gs://new_cxr_30/models/cxr_model/model-012.h5\n","Epoch 13/500\n","8/8 [==============================] - 18s 2s/step - loss: 5.5408 - tp: 1.3333 - fp: 5.3333 - tn: 63.7778 - fn: 7.7778 - accuracy: 0.8296 - precision: 0.2424 - recall: 0.1670 - auc: 0.5253 - f1: 0.1554 - val_loss: 0.3616 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7769 - val_f1: 0.0000e+00\n","\n","Epoch 00013: val_auc improved from 0.77434 to 0.77695, saving model to gs://new_cxr_30/models/cxr_model/model-013.h5\n","Epoch 14/500\n","8/8 [==============================] - 18s 2s/step - loss: 2.8304 - tp: 0.0000e+00 - fp: 1.0000 - tn: 72.6667 - fn: 4.5556 - accuracy: 0.9385 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3557 - f1: 0.0000e+00 - val_loss: 0.3643 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7703 - val_f1: 0.0000e+00\n","\n","Epoch 00014: val_auc did not improve from 0.77695\n","Epoch 15/500\n","8/8 [==============================] - 18s 3s/step - loss: 3.3360 - tp: 0.0000e+00 - fp: 4.1111 - tn: 69.3333 - fn: 4.7778 - accuracy: 0.8770 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6198 - f1: 0.0000e+00 - val_loss: 0.3642 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7719 - val_f1: 0.0000e+00\n","\n","Epoch 00015: val_auc did not improve from 0.77695\n","Epoch 16/500\n","8/8 [==============================] - 18s 3s/step - loss: 4.6984 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 70.8889 - fn: 7.3333 - accuracy: 0.9068 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4862 - f1: 0.0000e+00 - val_loss: 0.3589 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7737 - val_f1: 0.0000e+00\n","\n","Epoch 00016: val_auc did not improve from 0.77695\n","Epoch 17/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.2437 - tp: 2.0000 - fp: 10.8889 - tn: 56.0000 - fn: 9.3333 - accuracy: 0.7789 - precision: 0.2344 - recall: 0.1418 - auc: 0.6048 - f1: 0.0971 - val_loss: 0.3599 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7787 - val_f1: 0.0000e+00\n","\n","Epoch 00017: val_auc improved from 0.77695 to 0.77873, saving model to gs://new_cxr_30/models/cxr_model/model-017.h5\n","Epoch 18/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.6328 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 67.2222 - fn: 11.0000 - accuracy: 0.8601 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6313 - f1: 0.0000e+00 - val_loss: 0.3554 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7770 - val_f1: 0.0000e+00\n","\n","Epoch 00018: val_auc did not improve from 0.77873\n","Epoch 19/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.0963 - tp: 2.6667 - fp: 9.7778 - tn: 56.6667 - fn: 9.1111 - accuracy: 0.7673 - precision: 0.3117 - recall: 0.2204 - auc: 0.7000 - f1: 0.2004 - val_loss: 0.3552 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7762 - val_f1: 0.0000e+00\n","\n","Epoch 00019: val_auc did not improve from 0.77873\n","Epoch 20/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6189 - tp: 0.4444 - fp: 1.0000 - tn: 67.4444 - fn: 9.3333 - accuracy: 0.8672 - precision: 0.1111 - recall: 0.0296 - auc: 0.7540 - f1: 0.0278 - val_loss: 0.3532 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7800 - val_f1: 0.0000e+00\n","\n","Epoch 00020: val_auc improved from 0.77873 to 0.77999, saving model to gs://new_cxr_30/models/cxr_model/model-020.h5\n","Epoch 21/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.1599 - tp: 1.5556 - fp: 2.8889 - tn: 65.0000 - fn: 8.7778 - accuracy: 0.8270 - precision: 0.3222 - recall: 0.1379 - auc: 0.5547 - f1: 0.1430 - val_loss: 0.3569 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7792 - val_f1: 0.0000e+00\n","\n","Epoch 00021: val_auc did not improve from 0.77999\n","Epoch 22/500\n","8/8 [==============================] - 18s 3s/step - loss: 5.4598 - tp: 0.0000e+00 - fp: 0.4444 - tn: 66.1111 - fn: 11.6667 - accuracy: 0.8382 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6249 - f1: 0.0000e+00 - val_loss: 0.3486 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7827 - val_f1: 0.0000e+00\n","\n","Epoch 00022: val_auc improved from 0.77999 to 0.78272, saving model to gs://new_cxr_30/models/cxr_model/model-022.h5\n","Epoch 23/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.7245 - tp: 1.6667 - fp: 6.6667 - tn: 64.2222 - fn: 5.6667 - accuracy: 0.8449 - precision: 0.2944 - recall: 0.2468 - auc: 0.6707 - f1: 0.2140 - val_loss: 0.3573 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7820 - val_f1: 0.0000e+00\n","\n","Epoch 00023: val_auc did not improve from 0.78272\n","Epoch 24/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.8019 - tp: 0.2222 - fp: 0.0000e+00 - tn: 69.3333 - fn: 8.6667 - accuracy: 0.8849 - precision: 0.2222 - recall: 0.0159 - auc: 0.6400 - f1: 0.0139 - val_loss: 0.3533 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7822 - val_f1: 0.0000e+00\n","\n","Epoch 00024: val_auc did not improve from 0.78272\n","Epoch 25/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.6882 - tp: 1.6667 - fp: 3.4444 - tn: 66.1111 - fn: 7.0000 - accuracy: 0.8717 - precision: 0.3085 - recall: 0.2198 - auc: 0.6723 - f1: 0.2111 - val_loss: 0.3568 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7821 - val_f1: 0.0000e+00\n","\n","Epoch 00025: val_auc did not improve from 0.78272\n","Epoch 26/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.8037 - tp: 0.6667 - fp: 0.2222 - tn: 71.0000 - fn: 6.3333 - accuracy: 0.9119 - precision: 0.5556 - recall: 0.0754 - auc: 0.7353 - f1: 0.0748 - val_loss: 0.3549 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7816 - val_f1: 0.0000e+00\n","\n","Epoch 00026: val_auc did not improve from 0.78272\n","Epoch 27/500\n","8/8 [==============================] - 19s 3s/step - loss: 6.3093 - tp: 2.0000 - fp: 3.0000 - tn: 60.5556 - fn: 12.6667 - accuracy: 0.7838 - precision: 0.4405 - recall: 0.1374 - auc: 0.6239 - f1: 0.1749 - val_loss: 0.3474 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7823 - val_f1: 0.0000e+00\n","\n","Epoch 00027: val_auc did not improve from 0.78272\n","Epoch 28/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.5259 - tp: 0.0000e+00 - fp: 1.0000 - tn: 73.0000 - fn: 4.2222 - accuracy: 0.9398 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3724 - f1: 0.0000e+00 - val_loss: 0.3709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7798 - val_f1: 0.0000e+00\n","\n","Epoch 00028: val_auc did not improve from 0.78272\n","Epoch 29/500\n","8/8 [==============================] - 19s 3s/step - loss: 2.7938 - tp: 0.4444 - fp: 0.4444 - tn: 71.0000 - fn: 6.3333 - accuracy: 0.9231 - precision: 0.2222 - recall: 0.0424 - auc: 0.6350 - f1: 0.0249 - val_loss: 0.3467 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7837 - val_f1: 0.0000e+00\n","\n","Epoch 00029: val_auc improved from 0.78272 to 0.78370, saving model to gs://new_cxr_30/models/cxr_model/model-029.h5\n","Epoch 30/500\n","8/8 [==============================] - 19s 3s/step - loss: 3.1458 - tp: 0.8889 - fp: 2.7778 - tn: 68.3333 - fn: 6.2222 - accuracy: 0.8820 - precision: 0.2222 - recall: 0.1319 - auc: 0.6139 - f1: 0.0683 - val_loss: 0.3577 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7822 - val_f1: 0.0000e+00\n","\n","Epoch 00030: val_auc did not improve from 0.78370\n","Epoch 31/500\n","8/8 [==============================] - 19s 3s/step - loss: 1.8975 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 74.4444 - fn: 3.7778 - accuracy: 0.9607 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4679 - f1: 0.0000e+00 - val_loss: 0.3703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7805 - val_f1: 0.0000e+00\n","\n","Epoch 00031: val_auc did not improve from 0.78370\n","Epoch 32/500\n","8/8 [==============================] - 20s 3s/step - loss: 2.2494 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 73.8889 - fn: 4.3333 - accuracy: 0.9476 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5577 - f1: 0.0000e+00 - val_loss: 0.3535 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7819 - val_f1: 0.0000e+00\n","\n","Epoch 00032: val_auc did not improve from 0.78370\n","Epoch 33/500\n","8/8 [==============================] - 19s 3s/step - loss: 4.6448 - tp: 0.3333 - fp: 0.3333 - tn: 68.6667 - fn: 8.8889 - accuracy: 0.8803 - precision: 0.1667 - recall: 0.0234 - auc: 0.4976 - f1: 0.0218 - val_loss: 0.3477 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7815 - val_f1: 0.0000e+00\n","\n","Epoch 00033: val_auc did not improve from 0.78370\n","Epoch 34/500\n","8/8 [==============================] - 20s 3s/step - loss: 1.9598 - tp: 0.7778 - fp: 1.2222 - tn: 71.0000 - fn: 5.2222 - accuracy: 0.9200 - precision: 0.3148 - recall: 0.1146 - auc: 0.9100 - f1: 0.0746 - val_loss: 0.3656 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7791 - val_f1: 0.0000e+00\n","\n","Epoch 00034: val_auc did not improve from 0.78370\n","Epoch 35/500\n","8/8 [==============================] - 20s 3s/step - loss: 4.3988 - tp: 0.5556 - fp: 0.3333 - tn: 67.2222 - fn: 10.1111 - accuracy: 0.8696 - precision: 0.3889 - recall: 0.0394 - auc: 0.7125 - f1: 0.0563 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7799 - val_f1: 0.0000e+00\n","\n","Epoch 00035: val_auc did not improve from 0.78370\n","Epoch 36/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6268 - tp: 0.6667 - fp: 4.3333 - tn: 64.2222 - fn: 9.0000 - accuracy: 0.8317 - precision: 0.1042 - recall: 0.0529 - auc: 0.7085 - f1: 0.0280 - val_loss: 0.3548 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7842 - val_f1: 0.0000e+00\n","\n","Epoch 00036: val_auc improved from 0.78370 to 0.78415, saving model to gs://new_cxr_30/models/cxr_model/model-036.h5\n","Epoch 37/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.6556 - tp: 0.4444 - fp: 0.5556 - tn: 68.0000 - fn: 9.2222 - accuracy: 0.8904 - precision: 0.1111 - recall: 0.0234 - auc: 0.6714 - f1: 0.0139 - val_loss: 0.3290 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7816 - val_f1: 0.0000e+00\n","\n","Epoch 00037: val_auc did not improve from 0.78415\n","Epoch 38/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.0936 - tp: 0.8889 - fp: 4.2222 - tn: 70.0000 - fn: 3.1111 - accuracy: 0.8969 - precision: 0.1667 - recall: 0.2243 - auc: 0.5819 - f1: 0.0819 - val_loss: 0.3716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7838 - val_f1: 0.0000e+00\n","\n","Epoch 00038: val_auc did not improve from 0.78415\n","Epoch 39/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.9473 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 69.7778 - fn: 8.4444 - accuracy: 0.8918 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6667 - f1: 0.0000e+00 - val_loss: 0.3413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7823 - val_f1: 0.0000e+00\n","\n","Epoch 00039: val_auc did not improve from 0.78415\n","Epoch 40/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.5167 - tp: 1.3333 - fp: 4.4444 - tn: 64.8889 - fn: 7.5556 - accuracy: 0.8578 - precision: 0.2095 - recall: 0.1250 - auc: 0.6335 - f1: 0.1332 - val_loss: 0.3417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7847 - val_f1: 0.0000e+00\n","\n","Epoch 00040: val_auc improved from 0.78415 to 0.78470, saving model to gs://new_cxr_30/models/cxr_model/model-040.h5\n","Epoch 41/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.3894 - tp: 0.0000e+00 - fp: 0.4444 - tn: 70.1111 - fn: 7.6667 - accuracy: 0.9048 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6100 - f1: 0.0000e+00 - val_loss: 0.3498 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7860 - val_f1: 0.0000e+00\n","\n","Epoch 00041: val_auc improved from 0.78470 to 0.78596, saving model to gs://new_cxr_30/models/cxr_model/model-041.h5\n","Epoch 42/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.2617 - tp: 0.0000e+00 - fp: 1.5556 - tn: 67.1111 - fn: 9.5556 - accuracy: 0.8745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6560 - f1: 0.0000e+00 - val_loss: 0.3407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7821 - val_f1: 0.0000e+00\n","\n","Epoch 00042: val_auc did not improve from 0.78596\n","Epoch 43/500\n","8/8 [==============================] - 20s 3s/step - loss: 5.3075 - tp: 0.0000e+00 - fp: 1.0000 - tn: 66.2222 - fn: 11.0000 - accuracy: 0.8376 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5510 - f1: 0.0000e+00 - val_loss: 0.3352 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7824 - val_f1: 0.0000e+00\n","\n","Epoch 00043: val_auc did not improve from 0.78596\n","Epoch 44/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.4166 - tp: 2.1111 - fp: 5.8889 - tn: 64.5556 - fn: 5.6667 - accuracy: 0.8479 - precision: 0.2385 - recall: 0.2466 - auc: 0.6770 - f1: 0.1739 - val_loss: 0.3761 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7827 - val_f1: 0.0000e+00\n","\n","Epoch 00044: val_auc did not improve from 0.78596\n","Epoch 45/500\n","8/8 [==============================] - 20s 3s/step - loss: 6.0936 - tp: 0.0000e+00 - fp: 1.4444 - tn: 61.0000 - fn: 15.7778 - accuracy: 0.7824 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.7345 - f1: 0.0000e+00 - val_loss: 0.3254 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7815 - val_f1: 0.0000e+00\n","\n","Epoch 00045: val_auc did not improve from 0.78596\n","Epoch 46/500\n","8/8 [==============================] - 20s 3s/step - loss: 3.7672 - tp: 1.8889 - fp: 7.6667 - tn: 64.0000 - fn: 4.6667 - accuracy: 0.8216 - precision: 0.2019 - recall: 0.3573 - auc: 0.7206 - f1: 0.2268 - val_loss: 0.4142 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7709 - val_f1: 0.0000e+00\n","\n","Epoch 00046: val_auc did not improve from 0.78596\n","Epoch 47/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.2944 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 71.7778 - fn: 6.4444 - accuracy: 0.9210 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6549 - f1: 0.0000e+00 - val_loss: 0.3460 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7782 - val_f1: 0.0000e+00\n","\n","Epoch 00047: val_auc did not improve from 0.78596\n","Epoch 48/500\n","8/8 [==============================] - 21s 3s/step - loss: 2.5354 - tp: 0.4444 - fp: 1.3333 - tn: 69.2222 - fn: 7.2222 - accuracy: 0.9082 - precision: 0.1296 - recall: 0.0347 - auc: 0.7755 - f1: 0.0207 - val_loss: 0.3311 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7794 - val_f1: 0.0000e+00\n","\n","Epoch 00048: val_auc did not improve from 0.78596\n","Epoch 49/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.9352 - tp: 1.2222 - fp: 6.1111 - tn: 64.0000 - fn: 6.8889 - accuracy: 0.8234 - precision: 0.1320 - recall: 0.1136 - auc: 0.6166 - f1: 0.0786 - val_loss: 0.3636 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7763 - val_f1: 0.0000e+00\n","\n","Epoch 00049: val_auc did not improve from 0.78596\n","Epoch 50/500\n","8/8 [==============================] - 21s 3s/step - loss: 4.6942 - tp: 1.5556 - fp: 1.0000 - tn: 64.0000 - fn: 11.6667 - accuracy: 0.8272 - precision: 0.4667 - recall: 0.0973 - auc: 0.7368 - f1: 0.1626 - val_loss: 0.3299 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7798 - val_f1: 0.0000e+00\n","\n","Epoch 00050: val_auc did not improve from 0.78596\n","Epoch 51/500\n","8/8 [==============================] - 21s 3s/step - loss: 3.6658 - tp: 3.3333 - fp: 6.2222 - tn: 60.6667 - fn: 8.0000 - accuracy: 0.8223 - precision: 0.3634 - recall: 0.2749 - auc: 0.8014 - f1: 0.1739 - val_loss: 0.3652 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 404.0000 - val_fn: 57.0000 - val_accuracy: 0.8764 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7788 - val_f1: 0.0000e+00\n","\n","Epoch 00051: val_auc did not improve from 0.78596\n","Restoring model weights from the end of the best epoch.\n","Epoch 00051: early stopping\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 24/24 [4:32:18<00:00, 680.77s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"1al3PY5t9Cbw","executionInfo":{"status":"error","timestamp":1615407961944,"user_tz":-60,"elapsed":16365667,"user":{"displayName":"Miguel Ángel Armengol de la Hoz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-TNP_Mlou2y7VmYBdsulF24WWKZYmqdqSbHr5Rw=s64","userId":"04029216167379405828"}},"outputId":"352eb50b-1b65-4d89-9603-b0c66161e9b4"},"source":["history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-d3b6003cb2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n\u001b[1;32m     10\u001b[0m        'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-24-62464fb0d283>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(results, history, params, extension)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfpath\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/figures'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-c9a4236b3e9d>\u001b[0m in \u001b[0;36mvisualize\u001b[0;34m(history, outpath)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2309\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2218\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36mprint_pdf\u001b[0;34m(self, filename, dpi, bbox_inches_restore, metadata)\u001b[0m\n\u001b[1;32m   2584\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2586\u001b[0;31m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2587\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_file_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/home/Dell/.local/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/figures/k-fold0_augment_bboxB_dropout0.5_layers_not_trainable400_lr_init0.001_cxr_hidden_dims[128, 64]_output_bias[-2.07156032]_pretrained_feature_layer-2_class_weight|0| 10, 1| 10|_loss_functionbinary_crossentropy.pdf'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1800x360 with 6 Axes>"],"image/png":"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\n"},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"UCUBcAyFX7Fk"},"source":["TARGET_SIZE = 320\n","MODEL_TEACHER = ['gs://first_cxr/model/mimic_gen_aug_epoch5.h5'] # 320x320 input\n","\n","# set 1\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": [{0:10 , 1:10}],\n","    \"dropout\": [0.5],\n","    \"epochs\": [50],\n","    \"lr_init\": [0.001,0.003],\n","    \"loss_function\": ['binary_crossentropy'], \n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": [[128,64]],\n","    \"output_bias\": [initial_bias], #[None, initial_bias],\n","    \"layers_not_trainable\": [355, 400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2,-4],\n","    \"augment_bbox\": ['B'], #[False]\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0,1,2,3],\n","}\n","\n","# set 2\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": [{0:10 , 1:10}],\n","    \"dropout\": [0.5],\n","    \"epochs\": [50],\n","    \"lr_init\": [0.001,0.002,0.003],\n","    \"loss_function\": ['binary_crossentropy'], \n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": [[128,64],[128,128,64]],\n","    \"output_bias\": [initial_bias], #[None, initial_bias],\n","    \"layers_not_trainable\": [400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2, -4],\n","    \"augment_bbox\": [False] , #['B']\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0,1,2,3],\n","}\n","\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    cxr320 = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=cxr_search_space,\n","                        experiment_name='tune_covid19_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeVXfi-FYj3R"},"source":["cxr320_search_report = ta.Reporting(cxr320).data\n","report_filename = 'cxr320_rough_search_report_nobbox.csv'\n","report_filename = 'cxr320_rough_search_report_bbox.csv'\n","report_filename = 'cxr320_focalsigmoidloss_report_bbox.csv'\n","report_filename = 'cxr320_focalsigmoidloss_report_bbox2.csv'\n","report_filename = 'cxr320_f1_loss_report_bbox.csv'\n","report_filename = 'cxr320_binary_crossentropy_report_bbox.csv'\n","report_filename = 'cxr320_4fold_report_bbox.csv'\n","report_filename = 'cxr320_4fold_report_bbox_7feb.csv'\n","report_filename = 'cxr320_4fold_report_bbox_8feb.csv'\n","report_filename = 'cxr320_4fold_report_nobbox_11feb.csv'\n","report_filename = 'cxr320_4fold_report_bbox_12feb.csv'\n","\n","export_to_gcs(cxr320_search_report, report_filename, 'gs://new_cxr_30/models/cxr_models')\n","cxr320_search_report.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',report_filename))\n","\n","round_history = cxr320.round_history\n","filename = 'cxrmodel320_rough_search_roundhistory_nobbox.json'\n","filename = 'cxrmodel320_rough_search_roundhistory_bbox.json'\n","filename = 'cxrmodel320_focalsigmoidloss_roundhistory_bbox.json'\n","filename = 'cxrmodel320_focalsigmoidloss_roundhistory_bbox2.json'\n","filename = 'cxrmodel320_f1_loss_roundhistory_bbox2.json'\n","filename = 'cxrmodel320_binary_crossentropy_roundhistory_bbox.json'\n","filename = 'cxrmodel320_4fold_roundhistory_bbox.json'\n","filename = 'cxrmodel320_4fold_roundhistory_bbox_7feb.json'\n","filename = 'cxrmodel320_4fold_roundhistory_bbox_8feb.json'\n","filename = 'cxrmodel320_4fold_roundhistory_nobbox_11feb.json'\n","filename = 'cxrmodel320_4fold_roundhistory_bbox_12feb.json'\n","\n","with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',filename), 'w') as fout:\n","    json.dump(round_history, fout)\n","with open(filename, 'w') as fout:\n","    json.dump(round_history, fout)\n","    export_to_gcs(fout, filename, 'gs://new_cxr_30/models/cxr_models')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXSk9TlKxPSB"},"source":["history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zk5BtNaHFNz8"},"source":["# cxr320_standard_report = ta.Reporting(cxr320_standard).data\n","# report_filename = 'cxr320_standard_search_report3.csv'\n","# export_to_gcs(cxr320_standard_report, report_filename, 'gs://new_cxr_30/models/cxr_models')\n","# cxr320_standard_report.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',report_filename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Pkpeu5yoxIA"},"source":["# averaging weights\n","# https://stackoverflow.com/questions/48212110/average-weights-in-keras-models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iAc6rxGQ4OCZ"},"source":["## Tuning CXR experiments with 224 pretrained model"]},{"cell_type":"code","metadata":{"id":"A-eRW-zcBRq6"},"source":["TARGET_SIZE = 224\n","# trained for pneumonia detection: https://github.com/brucechou1983/CheXNet-Keras#trained-model-weights\n","MODEL_TEACHER = ['gs://first_cxr/model/brucechou1983_CheXNet_Keras_0.3.0_weights.h5'] # 224x224 input\n","\n","def read_image_label_and_path(img_path):\n","    bits = tf.io.read_file(img_path)\n","    image = tf.image.decode_jpeg(bits, channels=1)\n","    image = tf.image.resize(image, [TARGET_SIZE, TARGET_SIZE])\n","    image = tf.cast(image, tf.float32) / 255.0\n","    label = tf.strings.split(img_path, sep='/')[4]\n","    return image, label, img_path\n","\n","# # Hyperparameter search space\n","# cxr_search_space = {\n","#     \"batch_size\": BATCH_SIZE,\n","#     \"class_weight\": CLASS_WEIGHT,\n","#     \"dropout\": DROPOUT,\n","#     \"epochs\": EPOCHS,\n","#     \"lr_init\": LR_INIT,\n","#     \"model_type\": ['cxr_model'],\n","#     \"tab_out_dim\": [1],\n","#     \"cxr_hidden_dims\": CXR_HIDDEN_DIMS,\n","#     \"output_bias\": BIAS,\n","#     \"layers_not_trainable\": LAYERS_NOT_TRAINABLE, # max layers 428 for Po-Chi's base cxr model\n","#     'pretrained_feature_layer': PRETRAINED_FEATURE_LAYER,\n","#     \"augment_bbox\": AUGMENT_BBOX,\n","#     \"model_teacher\": MODEL_TEACHER,\n","# }\n","\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": [{0:10 , 1:10}], # class weight doesn't really help\n","    \"dropout\": [0.5],\n","    \"epochs\": [40],\n","    \"lr_init\": [0.001, 0.003, 0.006], # learning reate 0.009 is too high\n","    \"loss_function\": ['binary_crossentropy'], # both pretty bad -- not learning at all\n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [1],\n","    \"cxr_hidden_dims\": [[128],[128,64],[128,128,64]],\n","    \"output_bias\": BIAS, #[None, initial_bias],\n","    \"layers_not_trainable\": [355,400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2,-4],\n","    \"augment_bbox\": ['B'],\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[1],\n","}\n","# most val F1, precision and recall are really low for these search params, seems to be doing worse than the 320 model\n","\n","\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    cxr224 = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=cxr_search_space,\n","                        experiment_name='tune_covid19_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fFtJ1KorY05H"},"source":["cxr224_search_report = ta.Reporting(cxr224).data\n","report_filename = 'cxr224_fine_search_report.csv'\n","report_filename = 'cxr224_binary_crossentropy_report_bbox.csv'\n","export_to_gcs(cxr224_search_report, report_filename, 'gs://new_cxr_30/models/cxr_models')\n","cxr320_search_report.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',report_filename))\n","\n","round_history = cxr224.round_history\n","\n","filename = 'cxrmodel224_fine_search_roundhistory.json'\n","filename = 'cxrmodel224_binary_crossentropy_roundhistory_bbox.json'\n","\n","with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',filename), 'w') as fout:\n","    json.dump(round_history, fout)\n","with open(filename, 'w') as fout:\n","    json.dump(round_history, fout)\n","    export_to_gcs(fout, filename, 'gs://new_cxr_30/models/cxr_models')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qw09gUuV5ADW"},"source":["## Train late fusion model"]},{"cell_type":"code","metadata":{"id":"ukofYVE54_fH"},"source":["# offline approach:\n","# base model on image, get 14 cxr finding prediciton, concat with structured, then downstream predict mortality\n","# or best CXR model output with rest of structured data\n","# can try tabular deep learning model and all the different models that Wesley tried"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33omj3Rh15Pg"},"source":["# Po-Chih is doing separately"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m15aQsgXnprl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0pfYYXy15Cp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGXaXUh_4xvn"},"source":["## Train intermediate fusion model"]},{"cell_type":"code","metadata":{"id":"WA6-5EwLnxy2"},"source":["# pretrained CXR model input image width/height\n","TARGET_SIZE = 320\n","MODEL_TEACHER = ['gs://first_cxr/model/mimic_gen_aug_epoch5.h5'] # 320x320 input\n","\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": [{0:10 , 1:10}], # tunable\n","    \"dropout\": [0.5], # tunable\n","    \"epochs\": [50], # maximum number because there is early stopping\n","    \"lr_init\": [0.001,0.002,0.003], # tunable\n","    \"loss_function\": ['binary_crossentropy'], \n","    \"model_type\": ['fused_model'],\n","    \"tab_out_dim\": [32, 64], # this may need to be changed to larger for fused model\n","    \"cxr_hidden_dims\": [[128,64], [128, 32], [128,128,64]],\n","    \"output_bias\": [initial_bias], #[None, initial_bias],\n","    \"layers_not_trainable\": [355, 400], # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': [-2, -4],\n","    \"augment_bbox\": ['B'],\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":[0,1,2,3],\n","}\n","\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    cxr320 = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=cxr_search_space,\n","                        experiment_name='tune_covid19_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dpoRIdvQnxve"},"source":["# plot and save\n","history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsYjfogmnxrm"},"source":["cxr320_search_report = ta.Reporting(cxr320).data\n","report_filename = 'change this.csv'\n","\n","export_to_gcs(cxr320_search_report, report_filename, 'gs://new_cxr_30/models/cxr_models')\n","cxr320_search_report.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',report_filename))\n","\n","round_history = cxr320.round_history\n","filename = 'change this.json'\n","\n","with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',filename), 'w') as fout:\n","    json.dump(round_history, fout)\n","with open(filename, 'w') as fout:\n","    json.dump(round_history, fout)\n","    export_to_gcs(fout, filename, 'gs://new_cxr_30/models/cxr_models')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WUbp_I8nxfg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFqjivTbGVEa"},"source":["## Train structured model/encoder"]},{"cell_type":"markdown","metadata":{"id":"CM9Kbvy1iI-t"},"source":["### Structured only"]},{"cell_type":"code","metadata":{"id":"NqSFWRNMQEhr"},"source":["# Hyperparameter search space - some search spaces are not need for some models\n","tab_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": CLASS_WEIGHT,\n","    \"dropout\": DROPOUT,\n","    \"epochs\": EPOCHS,\n","    \"lr_init\": LR_INIT,\n","    \"model_type\": ['tab_model'],\n","    \"tab_out_dim\": [structured_feature_size],\n","    \"cxr_out_dim\": [structured_feature_size],\n","    \"layers_not_trainable\": [355], # max layers 428 for Po-Chi's base cxr model\n","    \"augment_bbox\": [False],\n","    \"model_teacher\": [''],\n","}\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    tab_results = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=tab_search_space,\n","                        experiment_name='tune_covid19_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxGD6XJNcz-3"},"source":["tab_report = ta.Reporting(tab_results).data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pDwVan49zOP"},"source":["tab_report.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeOEw-wroWM2"},"source":["val_precision = tab_report.val_precision.tolist()\n","val_loss = tab_report.val_loss.tolist()\n","val_recall = tab_report.val_recall.tolist() \n","val_accuracy = tab_report.val_binary_accuracy.tolist() \n","lr = tab_report.lr_init.tolist() # no real trend but top performing around 0.009 initial learning rate (already using kera's learning rate scheduler)\n","epochs = tab_report.round_epochs.tolist() # top performers converge before epoch 5\n","bz = tab_report.batch_size.tolist() # larger didn't help\n","cw = [x[0] for x in tab_report.class_weight.tolist()] # recall higher if max weight for minority class, precision the reverse - expected behavior\n","drop = tab_report.dropout.tolist() \n","\n","# x, y = zip(*sorted(zip(lr, loss)))\n","x = drop\n","y = val_precision\n","\n","\n","plt.plot(x, y, 'o', color='black');"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_OkjyeNigxDw"},"source":["best_accuracy = tab_report['val_binary_accuracy'].astype('float').argmax()\n","print(best_accuracy)\n","tab_report.loc[best_accuracy,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsB9FefogFzn"},"source":["best_precision = tab_report['val_precision'].astype('float').argmax()\n","print(best_precision)\n","tab_report.loc[best_precision,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"auhy_Pu2graa"},"source":["best_recall = tab_report['val_recall'].astype('float').argmax()\n","print(best_recall)\n","tab_report.loc[best_recall,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyjBSj1XfTf5"},"source":["# Took quite ~4 hours on cpu...\n","# Deep learning models likely note best choice to learn on a small dataset like this \n","# as compared to RF, XGB, etc that Wesley did -- as expected\n","# But weights combine better in fusion case if the structured data is first passed through some deep learning layers\n","\n","# filename = 'structured_tuning_report.csv'\n","# exportdir = 'gs://new_cxr_30/models/structured/'\n","# export_to_gcs(tab_report, filename, exportdir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNnrmrJykzWe"},"source":["# model_precision = get_best_model(tab_results, 'val_precision')\n","# model_recall = get_best_model(tab_results, 'val_precision')\n","# model_accuracy = get_best_model(tab_results, 'val_binary_accuracy')\n","\n","# exportdir = 'gs://new_cxr_30/models/structured/talos_tuned_models/'\n","# date = '2020_12_25'\n","# export_to_gcs(model_precision, 'structured_best_precision_'+date+'.h5', exportdir)\n","# export_to_gcs(model_recall, 'structured_best_recall_'+date+'.h5', exportdir)\n","# export_to_gcs(model_accuracy, 'structured_best_accuracy_'+date+'.h5', exportdir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0wrzZTb0iN3L"},"source":["### CXR only"]},{"cell_type":"code","metadata":{"id":"PqvzaPE586QV"},"source":["# Hyperparameter search space\n","cxr_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": CLASS_WEIGHT,\n","    \"dropout\": DROPOUT,\n","    \"epochs\": EPOCHS,\n","    \"lr_init\": LR_INIT,\n","    \"model_type\": ['cxr_model'],\n","    \"tab_out_dim\": [structured_feature_size],\n","    \"cxr_out_dim\": [structured_feature_size],\n","    \"layers_not_trainable\": [355, 400, 420], # max layers 428 for Po-Chi's base cxr model\n","    \"augment_bbox\": [False],#AUGMENT_BBOX,\n","    \"model_teacher\": MODEL_TEACHER,\n","}\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    cxr_results = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=cxr_search_space,\n","                        experiment_name='tune_covid19_models')\n","\n","# cxr_results = tune_multiprocess(cxr_search_space, 'tune_covid19_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIgypbKe9xiO"},"source":["cxr_results.data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6RoVQACiRjl"},"source":["### Intermediate fusion"]},{"cell_type":"code","metadata":{"id":"GQDmyafQ9id2"},"source":["# Hyperparameter search space\n","fused_search_space = {\n","    \"batch_size\": BATCH_SIZE,\n","    \"class_weight\": CLASS_WEIGHT,\n","    \"dropout\": DROPOUT,\n","    \"epochs\": EPOCHS,\n","    \"lr_init\": LR_INIT,\n","    \"model_type\": ['fused_model'],\n","    \"tab_out_dim\": [64], #[structured_feature_size, 64, 128],\n","    \"cxr_out_dim\": [64], #[structured_feature_size, 64, 128],\n","    \"layers_not_trainable\": [400],#[355, 400, 420], # max layers 428 for Po-Chi's base cxr model\n","    \"augment_bbox\": [False],#AUGMENT_BBOX, #eagarly execution still doesn't work on cloud tpu...\n","    \"model_teacher\": MODEL_TEACHER,\n","}\n","# https://towardsdatascience.com/smart-hyperparameter-optimization-of-any-deep-learning-model-using-tpu-and-talos-9eb48d09d637\n","with CustomObjectScope({'GlorotUniform': tf.keras.initializers.glorot_uniform()}):\n","    fused_results = ta.Scan(x='x', y='y', x_val= 'xval',y_val= 'yval', # seems to be required input args but irrelevant for tune_coviv19_models i think\n","                        model=tune_covid19_models,\n","                        params=fused_search_space,\n","                        experiment_name='tune_covid19_fused_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6diAdKk4bflR"},"source":["fused_report = ta.Reporting(fused_results).data\n","fused_report.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MO_vh9Vt3Wv5"},"source":["fused_report[fused_report.val_precision > 0.5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJFNH2Gw3WfZ"},"source":["fused_report[fused_report.val_recall > 0.3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kgPfP9Tu3CE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFV43BdBu227"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ldTRiR9m3QRf"},"source":["# ReTrain CXR model on whole dataset with best params"]},{"cell_type":"code","metadata":{"id":"zRzzEx_xT4ZY"},"source":["def train(config, valid = True):\n","    tf.keras.backend.clear_session()\n","    \n","    print(config)\n","    # args\n","    args = type('', (), {})()\n","    # Hyperparameters that can be tuned\n","    args.model_type = config['model_type'] #'tab_model','cxr_model','model_fused'\n","    args.tab_out_dim = config['tab_out_dim']\n","    #args.cxr_out_dim = config['cxr_out_dim'] # last hidden dim would be the cxr_out_dim so fewer search params\n","    args.augment_bbox = config['augment_bbox']\n","    args.model_teacher = config['model_teacher']\n","    args.lr_init = config['lr_init']\n","    args.epochs = config[\"epochs\"]\n","    args.dropout = config['dropout']\n","    args.batch_size = config['batch_size']\n","    args.loss_function = config['loss_function']\n","    args.class_weight = config['class_weight']\n","    args.layers_not_trainable = config['layers_not_trainable']\n","    args.pretrained_feature_layer = config['pretrained_feature_layer']\n","    args.cxr_hidden_dims = config['cxr_hidden_dims']\n","    args.output_bias = config['output_bias']\n","    args.steps_per_epoch = int(len(training_filenames)) // args.batch_size\n","    args.val_steps = int(len(validation_filenames)) // args.batch_size\n","    print(\"With a batch size of {}, there will be {} batches per training epoch and {} batch(es) per validation run.\".format(args.batch_size, args.steps_per_epoch, args.val_steps))\n","    args.fold = config['k-fold']\n","\n","    # input and output parameters\n","    args.train_table_path = 'gs://new_cxr_30/split/train_structured.csv'\n","    args.valid_table_path = 'gs://new_cxr_30/split/valtest_structured.csv'\n","    args.test_table_path = 'gs://new_cxr_30/split/test_structured.csv'\n","    args.combined_table_path = 'gs://new_cxr_30/split/combined_structured.csv'\n","    args.xfeatures = XFEATURES\n","    args.image_path_train = 'gs://new_cxr_30/classified/*/train_*.jpg'\n","    args.image_path_test = 'gs://new_cxr_30/classified/*/test_*.jpg' \n","    #args.resize = TARGET_SIZE\n","    args.num_workers = 16 # can reduce to optimize memory\n","    args.rseed = SEED\n","    args.output_dir = 'gs://new_cxr_30/models/'\n","\n","    # Create saving dir, all useful variables\n","    output_model_path = os.path.join(args.output_dir, args.model_type)\n","    if not os.path.exists(output_model_path): \n","        os.makedirs(output_model_path)\n","    \n","    # Option for k-fold splits for train/val, k=4\n","    if args.fold == 'all':\n","        dftrain = pd.read_csv(args.combined_table_path)\n","        valid = False\n","    else:\n","        dfall = pd.read_csv(args.combined_table_path)\n","        dfvalid = dfall[dfall.fold==args.fold].copy()\n","        dftrain = dfall[~dfall.index.isin(dfvalid.index.tolist())].copy()\n","\n","    # Need to load datasets before initializing tpu or will have address error\n","    # problem:https://github.com/tensorflow/tensorflow/issues/43037\n","    # solution: https://colab.research.google.com/drive/1kpCDInclZHLOvb-9MOgQHUfJfsg8748Z#scrollTo=ZbJDZ6chSWOb\n","\n","    # Compile model\n","    with strategy.scope():\n","        # Load data to iterator\n","        # argumetns: get_augmented_batched_dataset_(structured_path, xfeatures, model_type, batch_size, rseed, train=True)\n","        train_dl = get_augmented_batched_dataset_(dftrain, args.xfeatures\n","                                , args.model_type, args.batch_size, args.augment_bbox, args.rseed, train=True)\n","        if valid:\n","            valid_dl = get_augmented_batched_dataset_(dfvalid, args.xfeatures\n","                                    , args.model_type, args.batch_size, False, args.rseed, train=False)\n","        #test_dl = get_augmented_batched_dataset_(args.test_table_path, args.xfeatures\n","                                #, args.model_type, args.batch_size, False, args.rseed, train=False)\n","        \n","        # # Logs in keras -- no idea where things are being saved\n","        # checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(output_model_path,'model-{epoch:03d}.h5')\n","        #                                                 , verbose=1, monitor='val_auc'\n","        #                                                 ,save_best_only=True, mode='max')  \n","        # early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=10, mode = 'max'\n","        #                                                 , verbose = 1, restore_best_weights=True)\n","        \n","        # Tune learning rate\n","        initial_learning_rate = config['lr_init']\n","        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate\n","                        , decay_steps=100000, decay_rate=0.96, staircase=True)  \n","        \n","        # Getting error with serializing subclassed models...which cannot be done! so changed models to functional\n","        # https://stackoverflow.com/questions/51806852/cant-save-custom-subclassed-model\n","        # Pick the model to fit\n","        if args.model_type == 'tab_model':\n","            #input: input_dim, drop+out\n","            model = TabularModel_functional(len(args.xfeatures), args.dropout)\n","        elif args.model_type == 'cxr_model':\n","            base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","            #input: drop_out, layers_not_trainable\n","            model = CXRModel_functional(base, args.dropout, args.layers_not_trainable\n","                                        , pretrained_feature_layer=args.pretrained_feature_layer\n","                                        , hidden_dims = args.cxr_hidden_dims\n","                                        , output_bias = args.output_bias\n","                                        )\n","        elif args.model_type == 'fused_model':\n","            base = load_base_model(args.model_teacher) # load base model from gb to local runtime\n","            #input: tab_input_dim, drop_out, layers_not_trainable, tab_out_dim, cxr_out_dim\n","            model = Combined_Model_functional(base, len(args.xfeatures), args.dropout, args.layers_not_trainable\n","                                        ,args.pretrained_feature_layer, args.cxr_hidden_dims\n","                                        , args.tab_out_dim \n","                                        #, args.cxr_out_dim\n","                                        , output_bias = args.output_bias\n","                                        )\n","        else:\n","            print('Model type does not exist')\n","        METRICS = [\n","                tf.keras.metrics.TruePositives(name='tp'),\n","                tf.keras.metrics.FalsePositives(name='fp'),\n","                tf.keras.metrics.TrueNegatives(name='tn'),\n","                tf.keras.metrics.FalseNegatives(name='fn'), \n","                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","                tf.keras.metrics.Precision(name=\"precision\"),\n","                tf.keras.metrics.Recall(name=\"recall\"),\n","                tf.keras.metrics.AUC(name='auc'),\n","                #f1,\n","                #tfa.metrics.F1Score(2, name='f1_score') # gives an error\n","                ]\n","        \n","        # likely do better for imbalanced data: https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy\n","        if args.loss_function == 'sigmoid_focal_crossentropy':\n","            loss = tfa.losses.SigmoidFocalCrossEntropy()\n","        elif args.loss_function == 'f1_loss':  \n","            loss = f1_loss\n","        elif args.loss_function == 'macro_double_soft_f1':\n","            loss = macro_double_soft_f1\n","        else:\n","            loss = args.loss_function\n","        \n","        model.compile(\n","            #optimizer='adam',\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n","            loss=loss,\n","            metrics=METRICS,\n","        )\n","\n","    # Fit the model in tf.keras...\n","    if valid:\n","        history = model.fit(train_dl,\n","                            steps_per_epoch = args.steps_per_epoch,\n","                            epochs = args.epochs, \n","                            validation_data = valid_dl,\n","                            shuffle = True,\n","                            class_weight = args.class_weight, \n","                            #callbacks=[checkpoint, early_stopping_cb]\n","                            )\n","    else:\n","        history = model.fit(train_dl,\n","                            steps_per_epoch = args.steps_per_epoch,\n","                            epochs = args.epochs, \n","                            shuffle = True,\n","                            class_weight = args.class_weight, \n","                            #callbacks=[checkpoint, early_stopping_cb]\n","                            )\n","    \n","    # Visualize\n","    \n","    # might not need this in tensorflow 2.x\n","    # if USE_TPU:\n","    #     return history, model #.sync_to_cpu() \n","    # else:\n","    return history, model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v4op3JNbF8dR"},"source":["## Train 4 separate models on the different dataset splits on the final hyperparameters\n","\n","To generate likelihood numbers for different splits for the late fusion model.\n","\n","If trained on all data then the fusion model will likely expect a better than would be in real life likelihood number from the CXR model."]},{"cell_type":"code","metadata":{"id":"HxE1-i5fb-00"},"source":["TARGET_SIZE = 320\n","MODEL_TEACHER = 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5' # 320x320 input\n","folds = [0,1,2,3]\n","\n","config = {\n","        \"batch_size\": 16,\n","        \"class_weight\": {0:10 , 1:10},\n","        \"dropout\": 0.5,\n","        \"epochs\": 19,\n","        \"lr_init\": 0.002,\n","        \"loss_function\": 'binary_crossentropy', \n","        \"model_type\": 'cxr_model',\n","        \"tab_out_dim\": 1,\n","        \"cxr_hidden_dims\": [128,64],\n","        \"output_bias\": initial_bias, #[None, initial_bias],\n","        \"layers_not_trainable\": 400, # max layers 428 for Po-Chi's base cxr model\n","        'pretrained_feature_layer': -2,\n","        \"augment_bbox\": 'B', #[False]\n","        \"model_teacher\": MODEL_TEACHER,\n","        \"k-fold\":None,\n","    }\n","    \n","# final params on different splits\n","histories = []\n","models = []\n","for fold in folds:\n","    fold_config = config.copy()\n","    fold_config['k-fold'] = fold\n","    fold_history, fold_model = train(fold_config)\n","    histories.append(fold_history)\n","    models.append(fold_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fW8KmgAE9jAj"},"source":["# four fold training results\n","model_path = '/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/final'\n","if not os.path.isdir(model_path):\n","    os.makedirs(model_path)\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","\n","for fold, history, model in zip(folds, histories, models):\n","    fold_config = config.copy()\n","    fold_config['k-fold'] = fold\n","    fname = []\n","    for p in params:\n","        v = fold_config[p]\n","        if type(v)==float: v=round(v,4)\n","        fname.append(p+str(v))\n","    fname = '_'.join(fname)\n","    fname = fname.replace(':','|').replace('{','|').replace('}','|')\n","\n","    f1 = [calculate_f1(p,r) for p,r in zip(history.history['precision'],history.history['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(history.history['val_precision'],history.history['val_recall'])]\n","    history.history['f1'] = f1\n","    history.history['val_f1'] = val_f1\n","\n","    metrics = [\"loss\",\"precision\", \"recall\", \"accuracy\", \"auc\",\"f1\"]\n","    fig, ax = plt.subplots(1, len(metrics), figsize=(25, 5))\n","    ax = ax.ravel()\n","\n","    for i, met in enumerate(metrics):\n","        ax[i].plot(history.history[met])\n","        ax[i].plot(history.history[\"val_\" + met])\n","        ax[i].set_title(\"Model {}\".format(met))\n","        ax[i].set_xlabel(\"epochs\")\n","        ax[i].set_ylabel(met)\n","        ax[i].legend([\"train\"])\n","\n","\n","    plt.savefig(os.path.join(model_path, fname+'.pdf'))\n","    model.save(os.path.join(model_path,fname+'.h5'))\n","    with open(os.path.join(model_path,fname+'.json'), 'w') as outfile:\n","        json.dump(history.history, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olFrpErIDxMw"},"source":["combined_table_path = 'gs://new_cxr_30/split/combined_structured.csv'\n","dfall = pd.read_csv(combined_table_path)\n","\n","valresults = {'fold':[],'predicted_probability':[],'y_encoded':[],'path':[]}\n","for fold in folds:\n","    dfvalid = dfall[dfall.fold==fold].copy()\n","    valid_dl = get_augmented_batched_dataset_(dfvalid, XFEATURES, '', len(dfvalid), False, SEED, train=False)    \n","    for structured, images, labels, labels_encoded, img_paths, bbox_coords in valid_dl:\n","        print(images.shape)\n","        ys = labels_encoded.numpy().tolist()\n","        paths = img_paths.numpy().tolist()\n","        y_prob = models[fold].predict(images)\n","        y_prob = [x[0] for x in y_prob]\n","        y_classes = [1 if x > 0.5 else 0 for x in y_prob]\n","        for prob, c, y, path  in zip(y_prob, y_classes, ys, paths):\n","            valresults['fold'].append(fold)\n","            valresults['predicted_probability'].append(prob)\n","            valresults['y_encoded'].append(y)\n","            valresults['path'].append(path)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OeyQ3RQUbxVo"},"source":["dfresults = pd.DataFrame(valresults).copy()   \n","print(dfresults.shape)\n","dfresults['path'] = [x.decode(\"utf-8\") for x in dfresults['path']]\n","dfresults.head()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFP_dTkkB8Kv"},"source":["print(dfall.shape)\n","keep = ['path','predicted_probability']\n","dfstructure_cxr = dfall.merge(dfresults[keep],how = 'left', left_on='path',right_on='path')\n","print(dfstructure_cxr.shape)\n","dfstructure_cxr.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKyCOJMQT2dO"},"source":["model_path = '/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/final'\n","fname = '4fold_models_predictions.csv'\n","dfstructure_cxr.to_csv(os.path.join(model_path,fname),encoding='utf-8',index=False)\n","export_to_gcs(dfstructure_cxr, fname, 'gs://new_cxr_30/predictions/cxr_model')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bEEZo7udbx2o"},"source":["## To train the final CXR model end to end for prediction on test set"]},{"cell_type":"code","metadata":{"id":"P5lvjOePT4OO"},"source":["TARGET_SIZE = 320\n","MODEL_TEACHER = 'gs://first_cxr/model/mimic_gen_aug_epoch5.h5' # 320x320 input\n","fold = 'all'\n","\n","# final params on different splits\n","cxr_config = {\n","    \"batch_size\": 16,\n","    \"class_weight\": {0:10 , 1:10},\n","    \"dropout\": 0.5,\n","    \"epochs\": 19,\n","    \"lr_init\": 0.002,\n","    \"loss_function\": 'binary_crossentropy', \n","    \"model_type\": 'cxr_model',\n","    \"tab_out_dim\": 1,\n","    \"cxr_hidden_dims\": [128,64],\n","    \"output_bias\": initial_bias, #[None, initial_bias],\n","    \"layers_not_trainable\": 400, # max layers 428 for Po-Chi's base cxr model\n","    'pretrained_feature_layer': -2,\n","    \"augment_bbox\": 'B', #[False]\n","    \"model_teacher\": MODEL_TEACHER,\n","    \"k-fold\":fold,\n","}\n","\n","history, model = train(cxr_config, valid = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OtxEeUGniVae"},"source":["model_path = '/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/final'\n","if not os.path.isdir(model_path):\n","    os.makedirs(model_path)\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","\n","fname = []\n","for p in params:\n","    v = cxr_config[p]\n","    if type(v)==float: v=round(v,4)\n","    fname.append(p+str(v))\n","fname = '_'.join(fname)\n","fname = fname.replace(':','|').replace('{','|').replace('}','|')\n","print(fname)\n","\n","model.save(os.path.join(model_path,fname + '.h5'))\n","export_to_gcs(model, fname + '.h5', 'gs://new_cxr_30/models/cxr_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4NkdHQHRwsB"},"source":["with open(os.path.join(model_path,fname+'.json'), 'w') as outfile:\n","    json.dump(history.history, outfile)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4h0NZcUT4C5"},"source":["# final training curve\n","f1 = [calculate_f1(p,r) for p,r in zip(history.history['precision'],history.history['recall'])]\n","history.history['f1'] = f1\n","\n","metrics = [\"loss\",\"precision\", \"recall\", \"accuracy\", \"auc\",\"f1\"]\n","fig, ax = plt.subplots(1, len(metrics), figsize=(25, 5))\n","ax = ax.ravel()\n","\n","for i, met in enumerate(metrics):\n","    ax[i].plot(history.history[met])\n","    ax[i].set_title(\"Model {}\".format(met))\n","    ax[i].set_xlabel(\"epochs\")\n","    ax[i].set_ylabel(met)\n","    ax[i].legend([\"train\"])\n","plt.savefig(os.path.join(model_path, fname+'.pdf'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NrVti_6kaB0"},"source":["combined_table_path = 'gs://new_cxr_30/split/combined_structured.csv'\n","dfall = pd.read_csv(combined_table_path)\n","\n","data_l = get_augmented_batched_dataset_(dfall, XFEATURES, '', len(dfall), False, SEED, train=False)\n","results = {'predicted_probability':[],'y':[],'path':[]}\n","for structured, images, labels, labels_encoded, img_paths, bbox_coords in data_l:\n","    print(images.shape)\n","    ys = labels_encoded.numpy().tolist()\n","    paths = img_paths.numpy().tolist()\n","    y_prob = model.predict(images)\n","    y_prob = [x[0] for x in y_prob]\n","    for p, y, path in zip(y_prob, ys, paths):\n","        results['predicted_probability'].append(p)\n","        results['y'].append(y)\n","        results['path'].append(path)\n","results = pd.DataFrame(results).copy()\n","results['path'] = [x.decode(\"utf-8\") for x in results['path']]\n","\n","print(results.shape)\n","results.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWXODCftT4s8"},"source":["model_path = '/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/final'\n","fname = 'end2end_final_model_predictions.csv'\n","results.to_csv(os.path.join(model_path,fname),encoding='utf-8',index=False)\n","export_to_gcs(results, fname, 'gs://new_cxr_30/predictions/cxr_model')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9CL_RTpIqKdS"},"source":["# Visualize Results"]},{"cell_type":"code","metadata":{"id":"nmLZBDlqWRoW"},"source":["history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMefY1olKThV"},"source":["metrics = [\"loss\",\"precision\", \"recall\", \"accuracy\", \"auc\",\"f1\"]\n","\n","params = ['k-fold','lr_init', 'cxr_hidden_dims']\n","\n","history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","frames = []\n","for i in results.index:\n","    df = pd.DataFrame(history[i])\n","    rounds = list(range(0,len(df)))\n","    for p in params:\n","        v = results.loc[i,p]\n","        # print(p, type(v))\n","        if type(v)==list: \n","            v = str(v)\n","        df[p] = v\n","    df['experiment'] = i\n","    df['round_epoch'] = rounds\n","    df['differentiating_params'] = str(results.loc[i,'lr_init'])+'|' + str(results.loc[i,'cxr_hidden_dims'])\n","    frames.append(df)\n","dfrh = pd.concat(frames,ignore_index=True)\n","print(dfrh.shape)\n","dfrh.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGhbWGsuP_sV"},"source":["dfmax_auc = dfrh.groupby(['k-fold','differentiating_params','experiment'], as_index=False)['val_auc'].max()\n","dfmax_auc['index'] = [dfrh[(dfrh['val_auc']== v)&(dfrh['experiment']==e)].index.tolist()[0] for v, e in zip(dfmax_auc['val_auc'],dfmax_auc['experiment'])]\n","addcols = ['val_f1','val_precision','val_recall','round_epoch']\n","for col in addcols:\n","    dfmax_auc[col] = [dfrh.loc[idx,col] for idx in dfmax_auc['index']]\n","dfmax_auc.sort_values(by=['differentiating_params','k-fold','val_auc'],ascending=[True,True,False],inplace=True)\n","dfmax_auc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQLECtUpNrrU"},"source":["dfmax_f1 = dfrh.groupby(['k-fold','differentiating_params','experiment'], as_index=False)['val_f1'].max()\n","dfmax_f1['index'] = [dfrh[(dfrh['val_f1']== v)&(dfrh['experiment']==e)].index.tolist()[0] for v, e in zip(dfmax_f1['val_f1'],dfmax_f1['experiment'])]\n","addcols = ['val_auc','val_precision','val_recall','round_epoch']\n","for col in addcols:\n","    dfmax_f1[col] = [dfrh.loc[idx,col] for idx in dfmax_f1['index']]\n","dfmax_f1.sort_values(by=['differentiating_params','k-fold','val_f1'],ascending=[True,True,False],inplace=True)\n","dfmax_f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0A-4TUpYapy"},"source":["dfmax_f1_averaged = dfmax_f1.groupby('differentiating_params').agg({'val_f1':'mean', \n","                         'val_auc':'mean', \n","                         'val_precision':'mean', \n","                         'val_recall': 'mean'}).reset_index()\n","\n","dfmax_f1_averaged.sort_values(by=['val_f1','val_auc','val_precision','val_recall'],ascending=[False,False,False,False],inplace=True)\n","\n","dfmax_f1_averaged\n","\n","# 0.002|[128, 64] seems to have the most steady performance across all split and all metrics on val set\n","\n","# So how long shoudl we train for? Need to look at the learning curves for the experiments ran with this param"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhwvzC7McH46"},"source":["exp = dfmax_f1[dfmax_f1.differentiating_params=='0.002|[128, 64]'].experiment.tolist()\n","print(exp)\n","\n","selected_results = results[results.index.isin(exp)].copy()\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","\n","plot_history(selected_results, history, params)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2D42-Do4n4pB"},"source":["show = ['k-fold','val_f1','val_auc','val_precision','val_recall','round_epoch']\n","dfrh[(dfrh.experiment.isin(exp)&(dfrh.round_epoch.isin([15,16,17,18,19,20,21,22])))][show]\n","\n","# 19 epochs looks best on average across the 4 splits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aAsJlUmQQpxC"},"source":["history = cxr320.round_history\n","results = cxr320.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHoojg_UbGI5"},"source":["# Opening JSON file with round history\n","f = open('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/cxrmodel320_rough_search_roundhistory_nobbox.json',) \n","# returns JSON object as  \n","# a dictionary \n","history = json.load(f) \n","\n","# Read in results file with params per search experiment\n","results = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/cxr320_rough_search_report_nobbox.csv')\n","print(results.shape)\n","results.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8AC_Y-Jlz9q"},"source":["# printed results\n","dfres = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models/cxr320_4fold_bboxes_search_report.csv')\n","dfres['f1'] = [calculate_f1(precision,recall) for precision,recall in zip(dfres['precision'],dfres['recall'])]\n","dfres['val_f1'] = [calculate_f1(precision,recall) for precision,recall in zip(dfres['val_precision'],dfres['val_recall'])]\n","dfres.head()\n","\n","params = ['k-fold','augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight']\n","keep = ['experiment'] + params\n","dfres.columns = [x.strip() for x in dfres.columns.tolist()]\n","results = dfres[keep].drop_duplicates().reset_index(drop=True).copy()\n","print(results.shape)\n","\n","history = []\n","metrics = [\"loss\",\"precision\", \"recall\", \"accuracy\", \"auc\",\"f1\"]\n","for i in results.index:\n","    exp = results.loc[i,'experiment']\n","    df = dfres[dfres.experiment == exp].copy()\n","    his = {}\n","    for m in metrics:\n","        his[m] = df[m].tolist()\n","        his['val_'+m] = df['val_' + m].tolist()\n","    history.append(his)\n","\n","# history[0]\n","\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmSfiOL4rFW0"},"source":["report_filename = 'cxr320_4fold_report_bbox.csv'\n","\n","export_to_gcs(results, report_filename, 'gs://new_cxr_30/models/cxr_models')\n","results.to_csv(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',report_filename))\n","\n","filename = 'cxrmodel320_4fold_roundhistory_bbox.json'\n","with open(os.path.join('/content/drive/MyDrive/Colab Notebooks/MIT_COVID19/models',filename), 'w') as fout:\n","    json.dump(history, fout)\n","with open(filename, 'w') as fout:\n","    json.dump(history, fout)\n","    export_to_gcs(fout, filename, 'gs://new_cxr_30/models/cxr_models')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Pe8bQ4rdJac"},"source":["history = cxr224.round_history\n","results = cxr224.data\n","for h in history:\n","    f1 = [calculate_f1(p,r) for p,r in zip(h['precision'],h['recall'])]\n","    val_f1 = [calculate_f1(p,r) for p,r in zip(h['val_precision'],h['val_recall'])]\n","    h['f1'] = f1\n","    h['val_f1'] = val_f1\n","\n","params = ['augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', 'cxr_hidden_dims',\n","       'output_bias', 'pretrained_feature_layer','class_weight', 'loss_function']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pseDtInH82Xh"},"source":["Comments: models aren't really learning yet -- need to tune"]},{"cell_type":"code","metadata":{"id":"xmGHf-fW8h6t"},"source":["params = ['augment_bbox', 'dropout', 'layers_not_trainable', 'lr_init', \n","       'output_bias', 'pretrained_feature_layer','class_weight']\n","plot_history(results, history, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBjDmZDGLnQR"},"source":["idx=0\n","print(cxr320.data.loc[idx,:])\n","print(cxr320.data.columns)\n","visualize(cxr320.round_history[idx])\n","# cxr320.round_history[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_t5dzHjhN4ES"},"source":["idx=1\n","print(cxr320.data.loc[idx,:])\n","visualize(cxr320.round_history[idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ygz9wQnRVn8f"},"source":["idx=2\n","print(cxr320.data.loc[idx,:])\n","visualize(cxr320.round_history[idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8adaF4xoVp5j"},"source":["idx=3\n","print(cxr320.data.loc[idx,:])\n","visualize(cxr320.round_history[idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS8Zl-CoSBYS"},"source":["# visualize(tab_history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6Tp0dJCSDfR"},"source":["# visualize(cxr_history) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7_4tjFg67cY"},"source":["# visualize(fused_history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sdl7qQpMFpWb"},"source":["## Compare models with Bbox augmentation"]},{"cell_type":"code","metadata":{"id":"AeSVFVBvFsDG"},"source":["# seems to be learning better though not optimal and still need to tune\n","\n","# the model seems to do the best on valid set in the first 1-2 epochs \n","# then drops very sharply suddenly \n","# then appears to quickly overfit on training data\n","# This may suggest that the original base CXR model is better trained to recognize key CXR image findings (14 chexpert findings)\n","# And that features learned for the 14 findings are good predictors of the patient mortality outcome even in this different Madrid dataset\n","# Tuning those weights on the small madrid dataset does not seem to be helping to performance (though we still haven't tuned properly)\n","# This also suggest that maybe we should try another late fusion approach where features are structured data + 14 predicted output from the base CXR model without transfer learning\n","\n","# visualize(cxr_bbox_history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7v4tEkbZFsOD"},"source":["# visualize(fused_bbox_history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c7vSRjnI5OjB"},"source":["## scratch"]},{"cell_type":"code","metadata":{"id":"k-0fd4ealPPe"},"source":["# test_table_path = 'gs://new_cxr_30/split/test_structured.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CZ1lPp6Mc9Nc"},"source":["# def model_prediction(model, test_ds):\n","# for image, label in test_ds.take(1):\n","#     plt.imshow(image[0] / 255.0)\n","#     plt.title(CLASSES[label[0].numpy()])\n","\n","#     prediction = model.predict(test_ds.take(1))[0]\n","#     scores = [1 - prediction, prediction]\n","\n","#     for score, name in zip(scores, CLASSES):\n","#         print(\"This image is %.2f percent %s\" % ((100 * score), name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhhR7SenlG19"},"source":["# tab_test_dl = get_augmented_batched_dataset_(test_table_path, xfeatures\n","#                             , 'tab_model', BATCH_SIZE, SEED, train=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQu10svCSHdJ"},"source":["# tab_model.evaluate(test_ds, return_dict=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTFw58dDE7FV"},"source":["# model_prediction(tab_model, tab_test_ds)"],"execution_count":null,"outputs":[]}]}